*** SLURM BATCH JOB 'fine_tune' STARTING ***
tdk-bm4         Sun May 12 14:16:46 2024  535.154.05
[0] NVIDIA L40S | 26Â°C,   0 % |     0 / 49140 MB |
[1] NVIDIA L40S | 23Â°C,   0 % |     0 / 49140 MB |
[2024-05-12 14:16:50,479] torch.distributed.run: [WARNING] 
[2024-05-12 14:16:50,479] torch.distributed.run: [WARNING] *****************************************
[2024-05-12 14:16:50,479] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-12 14:16:50,479] torch.distributed.run: [WARNING] *****************************************
Clearing GPU cache for all ranks
--> Running with torch dist debug set to detail
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:04<00:04,  4.03s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:04<00:04,  4.21s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.36s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.61s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.42s/it]/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.69s/it]
/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
--> Model TheBloke/Llama-2-7B-Chat-fp16

--> TheBloke/Llama-2-7B-Chat-fp16 has 6738.415616 Million params

/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
bFloat16 enabled for mixed precision - using bfSixteen policy
--> applying fsdp activation checkpointing...
--> Training Set Length = 49898
--> Validation Set Length = 200
--> applying fsdp activation checkpointing...
/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 0:   0%|[34m          [0m| 0/779 [00:00<?, ?it/s]/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 0:   0%|[34m          [0m| 1/779 [00:10<2:19:45, 10.78s/it]Training Epoch: 1/1, step 1/779 completed (loss: 2.1923341751098633, lr: 2e-05):   0%|[34m          [0m| 1/779 [00:10<2:19:45, 10.78s/it]Training Epoch: 1/1, step 1/779 completed (loss: 2.1923341751098633, lr: 2e-05):   0%|[34m          [0m| 2/779 [00:17<1:48:50,  8.40s/it]Training Epoch: 1/1, step 2/779 completed (loss: 1.5337293148040771, lr: 2e-05):   0%|[34m          [0m| 2/779 [00:17<1:48:50,  8.40s/it]Training Epoch: 1/1, step 2/779 completed (loss: 1.5337293148040771, lr: 2e-05):   0%|[34m          [0m| 3/779 [00:24<1:39:19,  7.68s/it]Training Epoch: 1/1, step 3/779 completed (loss: 1.1022876501083374, lr: 2e-05):   0%|[34m          [0m| 3/779 [00:24<1:39:19,  7.68s/it]Training Epoch: 1/1, step 3/779 completed (loss: 1.1022876501083374, lr: 2e-05):   1%|[34m          [0m| 4/779 [00:31<1:34:46,  7.34s/it]Training Epoch: 1/1, step 4/779 completed (loss: 1.1715359687805176, lr: 2e-05):   1%|[34m          [0m| 4/779 [00:31<1:34:46,  7.34s/it]Training Epoch: 1/1, step 4/779 completed (loss: 1.1715359687805176, lr: 2e-05):   1%|[34m          [0m| 5/779 [00:37<1:32:11,  7.15s/it]Training Epoch: 1/1, step 5/779 completed (loss: 1.2081210613250732, lr: 2e-05):   1%|[34m          [0m| 5/779 [00:38<1:32:11,  7.15s/it]Training Epoch: 1/1, step 5/779 completed (loss: 1.2081210613250732, lr: 2e-05):   1%|[34m          [0m| 6/779 [00:44<1:30:42,  7.04s/it]Training Epoch: 1/1, step 6/779 completed (loss: 1.2001761198043823, lr: 2e-05):   1%|[34m          [0m| 6/779 [00:44<1:30:42,  7.04s/it]Training Epoch: 1/1, step 6/779 completed (loss: 1.2001761198043823, lr: 2e-05):   1%|[34m          [0m| 7/779 [00:51<1:29:40,  6.97s/it]Training Epoch: 1/1, step 7/779 completed (loss: 1.1570364236831665, lr: 2e-05):   1%|[34m          [0m| 7/779 [00:51<1:29:40,  6.97s/it]Training Epoch: 1/1, step 7/779 completed (loss: 1.1570364236831665, lr: 2e-05):   1%|[34m          [0m| 8/779 [00:58<1:29:05,  6.93s/it]Training Epoch: 1/1, step 8/779 completed (loss: 1.1724879741668701, lr: 2e-05):   1%|[34m          [0m| 8/779 [00:58<1:29:05,  6.93s/it]Training Epoch: 1/1, step 8/779 completed (loss: 1.1724879741668701, lr: 2e-05):   1%|[34m          [0m| 9/779 [01:05<1:28:36,  6.90s/it]Training Epoch: 1/1, step 9/779 completed (loss: 1.1580442190170288, lr: 2e-05):   1%|[34m          [0m| 9/779 [01:05<1:28:36,  6.90s/it]Training Epoch: 1/1, step 9/779 completed (loss: 1.1580442190170288, lr: 2e-05):   1%|[34mâ–         [0m| 10/779 [01:12<1:28:19,  6.89s/it]Training Epoch: 1/1, step 10/779 completed (loss: 1.0240978002548218, lr: 2e-05):   1%|[34mâ–         [0m| 10/779 [01:12<1:28:19,  6.89s/it]Training Epoch: 1/1, step 10/779 completed (loss: 1.0240978002548218, lr: 2e-05):   1%|[34mâ–         [0m| 11/779 [01:19<1:28:07,  6.88s/it]Training Epoch: 1/1, step 11/779 completed (loss: 0.9648826718330383, lr: 2e-05):   1%|[34mâ–         [0m| 11/779 [01:19<1:28:07,  6.88s/it]Training Epoch: 1/1, step 11/779 completed (loss: 0.9648826718330383, lr: 2e-05):   2%|[34mâ–         [0m| 12/779 [01:25<1:27:59,  6.88s/it]Training Epoch: 1/1, step 12/779 completed (loss: 1.1695799827575684, lr: 2e-05):   2%|[34mâ–         [0m| 12/779 [01:26<1:27:59,  6.88s/it]Training Epoch: 1/1, step 12/779 completed (loss: 1.1695799827575684, lr: 2e-05):   2%|[34mâ–         [0m| 13/779 [01:32<1:27:48,  6.88s/it]Training Epoch: 1/1, step 13/779 completed (loss: 1.1789003610610962, lr: 2e-05):   2%|[34mâ–         [0m| 13/779 [01:32<1:27:48,  6.88s/it]Training Epoch: 1/1, step 13/779 completed (loss: 1.1789003610610962, lr: 2e-05):   2%|[34mâ–         [0m| 14/779 [01:39<1:27:41,  6.88s/it]Training Epoch: 1/1, step 14/779 completed (loss: 1.2648367881774902, lr: 2e-05):   2%|[34mâ–         [0m| 14/779 [01:39<1:27:41,  6.88s/it]Training Epoch: 1/1, step 14/779 completed (loss: 1.2648367881774902, lr: 2e-05):   2%|[34mâ–         [0m| 15/779 [01:46<1:27:38,  6.88s/it]Training Epoch: 1/1, step 15/779 completed (loss: 1.2337400913238525, lr: 2e-05):   2%|[34mâ–         [0m| 15/779 [01:46<1:27:38,  6.88s/it]Training Epoch: 1/1, step 15/779 completed (loss: 1.2337400913238525, lr: 2e-05):   2%|[34mâ–         [0m| 16/779 [01:53<1:27:33,  6.89s/it]Training Epoch: 1/1, step 16/779 completed (loss: 1.0036540031433105, lr: 2e-05):   2%|[34mâ–         [0m| 16/779 [01:53<1:27:33,  6.89s/it]Training Epoch: 1/1, step 16/779 completed (loss: 1.0036540031433105, lr: 2e-05):   2%|[34mâ–         [0m| 17/779 [02:00<1:27:35,  6.90s/it]Training Epoch: 1/1, step 17/779 completed (loss: 1.1885839700698853, lr: 2e-05):   2%|[34mâ–         [0m| 17/779 [02:00<1:27:35,  6.90s/it]Training Epoch: 1/1, step 17/779 completed (loss: 1.1885839700698853, lr: 2e-05):   2%|[34mâ–         [0m| 18/779 [02:07<1:27:30,  6.90s/it]Training Epoch: 1/1, step 18/779 completed (loss: 1.2246568202972412, lr: 2e-05):   2%|[34mâ–         [0m| 18/779 [02:07<1:27:30,  6.90s/it]Training Epoch: 1/1, step 18/779 completed (loss: 1.2246568202972412, lr: 2e-05):   2%|[34mâ–         [0m| 19/779 [02:14<1:27:22,  6.90s/it]Training Epoch: 1/1, step 19/779 completed (loss: 0.9731040596961975, lr: 2e-05):   2%|[34mâ–         [0m| 19/779 [02:14<1:27:22,  6.90s/it]Training Epoch: 1/1, step 19/779 completed (loss: 0.9731040596961975, lr: 2e-05):   3%|[34mâ–Ž         [0m| 20/779 [02:21<1:27:19,  6.90s/it]Training Epoch: 1/1, step 20/779 completed (loss: 1.0907856225967407, lr: 2e-05):   3%|[34mâ–Ž         [0m| 20/779 [02:21<1:27:19,  6.90s/it]Training Epoch: 1/1, step 20/779 completed (loss: 1.0907856225967407, lr: 2e-05):   3%|[34mâ–Ž         [0m| 21/779 [02:27<1:27:09,  6.90s/it]Training Epoch: 1/1, step 21/779 completed (loss: 1.0446794033050537, lr: 2e-05):   3%|[34mâ–Ž         [0m| 21/779 [02:28<1:27:09,  6.90s/it]Training Epoch: 1/1, step 21/779 completed (loss: 1.0446794033050537, lr: 2e-05):   3%|[34mâ–Ž         [0m| 22/779 [02:34<1:26:57,  6.89s/it]Training Epoch: 1/1, step 22/779 completed (loss: 1.0212738513946533, lr: 2e-05):   3%|[34mâ–Ž         [0m| 22/779 [02:34<1:26:57,  6.89s/it]Training Epoch: 1/1, step 22/779 completed (loss: 1.0212738513946533, lr: 2e-05):   3%|[34mâ–Ž         [0m| 23/779 [02:41<1:26:45,  6.89s/it]Training Epoch: 1/1, step 23/779 completed (loss: 1.1920394897460938, lr: 2e-05):   3%|[34mâ–Ž         [0m| 23/779 [02:41<1:26:45,  6.89s/it]Training Epoch: 1/1, step 23/779 completed (loss: 1.1920394897460938, lr: 2e-05):   3%|[34mâ–Ž         [0m| 24/779 [02:48<1:26:36,  6.88s/it]Training Epoch: 1/1, step 24/779 completed (loss: 1.1317516565322876, lr: 2e-05):   3%|[34mâ–Ž         [0m| 24/779 [02:48<1:26:36,  6.88s/it]Training Epoch: 1/1, step 24/779 completed (loss: 1.1317516565322876, lr: 2e-05):   3%|[34mâ–Ž         [0m| 25/779 [02:55<1:26:27,  6.88s/it]Training Epoch: 1/1, step 25/779 completed (loss: 1.0462706089019775, lr: 2e-05):   3%|[34mâ–Ž         [0m| 25/779 [02:55<1:26:27,  6.88s/it]Training Epoch: 1/1, step 25/779 completed (loss: 1.0462706089019775, lr: 2e-05):   3%|[34mâ–Ž         [0m| 26/779 [03:02<1:26:25,  6.89s/it]Training Epoch: 1/1, step 26/779 completed (loss: 1.1063156127929688, lr: 2e-05):   3%|[34mâ–Ž         [0m| 26/779 [03:02<1:26:25,  6.89s/it]Training Epoch: 1/1, step 26/779 completed (loss: 1.1063156127929688, lr: 2e-05):   3%|[34mâ–Ž         [0m| 27/779 [03:09<1:26:20,  6.89s/it]Training Epoch: 1/1, step 27/779 completed (loss: 1.1989789009094238, lr: 2e-05):   3%|[34mâ–Ž         [0m| 27/779 [03:09<1:26:20,  6.89s/it]Training Epoch: 1/1, step 27/779 completed (loss: 1.1989789009094238, lr: 2e-05):   4%|[34mâ–Ž         [0m| 28/779 [03:16<1:26:14,  6.89s/it]Training Epoch: 1/1, step 28/779 completed (loss: 1.0551847219467163, lr: 2e-05):   4%|[34mâ–Ž         [0m| 28/779 [03:16<1:26:14,  6.89s/it]Training Epoch: 1/1, step 28/779 completed (loss: 1.0551847219467163, lr: 2e-05):   4%|[34mâ–Ž         [0m| 29/779 [03:23<1:26:09,  6.89s/it]Training Epoch: 1/1, step 29/779 completed (loss: 1.0340687036514282, lr: 2e-05):   4%|[34mâ–Ž         [0m| 29/779 [03:23<1:26:09,  6.89s/it]Training Epoch: 1/1, step 29/779 completed (loss: 1.0340687036514282, lr: 2e-05):   4%|[34mâ–         [0m| 30/779 [03:29<1:26:04,  6.90s/it]Training Epoch: 1/1, step 30/779 completed (loss: 1.092391014099121, lr: 2e-05):   4%|[34mâ–         [0m| 30/779 [03:30<1:26:04,  6.90s/it] Training Epoch: 1/1, step 30/779 completed (loss: 1.092391014099121, lr: 2e-05):   4%|[34mâ–         [0m| 31/779 [03:36<1:25:53,  6.89s/it]Training Epoch: 1/1, step 31/779 completed (loss: 1.032573938369751, lr: 2e-05):   4%|[34mâ–         [0m| 31/779 [03:36<1:25:53,  6.89s/it]Training Epoch: 1/1, step 31/779 completed (loss: 1.032573938369751, lr: 2e-05):   4%|[34mâ–         [0m| 32/779 [03:43<1:25:49,  6.89s/it]Training Epoch: 1/1, step 32/779 completed (loss: 1.20928955078125, lr: 2e-05):   4%|[34mâ–         [0m| 32/779 [03:43<1:25:49,  6.89s/it] Training Epoch: 1/1, step 32/779 completed (loss: 1.20928955078125, lr: 2e-05):   4%|[34mâ–         [0m| 33/779 [03:50<1:25:42,  6.89s/it]Training Epoch: 1/1, step 33/779 completed (loss: 1.219696044921875, lr: 2e-05):   4%|[34mâ–         [0m| 33/779 [03:50<1:25:42,  6.89s/it]Training Epoch: 1/1, step 33/779 completed (loss: 1.219696044921875, lr: 2e-05):   4%|[34mâ–         [0m| 34/779 [03:57<1:25:33,  6.89s/it]Training Epoch: 1/1, step 34/779 completed (loss: 1.1718847751617432, lr: 2e-05):   4%|[34mâ–         [0m| 34/779 [03:57<1:25:33,  6.89s/it]Training Epoch: 1/1, step 34/779 completed (loss: 1.1718847751617432, lr: 2e-05):   4%|[34mâ–         [0m| 35/779 [04:04<1:25:27,  6.89s/it]Training Epoch: 1/1, step 35/779 completed (loss: 1.0559844970703125, lr: 2e-05):   4%|[34mâ–         [0m| 35/779 [04:04<1:25:27,  6.89s/it]Training Epoch: 1/1, step 35/779 completed (loss: 1.0559844970703125, lr: 2e-05):   5%|[34mâ–         [0m| 36/779 [04:11<1:25:30,  6.91s/it]Training Epoch: 1/1, step 36/779 completed (loss: 1.1902731657028198, lr: 2e-05):   5%|[34mâ–         [0m| 36/779 [04:11<1:25:30,  6.91s/it]Training Epoch: 1/1, step 36/779 completed (loss: 1.1902731657028198, lr: 2e-05):   5%|[34mâ–         [0m| 37/779 [04:18<1:25:17,  6.90s/it]Training Epoch: 1/1, step 37/779 completed (loss: 1.1422803401947021, lr: 2e-05):   5%|[34mâ–         [0m| 37/779 [04:18<1:25:17,  6.90s/it]Training Epoch: 1/1, step 37/779 completed (loss: 1.1422803401947021, lr: 2e-05):   5%|[34mâ–         [0m| 38/779 [04:25<1:25:09,  6.90s/it]Training Epoch: 1/1, step 38/779 completed (loss: 1.0405150651931763, lr: 2e-05):   5%|[34mâ–         [0m| 38/779 [04:25<1:25:09,  6.90s/it]Training Epoch: 1/1, step 38/779 completed (loss: 1.0405150651931763, lr: 2e-05):   5%|[34mâ–Œ         [0m| 39/779 [04:32<1:25:02,  6.90s/it]Training Epoch: 1/1, step 39/779 completed (loss: 1.0457024574279785, lr: 2e-05):   5%|[34mâ–Œ         [0m| 39/779 [04:32<1:25:02,  6.90s/it]Training Epoch: 1/1, step 39/779 completed (loss: 1.0457024574279785, lr: 2e-05):   5%|[34mâ–Œ         [0m| 40/779 [04:38<1:24:54,  6.89s/it]Training Epoch: 1/1, step 40/779 completed (loss: 1.1082508563995361, lr: 2e-05):   5%|[34mâ–Œ         [0m| 40/779 [04:39<1:24:54,  6.89s/it]Training Epoch: 1/1, step 40/779 completed (loss: 1.1082508563995361, lr: 2e-05):   5%|[34mâ–Œ         [0m| 41/779 [04:45<1:24:49,  6.90s/it]Training Epoch: 1/1, step 41/779 completed (loss: 1.1315807104110718, lr: 2e-05):   5%|[34mâ–Œ         [0m| 41/779 [04:45<1:24:49,  6.90s/it]Training Epoch: 1/1, step 41/779 completed (loss: 1.1315807104110718, lr: 2e-05):   5%|[34mâ–Œ         [0m| 42/779 [04:52<1:24:44,  6.90s/it]Training Epoch: 1/1, step 42/779 completed (loss: 1.2006840705871582, lr: 2e-05):   5%|[34mâ–Œ         [0m| 42/779 [04:52<1:24:44,  6.90s/it]Training Epoch: 1/1, step 42/779 completed (loss: 1.2006840705871582, lr: 2e-05):   6%|[34mâ–Œ         [0m| 43/779 [04:59<1:24:35,  6.90s/it]Training Epoch: 1/1, step 43/779 completed (loss: 0.9500982165336609, lr: 2e-05):   6%|[34mâ–Œ         [0m| 43/779 [04:59<1:24:35,  6.90s/it]Training Epoch: 1/1, step 43/779 completed (loss: 0.9500982165336609, lr: 2e-05):   6%|[34mâ–Œ         [0m| 44/779 [05:06<1:24:33,  6.90s/it]Training Epoch: 1/1, step 44/779 completed (loss: 1.0074371099472046, lr: 2e-05):   6%|[34mâ–Œ         [0m| 44/779 [05:06<1:24:33,  6.90s/it]Training Epoch: 1/1, step 44/779 completed (loss: 1.0074371099472046, lr: 2e-05):   6%|[34mâ–Œ         [0m| 45/779 [05:13<1:24:24,  6.90s/it]Training Epoch: 1/1, step 45/779 completed (loss: 1.102023959159851, lr: 2e-05):   6%|[34mâ–Œ         [0m| 45/779 [05:13<1:24:24,  6.90s/it] Training Epoch: 1/1, step 45/779 completed (loss: 1.102023959159851, lr: 2e-05):   6%|[34mâ–Œ         [0m| 46/779 [05:20<1:24:25,  6.91s/it]Training Epoch: 1/1, step 46/779 completed (loss: 1.0923967361450195, lr: 2e-05):   6%|[34mâ–Œ         [0m| 46/779 [05:20<1:24:25,  6.91s/it]Training Epoch: 1/1, step 46/779 completed (loss: 1.0923967361450195, lr: 2e-05):   6%|[34mâ–Œ         [0m| 47/779 [05:27<1:24:19,  6.91s/it]Training Epoch: 1/1, step 47/779 completed (loss: 1.1591978073120117, lr: 2e-05):   6%|[34mâ–Œ         [0m| 47/779 [05:27<1:24:19,  6.91s/it]Training Epoch: 1/1, step 47/779 completed (loss: 1.1591978073120117, lr: 2e-05):   6%|[34mâ–Œ         [0m| 48/779 [05:34<1:24:18,  6.92s/it]Training Epoch: 1/1, step 48/779 completed (loss: 0.9223482012748718, lr: 2e-05):   6%|[34mâ–Œ         [0m| 48/779 [05:34<1:24:18,  6.92s/it]Training Epoch: 1/1, step 48/779 completed (loss: 0.9223482012748718, lr: 2e-05):   6%|[34mâ–‹         [0m| 49/779 [05:41<1:24:05,  6.91s/it]Training Epoch: 1/1, step 49/779 completed (loss: 1.066491961479187, lr: 2e-05):   6%|[34mâ–‹         [0m| 49/779 [05:41<1:24:05,  6.91s/it] Training Epoch: 1/1, step 49/779 completed (loss: 1.066491961479187, lr: 2e-05):   6%|[34mâ–‹         [0m| 50/779 [05:48<1:23:55,  6.91s/it]Training Epoch: 1/1, step 50/779 completed (loss: 1.0473084449768066, lr: 2e-05):   6%|[34mâ–‹         [0m| 50/779 [05:48<1:23:55,  6.91s/it]Training Epoch: 1/1, step 50/779 completed (loss: 1.0473084449768066, lr: 2e-05):   7%|[34mâ–‹         [0m| 51/779 [05:54<1:23:58,  6.92s/it]Training Epoch: 1/1, step 51/779 completed (loss: 1.1937103271484375, lr: 2e-05):   7%|[34mâ–‹         [0m| 51/779 [05:55<1:23:58,  6.92s/it]Training Epoch: 1/1, step 51/779 completed (loss: 1.1937103271484375, lr: 2e-05):   7%|[34mâ–‹         [0m| 52/779 [06:01<1:23:50,  6.92s/it]Training Epoch: 1/1, step 52/779 completed (loss: 1.101416826248169, lr: 2e-05):   7%|[34mâ–‹         [0m| 52/779 [06:02<1:23:50,  6.92s/it] Training Epoch: 1/1, step 52/779 completed (loss: 1.101416826248169, lr: 2e-05):   7%|[34mâ–‹         [0m| 53/779 [06:08<1:23:42,  6.92s/it]Training Epoch: 1/1, step 53/779 completed (loss: 1.107973575592041, lr: 2e-05):   7%|[34mâ–‹         [0m| 53/779 [06:08<1:23:42,  6.92s/it]Training Epoch: 1/1, step 53/779 completed (loss: 1.107973575592041, lr: 2e-05):   7%|[34mâ–‹         [0m| 54/779 [06:15<1:23:37,  6.92s/it]Training Epoch: 1/1, step 54/779 completed (loss: 1.1794297695159912, lr: 2e-05):   7%|[34mâ–‹         [0m| 54/779 [06:15<1:23:37,  6.92s/it]Training Epoch: 1/1, step 54/779 completed (loss: 1.1794297695159912, lr: 2e-05):   7%|[34mâ–‹         [0m| 55/779 [06:22<1:23:33,  6.92s/it]Training Epoch: 1/1, step 55/779 completed (loss: 1.1254140138626099, lr: 2e-05):   7%|[34mâ–‹         [0m| 55/779 [06:22<1:23:33,  6.92s/it]Training Epoch: 1/1, step 55/779 completed (loss: 1.1254140138626099, lr: 2e-05):   7%|[34mâ–‹         [0m| 56/779 [06:29<1:23:25,  6.92s/it]Training Epoch: 1/1, step 56/779 completed (loss: 1.0927705764770508, lr: 2e-05):   7%|[34mâ–‹         [0m| 56/779 [06:29<1:23:25,  6.92s/it]Training Epoch: 1/1, step 56/779 completed (loss: 1.0927705764770508, lr: 2e-05):   7%|[34mâ–‹         [0m| 57/779 [06:36<1:23:20,  6.93s/it]Training Epoch: 1/1, step 57/779 completed (loss: 1.087053894996643, lr: 2e-05):   7%|[34mâ–‹         [0m| 57/779 [06:36<1:23:20,  6.93s/it] Training Epoch: 1/1, step 57/779 completed (loss: 1.087053894996643, lr: 2e-05):   7%|[34mâ–‹         [0m| 58/779 [06:43<1:23:15,  6.93s/it]Training Epoch: 1/1, step 58/779 completed (loss: 1.0366413593292236, lr: 2e-05):   7%|[34mâ–‹         [0m| 58/779 [06:43<1:23:15,  6.93s/it]Training Epoch: 1/1, step 58/779 completed (loss: 1.0366413593292236, lr: 2e-05):   8%|[34mâ–Š         [0m| 59/779 [06:50<1:23:07,  6.93s/it]Training Epoch: 1/1, step 59/779 completed (loss: 0.9579463005065918, lr: 2e-05):   8%|[34mâ–Š         [0m| 59/779 [06:50<1:23:07,  6.93s/it]Training Epoch: 1/1, step 59/779 completed (loss: 0.9579463005065918, lr: 2e-05):   8%|[34mâ–Š         [0m| 60/779 [06:57<1:22:57,  6.92s/it]Training Epoch: 1/1, step 60/779 completed (loss: 1.060132384300232, lr: 2e-05):   8%|[34mâ–Š         [0m| 60/779 [06:57<1:22:57,  6.92s/it] Training Epoch: 1/1, step 60/779 completed (loss: 1.060132384300232, lr: 2e-05):   8%|[34mâ–Š         [0m| 61/779 [07:04<1:22:49,  6.92s/it]Training Epoch: 1/1, step 61/779 completed (loss: 1.0774799585342407, lr: 2e-05):   8%|[34mâ–Š         [0m| 61/779 [07:04<1:22:49,  6.92s/it]Training Epoch: 1/1, step 61/779 completed (loss: 1.0774799585342407, lr: 2e-05):   8%|[34mâ–Š         [0m| 62/779 [07:11<1:22:36,  6.91s/it]Training Epoch: 1/1, step 62/779 completed (loss: 1.1671850681304932, lr: 2e-05):   8%|[34mâ–Š         [0m| 62/779 [07:11<1:22:36,  6.91s/it]Training Epoch: 1/1, step 62/779 completed (loss: 1.1671850681304932, lr: 2e-05):   8%|[34mâ–Š         [0m| 63/779 [07:17<1:22:24,  6.91s/it]Training Epoch: 1/1, step 63/779 completed (loss: 1.0795783996582031, lr: 2e-05):   8%|[34mâ–Š         [0m| 63/779 [07:18<1:22:24,  6.91s/it]Training Epoch: 1/1, step 63/779 completed (loss: 1.0795783996582031, lr: 2e-05):   8%|[34mâ–Š         [0m| 64/779 [07:24<1:22:23,  6.91s/it]Training Epoch: 1/1, step 64/779 completed (loss: 0.9921687245368958, lr: 2e-05):   8%|[34mâ–Š         [0m| 64/779 [07:25<1:22:23,  6.91s/it]Training Epoch: 1/1, step 64/779 completed (loss: 0.9921687245368958, lr: 2e-05):   8%|[34mâ–Š         [0m| 65/779 [07:31<1:22:16,  6.91s/it]Training Epoch: 1/1, step 65/779 completed (loss: 1.02215576171875, lr: 2e-05):   8%|[34mâ–Š         [0m| 65/779 [07:31<1:22:16,  6.91s/it]  Training Epoch: 1/1, step 65/779 completed (loss: 1.02215576171875, lr: 2e-05):   8%|[34mâ–Š         [0m| 66/779 [07:38<1:22:07,  6.91s/it]Training Epoch: 1/1, step 66/779 completed (loss: 1.0219430923461914, lr: 2e-05):   8%|[34mâ–Š         [0m| 66/779 [07:38<1:22:07,  6.91s/it]Training Epoch: 1/1, step 66/779 completed (loss: 1.0219430923461914, lr: 2e-05):   9%|[34mâ–Š         [0m| 67/779 [07:45<1:22:07,  6.92s/it]Training Epoch: 1/1, step 67/779 completed (loss: 1.1118545532226562, lr: 2e-05):   9%|[34mâ–Š         [0m| 67/779 [07:45<1:22:07,  6.92s/it]Training Epoch: 1/1, step 67/779 completed (loss: 1.1118545532226562, lr: 2e-05):   9%|[34mâ–Š         [0m| 68/779 [07:52<1:21:54,  6.91s/it]Training Epoch: 1/1, step 68/779 completed (loss: 1.0640666484832764, lr: 2e-05):   9%|[34mâ–Š         [0m| 68/779 [07:52<1:21:54,  6.91s/it]Training Epoch: 1/1, step 68/779 completed (loss: 1.0640666484832764, lr: 2e-05):   9%|[34mâ–‰         [0m| 69/779 [07:59<1:21:44,  6.91s/it]Training Epoch: 1/1, step 69/779 completed (loss: 1.1814184188842773, lr: 2e-05):   9%|[34mâ–‰         [0m| 69/779 [07:59<1:21:44,  6.91s/it]Training Epoch: 1/1, step 69/779 completed (loss: 1.1814184188842773, lr: 2e-05):   9%|[34mâ–‰         [0m| 70/779 [08:06<1:21:34,  6.90s/it]Training Epoch: 1/1, step 70/779 completed (loss: 0.9335202574729919, lr: 2e-05):   9%|[34mâ–‰         [0m| 70/779 [08:06<1:21:34,  6.90s/it]Training Epoch: 1/1, step 70/779 completed (loss: 0.9335202574729919, lr: 2e-05):   9%|[34mâ–‰         [0m| 71/779 [08:13<1:21:31,  6.91s/it]Training Epoch: 1/1, step 71/779 completed (loss: 1.18392014503479, lr: 2e-05):   9%|[34mâ–‰         [0m| 71/779 [08:13<1:21:31,  6.91s/it]  Training Epoch: 1/1, step 71/779 completed (loss: 1.18392014503479, lr: 2e-05):   9%|[34mâ–‰         [0m| 72/779 [08:20<1:21:22,  6.91s/it]Training Epoch: 1/1, step 72/779 completed (loss: 1.0990517139434814, lr: 2e-05):   9%|[34mâ–‰         [0m| 72/779 [08:20<1:21:22,  6.91s/it]Training Epoch: 1/1, step 72/779 completed (loss: 1.0990517139434814, lr: 2e-05):   9%|[34mâ–‰         [0m| 73/779 [08:27<1:21:12,  6.90s/it]Training Epoch: 1/1, step 73/779 completed (loss: 0.9449329376220703, lr: 2e-05):   9%|[34mâ–‰         [0m| 73/779 [08:27<1:21:12,  6.90s/it]Training Epoch: 1/1, step 73/779 completed (loss: 0.9449329376220703, lr: 2e-05):   9%|[34mâ–‰         [0m| 74/779 [08:33<1:21:10,  6.91s/it]Training Epoch: 1/1, step 74/779 completed (loss: 0.9820210337638855, lr: 2e-05):   9%|[34mâ–‰         [0m| 74/779 [08:34<1:21:10,  6.91s/it]Training Epoch: 1/1, step 74/779 completed (loss: 0.9820210337638855, lr: 2e-05):  10%|[34mâ–‰         [0m| 75/779 [08:40<1:21:09,  6.92s/it]Training Epoch: 1/1, step 75/779 completed (loss: 1.1024283170700073, lr: 2e-05):  10%|[34mâ–‰         [0m| 75/779 [08:41<1:21:09,  6.92s/it]Training Epoch: 1/1, step 75/779 completed (loss: 1.1024283170700073, lr: 2e-05):  10%|[34mâ–‰         [0m| 76/779 [08:47<1:21:00,  6.91s/it]Training Epoch: 1/1, step 76/779 completed (loss: 0.9893214702606201, lr: 2e-05):  10%|[34mâ–‰         [0m| 76/779 [08:47<1:21:00,  6.91s/it]Training Epoch: 1/1, step 76/779 completed (loss: 0.9893214702606201, lr: 2e-05):  10%|[34mâ–‰         [0m| 77/779 [08:54<1:20:49,  6.91s/it]Training Epoch: 1/1, step 77/779 completed (loss: 1.1076714992523193, lr: 2e-05):  10%|[34mâ–‰         [0m| 77/779 [08:54<1:20:49,  6.91s/it]Training Epoch: 1/1, step 77/779 completed (loss: 1.1076714992523193, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 78/779 [09:01<1:20:40,  6.91s/it]Training Epoch: 1/1, step 78/779 completed (loss: 1.1426030397415161, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 78/779 [09:01<1:20:40,  6.91s/it]Training Epoch: 1/1, step 78/779 completed (loss: 1.1426030397415161, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 79/779 [09:08<1:20:30,  6.90s/it]Training Epoch: 1/1, step 79/779 completed (loss: 1.1367741823196411, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 79/779 [09:08<1:20:30,  6.90s/it]Training Epoch: 1/1, step 79/779 completed (loss: 1.1367741823196411, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 80/779 [09:15<1:20:23,  6.90s/it]Training Epoch: 1/1, step 80/779 completed (loss: 1.1559280157089233, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 80/779 [09:15<1:20:23,  6.90s/it]Training Epoch: 1/1, step 80/779 completed (loss: 1.1559280157089233, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 81/779 [09:22<1:20:13,  6.90s/it]Training Epoch: 1/1, step 81/779 completed (loss: 1.2347345352172852, lr: 2e-05):  10%|[34mâ–ˆ         [0m| 81/779 [09:22<1:20:13,  6.90s/it]Training Epoch: 1/1, step 81/779 completed (loss: 1.2347345352172852, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 82/779 [09:29<1:20:05,  6.89s/it]Training Epoch: 1/1, step 82/779 completed (loss: 1.0697425603866577, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 82/779 [09:29<1:20:05,  6.89s/it]Training Epoch: 1/1, step 82/779 completed (loss: 1.0697425603866577, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 83/779 [09:36<1:20:02,  6.90s/it]Training Epoch: 1/1, step 83/779 completed (loss: 1.0119895935058594, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 83/779 [09:36<1:20:02,  6.90s/it]Training Epoch: 1/1, step 83/779 completed (loss: 1.0119895935058594, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 84/779 [09:42<1:19:52,  6.90s/it]Training Epoch: 1/1, step 84/779 completed (loss: 1.0429768562316895, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 84/779 [09:43<1:19:52,  6.90s/it]Training Epoch: 1/1, step 84/779 completed (loss: 1.0429768562316895, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 85/779 [09:49<1:19:44,  6.89s/it]Training Epoch: 1/1, step 85/779 completed (loss: 1.1980602741241455, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 85/779 [09:50<1:19:44,  6.89s/it]Training Epoch: 1/1, step 85/779 completed (loss: 1.1980602741241455, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 86/779 [09:56<1:19:36,  6.89s/it]Training Epoch: 1/1, step 86/779 completed (loss: 1.023051142692566, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 86/779 [09:56<1:19:36,  6.89s/it] Training Epoch: 1/1, step 86/779 completed (loss: 1.023051142692566, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 87/779 [10:03<1:19:36,  6.90s/it]Training Epoch: 1/1, step 87/779 completed (loss: 1.0058648586273193, lr: 2e-05):  11%|[34mâ–ˆ         [0m| 87/779 [10:03<1:19:36,  6.90s/it]Training Epoch: 1/1, step 87/779 completed (loss: 1.0058648586273193, lr: 2e-05):  11%|[34mâ–ˆâ–        [0m| 88/779 [10:10<1:19:37,  6.91s/it]Training Epoch: 1/1, step 88/779 completed (loss: 1.1339468955993652, lr: 2e-05):  11%|[34mâ–ˆâ–        [0m| 88/779 [10:10<1:19:37,  6.91s/it]Training Epoch: 1/1, step 88/779 completed (loss: 1.1339468955993652, lr: 2e-05):  11%|[34mâ–ˆâ–        [0m| 89/779 [10:17<1:19:28,  6.91s/it]Training Epoch: 1/1, step 89/779 completed (loss: 1.1681121587753296, lr: 2e-05):  11%|[34mâ–ˆâ–        [0m| 89/779 [10:17<1:19:28,  6.91s/it]Training Epoch: 1/1, step 89/779 completed (loss: 1.1681121587753296, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 90/779 [10:24<1:19:17,  6.90s/it]Training Epoch: 1/1, step 90/779 completed (loss: 1.1284698247909546, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 90/779 [10:24<1:19:17,  6.90s/it]Training Epoch: 1/1, step 90/779 completed (loss: 1.1284698247909546, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 91/779 [10:31<1:19:12,  6.91s/it]Training Epoch: 1/1, step 91/779 completed (loss: 1.1271480321884155, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 91/779 [10:31<1:19:12,  6.91s/it]Training Epoch: 1/1, step 91/779 completed (loss: 1.1271480321884155, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 92/779 [10:38<1:19:04,  6.91s/it]Training Epoch: 1/1, step 92/779 completed (loss: 1.0517216920852661, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 92/779 [10:38<1:19:04,  6.91s/it]Training Epoch: 1/1, step 92/779 completed (loss: 1.0517216920852661, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 93/779 [10:45<1:18:55,  6.90s/it]Training Epoch: 1/1, step 93/779 completed (loss: 1.1295109987258911, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 93/779 [10:45<1:18:55,  6.90s/it]Training Epoch: 1/1, step 93/779 completed (loss: 1.1295109987258911, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 94/779 [10:52<1:18:46,  6.90s/it]Training Epoch: 1/1, step 94/779 completed (loss: 1.2185816764831543, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 94/779 [10:52<1:18:46,  6.90s/it]Training Epoch: 1/1, step 94/779 completed (loss: 1.2185816764831543, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 95/779 [10:58<1:18:42,  6.90s/it]Training Epoch: 1/1, step 95/779 completed (loss: 1.2410063743591309, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 95/779 [10:59<1:18:42,  6.90s/it]Training Epoch: 1/1, step 95/779 completed (loss: 1.2410063743591309, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 96/779 [11:05<1:18:37,  6.91s/it]Training Epoch: 1/1, step 96/779 completed (loss: 1.0122137069702148, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 96/779 [11:05<1:18:37,  6.91s/it]Training Epoch: 1/1, step 96/779 completed (loss: 1.0122137069702148, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 97/779 [11:12<1:18:32,  6.91s/it]Training Epoch: 1/1, step 97/779 completed (loss: 0.9265648722648621, lr: 2e-05):  12%|[34mâ–ˆâ–        [0m| 97/779 [11:12<1:18:32,  6.91s/it]Training Epoch: 1/1, step 97/779 completed (loss: 0.9265648722648621, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 98/779 [11:19<1:18:23,  6.91s/it]Training Epoch: 1/1, step 98/779 completed (loss: 1.0296787023544312, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 98/779 [11:19<1:18:23,  6.91s/it]Training Epoch: 1/1, step 98/779 completed (loss: 1.0296787023544312, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 99/779 [11:26<1:18:12,  6.90s/it]Training Epoch: 1/1, step 99/779 completed (loss: 1.084934115409851, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 99/779 [11:26<1:18:12,  6.90s/it] Training Epoch: 1/1, step 99/779 completed (loss: 1.084934115409851, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 100/779 [11:33<1:18:04,  6.90s/it]Training Epoch: 1/1, step 100/779 completed (loss: 1.0142496824264526, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 100/779 [11:33<1:18:04,  6.90s/it]Training Epoch: 1/1, step 100/779 completed (loss: 1.0142496824264526, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 101/779 [11:40<1:17:56,  6.90s/it]Training Epoch: 1/1, step 101/779 completed (loss: 1.133570909500122, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 101/779 [11:40<1:17:56,  6.90s/it] Training Epoch: 1/1, step 101/779 completed (loss: 1.133570909500122, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 102/779 [11:47<1:17:54,  6.90s/it]Training Epoch: 1/1, step 102/779 completed (loss: 0.955259382724762, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 102/779 [11:47<1:17:54,  6.90s/it]Training Epoch: 1/1, step 102/779 completed (loss: 0.955259382724762, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 103/779 [11:54<1:17:50,  6.91s/it]Training Epoch: 1/1, step 103/779 completed (loss: 1.0734484195709229, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 103/779 [11:54<1:17:50,  6.91s/it]Training Epoch: 1/1, step 103/779 completed (loss: 1.0734484195709229, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 104/779 [12:01<1:17:48,  6.92s/it]Training Epoch: 1/1, step 104/779 completed (loss: 0.944142758846283, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 104/779 [12:01<1:17:48,  6.92s/it] Training Epoch: 1/1, step 104/779 completed (loss: 0.944142758846283, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 105/779 [12:08<1:17:43,  6.92s/it]Training Epoch: 1/1, step 105/779 completed (loss: 1.0947964191436768, lr: 2e-05):  13%|[34mâ–ˆâ–Ž        [0m| 105/779 [12:08<1:17:43,  6.92s/it]Training Epoch: 1/1, step 105/779 completed (loss: 1.0947964191436768, lr: 2e-05):  14%|[34mâ–ˆâ–Ž        [0m| 106/779 [12:14<1:17:38,  6.92s/it]Training Epoch: 1/1, step 106/779 completed (loss: 0.9734719395637512, lr: 2e-05):  14%|[34mâ–ˆâ–Ž        [0m| 106/779 [12:15<1:17:38,  6.92s/it]Training Epoch: 1/1, step 106/779 completed (loss: 0.9734719395637512, lr: 2e-05):  14%|[34mâ–ˆâ–Ž        [0m| 107/779 [12:21<1:17:25,  6.91s/it]Training Epoch: 1/1, step 107/779 completed (loss: 0.9752591252326965, lr: 2e-05):  14%|[34mâ–ˆâ–Ž        [0m| 107/779 [12:22<1:17:25,  6.91s/it]Training Epoch: 1/1, step 107/779 completed (loss: 0.9752591252326965, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 108/779 [12:28<1:17:14,  6.91s/it]Training Epoch: 1/1, step 108/779 completed (loss: 1.0377057790756226, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 108/779 [12:28<1:17:14,  6.91s/it]Training Epoch: 1/1, step 108/779 completed (loss: 1.0377057790756226, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 109/779 [12:35<1:17:07,  6.91s/it]Training Epoch: 1/1, step 109/779 completed (loss: 1.031285285949707, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 109/779 [12:35<1:17:07,  6.91s/it] Training Epoch: 1/1, step 109/779 completed (loss: 1.031285285949707, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 110/779 [12:42<1:16:59,  6.90s/it]Training Epoch: 1/1, step 110/779 completed (loss: 1.0731260776519775, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 110/779 [12:42<1:16:59,  6.90s/it]Training Epoch: 1/1, step 110/779 completed (loss: 1.0731260776519775, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 111/779 [12:49<1:16:53,  6.91s/it]Training Epoch: 1/1, step 111/779 completed (loss: 1.0277619361877441, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 111/779 [12:49<1:16:53,  6.91s/it]Training Epoch: 1/1, step 111/779 completed (loss: 1.0277619361877441, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 112/779 [12:56<1:16:49,  6.91s/it]Training Epoch: 1/1, step 112/779 completed (loss: 1.2178198099136353, lr: 2e-05):  14%|[34mâ–ˆâ–        [0m| 112/779 [12:56<1:16:49,  6.91s/it]Training Epoch: 1/1, step 112/779 completed (loss: 1.2178198099136353, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 113/779 [13:03<1:16:43,  6.91s/it]Training Epoch: 1/1, step 113/779 completed (loss: 1.123484492301941, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 113/779 [13:03<1:16:43,  6.91s/it] Training Epoch: 1/1, step 113/779 completed (loss: 1.123484492301941, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 114/779 [13:10<1:16:33,  6.91s/it]Training Epoch: 1/1, step 114/779 completed (loss: 1.1142457723617554, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 114/779 [13:10<1:16:33,  6.91s/it]Training Epoch: 1/1, step 114/779 completed (loss: 1.1142457723617554, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 115/779 [13:17<1:16:27,  6.91s/it]Training Epoch: 1/1, step 115/779 completed (loss: 0.9836903810501099, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 115/779 [13:17<1:16:27,  6.91s/it]Training Epoch: 1/1, step 115/779 completed (loss: 0.9836903810501099, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 116/779 [13:24<1:16:16,  6.90s/it]Training Epoch: 1/1, step 116/779 completed (loss: 1.0448819398880005, lr: 2e-05):  15%|[34mâ–ˆâ–        [0m| 116/779 [13:24<1:16:16,  6.90s/it]Training Epoch: 1/1, step 116/779 completed (loss: 1.0448819398880005, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 117/779 [13:30<1:16:08,  6.90s/it]Training Epoch: 1/1, step 117/779 completed (loss: 1.1209325790405273, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 117/779 [13:31<1:16:08,  6.90s/it]Training Epoch: 1/1, step 117/779 completed (loss: 1.1209325790405273, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 118/779 [13:37<1:16:01,  6.90s/it]Training Epoch: 1/1, step 118/779 completed (loss: 1.0635879039764404, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 118/779 [13:37<1:16:01,  6.90s/it]Training Epoch: 1/1, step 118/779 completed (loss: 1.0635879039764404, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 119/779 [13:44<1:15:53,  6.90s/it]Training Epoch: 1/1, step 119/779 completed (loss: 1.021083950996399, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 119/779 [13:44<1:15:53,  6.90s/it] Training Epoch: 1/1, step 119/779 completed (loss: 1.021083950996399, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 120/779 [13:51<1:15:51,  6.91s/it]Training Epoch: 1/1, step 120/779 completed (loss: 0.9021173715591431, lr: 2e-05):  15%|[34mâ–ˆâ–Œ        [0m| 120/779 [13:51<1:15:51,  6.91s/it]Training Epoch: 1/1, step 120/779 completed (loss: 0.9021173715591431, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 121/779 [13:58<1:15:44,  6.91s/it]Training Epoch: 1/1, step 121/779 completed (loss: 1.0025038719177246, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 121/779 [13:58<1:15:44,  6.91s/it]Training Epoch: 1/1, step 121/779 completed (loss: 1.0025038719177246, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 122/779 [14:05<1:15:36,  6.91s/it]Training Epoch: 1/1, step 122/779 completed (loss: 1.038775086402893, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 122/779 [14:05<1:15:36,  6.91s/it] Training Epoch: 1/1, step 122/779 completed (loss: 1.038775086402893, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 123/779 [14:12<1:15:31,  6.91s/it]Training Epoch: 1/1, step 123/779 completed (loss: 1.2353622913360596, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 123/779 [14:12<1:15:31,  6.91s/it]Training Epoch: 1/1, step 123/779 completed (loss: 1.2353622913360596, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 124/779 [14:19<1:15:23,  6.91s/it]Training Epoch: 1/1, step 124/779 completed (loss: 1.0633667707443237, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 124/779 [14:19<1:15:23,  6.91s/it]Training Epoch: 1/1, step 124/779 completed (loss: 1.0633667707443237, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 125/779 [14:26<1:15:16,  6.91s/it]Training Epoch: 1/1, step 125/779 completed (loss: 1.0762579441070557, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 125/779 [14:26<1:15:16,  6.91s/it]Training Epoch: 1/1, step 125/779 completed (loss: 1.0762579441070557, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 126/779 [14:33<1:15:13,  6.91s/it]Training Epoch: 1/1, step 126/779 completed (loss: 1.2498656511306763, lr: 2e-05):  16%|[34mâ–ˆâ–Œ        [0m| 126/779 [14:33<1:15:13,  6.91s/it]Training Epoch: 1/1, step 126/779 completed (loss: 1.2498656511306763, lr: 2e-05):  16%|[34mâ–ˆâ–‹        [0m| 127/779 [14:39<1:15:03,  6.91s/it]Training Epoch: 1/1, step 127/779 completed (loss: 1.1183032989501953, lr: 2e-05):  16%|[34mâ–ˆâ–‹        [0m| 127/779 [14:40<1:15:03,  6.91s/it]Training Epoch: 1/1, step 127/779 completed (loss: 1.1183032989501953, lr: 2e-05):  16%|[34mâ–ˆâ–‹        [0m| 128/779 [14:46<1:14:54,  6.90s/it]Training Epoch: 1/1, step 128/779 completed (loss: 1.1378861665725708, lr: 2e-05):  16%|[34mâ–ˆâ–‹        [0m| 128/779 [14:47<1:14:54,  6.90s/it]Training Epoch: 1/1, step 128/779 completed (loss: 1.1378861665725708, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 129/779 [14:53<1:14:52,  6.91s/it]Training Epoch: 1/1, step 129/779 completed (loss: 1.1436631679534912, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 129/779 [14:53<1:14:52,  6.91s/it]Training Epoch: 1/1, step 129/779 completed (loss: 1.1436631679534912, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 130/779 [15:00<1:14:48,  6.92s/it]Training Epoch: 1/1, step 130/779 completed (loss: 1.117915153503418, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 130/779 [15:00<1:14:48,  6.92s/it] Training Epoch: 1/1, step 130/779 completed (loss: 1.117915153503418, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 131/779 [15:07<1:14:40,  6.92s/it]Training Epoch: 1/1, step 131/779 completed (loss: 1.0638562440872192, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 131/779 [15:07<1:14:40,  6.92s/it]Training Epoch: 1/1, step 131/779 completed (loss: 1.0638562440872192, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 132/779 [15:14<1:14:30,  6.91s/it]Training Epoch: 1/1, step 132/779 completed (loss: 1.117838740348816, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 132/779 [15:14<1:14:30,  6.91s/it] Training Epoch: 1/1, step 132/779 completed (loss: 1.117838740348816, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 133/779 [15:21<1:14:28,  6.92s/it]Training Epoch: 1/1, step 133/779 completed (loss: 1.2272329330444336, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 133/779 [15:21<1:14:28,  6.92s/it]Training Epoch: 1/1, step 133/779 completed (loss: 1.2272329330444336, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 134/779 [15:28<1:14:20,  6.92s/it]Training Epoch: 1/1, step 134/779 completed (loss: 1.1030409336090088, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 134/779 [15:28<1:14:20,  6.92s/it]Training Epoch: 1/1, step 134/779 completed (loss: 1.1030409336090088, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 135/779 [15:35<1:14:10,  6.91s/it]Training Epoch: 1/1, step 135/779 completed (loss: 1.151220679283142, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 135/779 [15:35<1:14:10,  6.91s/it] Training Epoch: 1/1, step 135/779 completed (loss: 1.151220679283142, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 136/779 [15:42<1:14:01,  6.91s/it]Training Epoch: 1/1, step 136/779 completed (loss: 1.265282392501831, lr: 2e-05):  17%|[34mâ–ˆâ–‹        [0m| 136/779 [15:42<1:14:01,  6.91s/it]Training Epoch: 1/1, step 136/779 completed (loss: 1.265282392501831, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 137/779 [15:49<1:13:52,  6.90s/it]Training Epoch: 1/1, step 137/779 completed (loss: 0.990759551525116, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 137/779 [15:49<1:13:52,  6.90s/it]Training Epoch: 1/1, step 137/779 completed (loss: 0.990759551525116, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 138/779 [15:55<1:13:43,  6.90s/it]Training Epoch: 1/1, step 138/779 completed (loss: 1.1386964321136475, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 138/779 [15:56<1:13:43,  6.90s/it]Training Epoch: 1/1, step 138/779 completed (loss: 1.1386964321136475, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 139/779 [16:02<1:13:41,  6.91s/it]Training Epoch: 1/1, step 139/779 completed (loss: 0.9850776791572571, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 139/779 [16:03<1:13:41,  6.91s/it]Training Epoch: 1/1, step 139/779 completed (loss: 0.9850776791572571, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 140/779 [16:09<1:13:39,  6.92s/it]Training Epoch: 1/1, step 140/779 completed (loss: 0.9988455176353455, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 140/779 [16:09<1:13:39,  6.92s/it]Training Epoch: 1/1, step 140/779 completed (loss: 0.9988455176353455, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 141/779 [16:16<1:13:33,  6.92s/it]Training Epoch: 1/1, step 141/779 completed (loss: 0.9507744312286377, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 141/779 [16:16<1:13:33,  6.92s/it]Training Epoch: 1/1, step 141/779 completed (loss: 0.9507744312286377, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 142/779 [16:23<1:13:25,  6.92s/it]Training Epoch: 1/1, step 142/779 completed (loss: 1.0087316036224365, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 142/779 [16:23<1:13:25,  6.92s/it]Training Epoch: 1/1, step 142/779 completed (loss: 1.0087316036224365, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 143/779 [16:30<1:13:15,  6.91s/it]Training Epoch: 1/1, step 143/779 completed (loss: 1.0096391439437866, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 143/779 [16:30<1:13:15,  6.91s/it]Training Epoch: 1/1, step 143/779 completed (loss: 1.0096391439437866, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 144/779 [16:37<1:13:04,  6.90s/it]Training Epoch: 1/1, step 144/779 completed (loss: 0.9033116698265076, lr: 2e-05):  18%|[34mâ–ˆâ–Š        [0m| 144/779 [16:37<1:13:04,  6.90s/it]Training Epoch: 1/1, step 144/779 completed (loss: 0.9033116698265076, lr: 2e-05):  19%|[34mâ–ˆâ–Š        [0m| 145/779 [16:44<1:12:56,  6.90s/it]Training Epoch: 1/1, step 145/779 completed (loss: 1.0245345830917358, lr: 2e-05):  19%|[34mâ–ˆâ–Š        [0m| 145/779 [16:44<1:12:56,  6.90s/it]Training Epoch: 1/1, step 145/779 completed (loss: 1.0245345830917358, lr: 2e-05):  19%|[34mâ–ˆâ–Š        [0m| 146/779 [16:51<1:12:47,  6.90s/it]Training Epoch: 1/1, step 146/779 completed (loss: 1.0678863525390625, lr: 2e-05):  19%|[34mâ–ˆâ–Š        [0m| 146/779 [16:51<1:12:47,  6.90s/it]Training Epoch: 1/1, step 146/779 completed (loss: 1.0678863525390625, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 147/779 [16:58<1:12:42,  6.90s/it]Training Epoch: 1/1, step 147/779 completed (loss: 1.1085883378982544, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 147/779 [16:58<1:12:42,  6.90s/it]Training Epoch: 1/1, step 147/779 completed (loss: 1.1085883378982544, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 148/779 [17:05<1:12:38,  6.91s/it]Training Epoch: 1/1, step 148/779 completed (loss: 1.0628501176834106, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 148/779 [17:05<1:12:38,  6.91s/it]Training Epoch: 1/1, step 148/779 completed (loss: 1.0628501176834106, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 149/779 [17:11<1:12:30,  6.91s/it]Training Epoch: 1/1, step 149/779 completed (loss: 1.0571190118789673, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 149/779 [17:12<1:12:30,  6.91s/it]Training Epoch: 1/1, step 149/779 completed (loss: 1.0571190118789673, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 150/779 [17:18<1:12:24,  6.91s/it]Training Epoch: 1/1, step 150/779 completed (loss: 1.0696007013320923, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 150/779 [17:19<1:12:24,  6.91s/it]Training Epoch: 1/1, step 150/779 completed (loss: 1.0696007013320923, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 151/779 [17:25<1:12:17,  6.91s/it]Training Epoch: 1/1, step 151/779 completed (loss: 1.0043715238571167, lr: 2e-05):  19%|[34mâ–ˆâ–‰        [0m| 151/779 [17:25<1:12:17,  6.91s/it]Training Epoch: 1/1, step 151/779 completed (loss: 1.0043715238571167, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 152/779 [17:32<1:12:11,  6.91s/it]Training Epoch: 1/1, step 152/779 completed (loss: 1.0494664907455444, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 152/779 [17:32<1:12:11,  6.91s/it]Training Epoch: 1/1, step 152/779 completed (loss: 1.0494664907455444, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 153/779 [17:39<1:12:02,  6.90s/it]Training Epoch: 1/1, step 153/779 completed (loss: 1.036259412765503, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 153/779 [17:39<1:12:02,  6.90s/it] Training Epoch: 1/1, step 153/779 completed (loss: 1.036259412765503, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 154/779 [17:46<1:11:54,  6.90s/it]Training Epoch: 1/1, step 154/779 completed (loss: 1.0005605220794678, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 154/779 [17:46<1:11:54,  6.90s/it]Training Epoch: 1/1, step 154/779 completed (loss: 1.0005605220794678, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 155/779 [17:53<1:11:47,  6.90s/it]Training Epoch: 1/1, step 155/779 completed (loss: 1.1531493663787842, lr: 2e-05):  20%|[34mâ–ˆâ–‰        [0m| 155/779 [17:53<1:11:47,  6.90s/it]Training Epoch: 1/1, step 155/779 completed (loss: 1.1531493663787842, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 156/779 [18:00<1:11:38,  6.90s/it]Training Epoch: 1/1, step 156/779 completed (loss: 0.9772876501083374, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 156/779 [18:00<1:11:38,  6.90s/it]Training Epoch: 1/1, step 156/779 completed (loss: 0.9772876501083374, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 157/779 [18:07<1:11:28,  6.90s/it]Training Epoch: 1/1, step 157/779 completed (loss: 1.0771459341049194, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 157/779 [18:07<1:11:28,  6.90s/it]Training Epoch: 1/1, step 157/779 completed (loss: 1.0771459341049194, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 158/779 [18:14<1:11:26,  6.90s/it]Training Epoch: 1/1, step 158/779 completed (loss: 1.0554726123809814, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 158/779 [18:14<1:11:26,  6.90s/it]Training Epoch: 1/1, step 158/779 completed (loss: 1.0554726123809814, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 159/779 [18:20<1:11:17,  6.90s/it]Training Epoch: 1/1, step 159/779 completed (loss: 0.836044192314148, lr: 2e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 159/779 [18:21<1:11:17,  6.90s/it] Training Epoch: 1/1, step 159/779 completed (loss: 0.836044192314148, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 160/779 [18:27<1:11:10,  6.90s/it]Training Epoch: 1/1, step 160/779 completed (loss: 1.1875752210617065, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 160/779 [18:28<1:11:10,  6.90s/it]Training Epoch: 1/1, step 160/779 completed (loss: 1.1875752210617065, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 161/779 [18:34<1:11:05,  6.90s/it]Training Epoch: 1/1, step 161/779 completed (loss: 1.0602798461914062, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 161/779 [18:34<1:11:05,  6.90s/it]Training Epoch: 1/1, step 161/779 completed (loss: 1.0602798461914062, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 162/779 [18:41<1:10:56,  6.90s/it]Training Epoch: 1/1, step 162/779 completed (loss: 1.1277724504470825, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 162/779 [18:41<1:10:56,  6.90s/it]Training Epoch: 1/1, step 162/779 completed (loss: 1.1277724504470825, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 163/779 [18:48<1:10:50,  6.90s/it]Training Epoch: 1/1, step 163/779 completed (loss: 1.1349784135818481, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 163/779 [18:48<1:10:50,  6.90s/it]Training Epoch: 1/1, step 163/779 completed (loss: 1.1349784135818481, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 164/779 [18:55<1:10:44,  6.90s/it]Training Epoch: 1/1, step 164/779 completed (loss: 1.024433970451355, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 164/779 [18:55<1:10:44,  6.90s/it] Training Epoch: 1/1, step 164/779 completed (loss: 1.024433970451355, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 165/779 [19:02<1:10:38,  6.90s/it]Training Epoch: 1/1, step 165/779 completed (loss: 1.1596887111663818, lr: 2e-05):  21%|[34mâ–ˆâ–ˆ        [0m| 165/779 [19:02<1:10:38,  6.90s/it]Training Epoch: 1/1, step 165/779 completed (loss: 1.1596887111663818, lr: 2e-05):  21%|[34mâ–ˆâ–ˆâ–       [0m| 166/779 [19:09<1:10:32,  6.91s/it]Training Epoch: 1/1, step 166/779 completed (loss: 1.0141600370407104, lr: 2e-05):  21%|[34mâ–ˆâ–ˆâ–       [0m| 166/779 [19:09<1:10:32,  6.91s/it]Training Epoch: 1/1, step 166/779 completed (loss: 1.0141600370407104, lr: 2e-05):  21%|[34mâ–ˆâ–ˆâ–       [0m| 167/779 [19:16<1:10:31,  6.91s/it]Training Epoch: 1/1, step 167/779 completed (loss: 1.2761876583099365, lr: 2e-05):  21%|[34mâ–ˆâ–ˆâ–       [0m| 167/779 [19:16<1:10:31,  6.91s/it]Training Epoch: 1/1, step 167/779 completed (loss: 1.2761876583099365, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 168/779 [19:23<1:10:23,  6.91s/it]Training Epoch: 1/1, step 168/779 completed (loss: 1.1016948223114014, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 168/779 [19:23<1:10:23,  6.91s/it]Training Epoch: 1/1, step 168/779 completed (loss: 1.1016948223114014, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 169/779 [19:30<1:10:17,  6.91s/it]Training Epoch: 1/1, step 169/779 completed (loss: 1.1260567903518677, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 169/779 [19:30<1:10:17,  6.91s/it]Training Epoch: 1/1, step 169/779 completed (loss: 1.1260567903518677, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 170/779 [19:36<1:10:07,  6.91s/it]Training Epoch: 1/1, step 170/779 completed (loss: 1.0983508825302124, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 170/779 [19:37<1:10:07,  6.91s/it]Training Epoch: 1/1, step 170/779 completed (loss: 1.0983508825302124, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 171/779 [19:43<1:10:08,  6.92s/it]Training Epoch: 1/1, step 171/779 completed (loss: 1.166129231452942, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 171/779 [19:44<1:10:08,  6.92s/it] Training Epoch: 1/1, step 171/779 completed (loss: 1.166129231452942, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 172/779 [19:50<1:09:58,  6.92s/it]Training Epoch: 1/1, step 172/779 completed (loss: 1.126844048500061, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 172/779 [19:50<1:09:58,  6.92s/it]Training Epoch: 1/1, step 172/779 completed (loss: 1.126844048500061, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 173/779 [19:57<1:09:47,  6.91s/it]Training Epoch: 1/1, step 173/779 completed (loss: 1.2471518516540527, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 173/779 [19:57<1:09:47,  6.91s/it]Training Epoch: 1/1, step 173/779 completed (loss: 1.2471518516540527, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 174/779 [20:04<1:09:43,  6.91s/it]Training Epoch: 1/1, step 174/779 completed (loss: 0.9581426382064819, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 174/779 [20:04<1:09:43,  6.91s/it]Training Epoch: 1/1, step 174/779 completed (loss: 0.9581426382064819, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 175/779 [20:11<1:09:34,  6.91s/it]Training Epoch: 1/1, step 175/779 completed (loss: 1.0769712924957275, lr: 2e-05):  22%|[34mâ–ˆâ–ˆâ–       [0m| 175/779 [20:11<1:09:34,  6.91s/it]Training Epoch: 1/1, step 175/779 completed (loss: 1.0769712924957275, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 176/779 [20:18<1:09:27,  6.91s/it]Training Epoch: 1/1, step 176/779 completed (loss: 1.1819387674331665, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 176/779 [20:18<1:09:27,  6.91s/it]Training Epoch: 1/1, step 176/779 completed (loss: 1.1819387674331665, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 177/779 [20:25<1:09:17,  6.91s/it]Training Epoch: 1/1, step 177/779 completed (loss: 0.8903241157531738, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 177/779 [20:25<1:09:17,  6.91s/it]Training Epoch: 1/1, step 177/779 completed (loss: 0.8903241157531738, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 178/779 [20:32<1:09:09,  6.91s/it]Training Epoch: 1/1, step 178/779 completed (loss: 0.9975045919418335, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 178/779 [20:32<1:09:09,  6.91s/it]Training Epoch: 1/1, step 178/779 completed (loss: 0.9975045919418335, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 179/779 [20:39<1:08:59,  6.90s/it]Training Epoch: 1/1, step 179/779 completed (loss: 1.1808909177780151, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 179/779 [20:39<1:08:59,  6.90s/it]Training Epoch: 1/1, step 179/779 completed (loss: 1.1808909177780151, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 180/779 [20:46<1:08:51,  6.90s/it]Training Epoch: 1/1, step 180/779 completed (loss: 1.0719406604766846, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 180/779 [20:46<1:08:51,  6.90s/it]Training Epoch: 1/1, step 180/779 completed (loss: 1.0719406604766846, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 181/779 [20:52<1:08:46,  6.90s/it]Training Epoch: 1/1, step 181/779 completed (loss: 1.2066326141357422, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 181/779 [20:53<1:08:46,  6.90s/it]Training Epoch: 1/1, step 181/779 completed (loss: 1.2066326141357422, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 182/779 [20:59<1:08:42,  6.91s/it]Training Epoch: 1/1, step 182/779 completed (loss: 0.9604456424713135, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 182/779 [20:59<1:08:42,  6.91s/it]Training Epoch: 1/1, step 182/779 completed (loss: 0.9604456424713135, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 183/779 [21:06<1:08:35,  6.91s/it]Training Epoch: 1/1, step 183/779 completed (loss: 0.8754860758781433, lr: 2e-05):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 183/779 [21:06<1:08:35,  6.91s/it]Training Epoch: 1/1, step 183/779 completed (loss: 0.8754860758781433, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–Ž       [0m| 184/779 [21:13<1:08:27,  6.90s/it]Training Epoch: 1/1, step 184/779 completed (loss: 0.9723795652389526, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–Ž       [0m| 184/779 [21:13<1:08:27,  6.90s/it]Training Epoch: 1/1, step 184/779 completed (loss: 0.9723795652389526, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–Ž       [0m| 185/779 [21:20<1:08:18,  6.90s/it]Training Epoch: 1/1, step 185/779 completed (loss: 1.0919404029846191, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–Ž       [0m| 185/779 [21:20<1:08:18,  6.90s/it]Training Epoch: 1/1, step 185/779 completed (loss: 1.0919404029846191, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 186/779 [21:27<1:08:11,  6.90s/it]Training Epoch: 1/1, step 186/779 completed (loss: 1.0816303491592407, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 186/779 [21:27<1:08:11,  6.90s/it]Training Epoch: 1/1, step 186/779 completed (loss: 1.0816303491592407, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 187/779 [21:34<1:08:04,  6.90s/it]Training Epoch: 1/1, step 187/779 completed (loss: 1.1388005018234253, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 187/779 [21:34<1:08:04,  6.90s/it]Training Epoch: 1/1, step 187/779 completed (loss: 1.1388005018234253, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 188/779 [21:41<1:08:01,  6.91s/it]Training Epoch: 1/1, step 188/779 completed (loss: 1.0630615949630737, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 188/779 [21:41<1:08:01,  6.91s/it]Training Epoch: 1/1, step 188/779 completed (loss: 1.0630615949630737, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 189/779 [21:48<1:07:56,  6.91s/it]Training Epoch: 1/1, step 189/779 completed (loss: 1.2044849395751953, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 189/779 [21:48<1:07:56,  6.91s/it]Training Epoch: 1/1, step 189/779 completed (loss: 1.2044849395751953, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 190/779 [21:55<1:07:44,  6.90s/it]Training Epoch: 1/1, step 190/779 completed (loss: 0.9997683763504028, lr: 2e-05):  24%|[34mâ–ˆâ–ˆâ–       [0m| 190/779 [21:55<1:07:44,  6.90s/it]Training Epoch: 1/1, step 190/779 completed (loss: 0.9997683763504028, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 191/779 [22:01<1:07:35,  6.90s/it]Training Epoch: 1/1, step 191/779 completed (loss: 1.126502513885498, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 191/779 [22:02<1:07:35,  6.90s/it] Training Epoch: 1/1, step 191/779 completed (loss: 1.126502513885498, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 192/779 [22:08<1:07:28,  6.90s/it]Training Epoch: 1/1, step 192/779 completed (loss: 1.0001827478408813, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 192/779 [22:08<1:07:28,  6.90s/it]Training Epoch: 1/1, step 192/779 completed (loss: 1.0001827478408813, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 193/779 [22:15<1:07:20,  6.90s/it]Training Epoch: 1/1, step 193/779 completed (loss: 0.9481173157691956, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 193/779 [22:15<1:07:20,  6.90s/it]Training Epoch: 1/1, step 193/779 completed (loss: 0.9481173157691956, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 194/779 [22:22<1:07:15,  6.90s/it]Training Epoch: 1/1, step 194/779 completed (loss: 1.0593442916870117, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–       [0m| 194/779 [22:22<1:07:15,  6.90s/it]Training Epoch: 1/1, step 194/779 completed (loss: 1.0593442916870117, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 195/779 [22:29<1:07:08,  6.90s/it]Training Epoch: 1/1, step 195/779 completed (loss: 0.9786718487739563, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 195/779 [22:29<1:07:08,  6.90s/it]Training Epoch: 1/1, step 195/779 completed (loss: 0.9786718487739563, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 196/779 [22:36<1:07:01,  6.90s/it]Training Epoch: 1/1, step 196/779 completed (loss: 1.1588125228881836, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 196/779 [22:36<1:07:01,  6.90s/it]Training Epoch: 1/1, step 196/779 completed (loss: 1.1588125228881836, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 197/779 [22:43<1:06:56,  6.90s/it]Training Epoch: 1/1, step 197/779 completed (loss: 1.0294572114944458, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 197/779 [22:43<1:06:56,  6.90s/it]Training Epoch: 1/1, step 197/779 completed (loss: 1.0294572114944458, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 198/779 [22:50<1:06:47,  6.90s/it]Training Epoch: 1/1, step 198/779 completed (loss: 1.0212458372116089, lr: 2e-05):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 198/779 [22:50<1:06:47,  6.90s/it]Training Epoch: 1/1, step 198/779 completed (loss: 1.0212458372116089, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 199/779 [22:57<1:06:41,  6.90s/it]Training Epoch: 1/1, step 199/779 completed (loss: 0.9432812929153442, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 199/779 [22:57<1:06:41,  6.90s/it]Training Epoch: 1/1, step 199/779 completed (loss: 0.9432812929153442, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 200/779 [23:04<1:06:31,  6.89s/it]Training Epoch: 1/1, step 200/779 completed (loss: 0.9749721884727478, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 200/779 [23:04<1:06:31,  6.89s/it]Training Epoch: 1/1, step 200/779 completed (loss: 0.9749721884727478, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 201/779 [23:10<1:06:23,  6.89s/it]Training Epoch: 1/1, step 201/779 completed (loss: 1.0431171655654907, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 201/779 [23:11<1:06:23,  6.89s/it]Training Epoch: 1/1, step 201/779 completed (loss: 1.0431171655654907, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 202/779 [23:17<1:06:21,  6.90s/it]Training Epoch: 1/1, step 202/779 completed (loss: 1.105792760848999, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 202/779 [23:17<1:06:21,  6.90s/it] Training Epoch: 1/1, step 202/779 completed (loss: 1.105792760848999, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 203/779 [23:24<1:06:12,  6.90s/it]Training Epoch: 1/1, step 203/779 completed (loss: 1.0297621488571167, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 203/779 [23:24<1:06:12,  6.90s/it]Training Epoch: 1/1, step 203/779 completed (loss: 1.0297621488571167, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 204/779 [23:31<1:06:05,  6.90s/it]Training Epoch: 1/1, step 204/779 completed (loss: 1.047119379043579, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 204/779 [23:31<1:06:05,  6.90s/it] Training Epoch: 1/1, step 204/779 completed (loss: 1.047119379043579, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 205/779 [23:38<1:05:54,  6.89s/it]Training Epoch: 1/1, step 205/779 completed (loss: 1.0752538442611694, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 205/779 [23:38<1:05:54,  6.89s/it]Training Epoch: 1/1, step 205/779 completed (loss: 1.0752538442611694, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 206/779 [23:45<1:05:52,  6.90s/it]Training Epoch: 1/1, step 206/779 completed (loss: 1.0160709619522095, lr: 2e-05):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 206/779 [23:45<1:05:52,  6.90s/it]Training Epoch: 1/1, step 206/779 completed (loss: 1.0160709619522095, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 207/779 [23:52<1:05:46,  6.90s/it]Training Epoch: 1/1, step 207/779 completed (loss: 1.0377970933914185, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 207/779 [23:52<1:05:46,  6.90s/it]Training Epoch: 1/1, step 207/779 completed (loss: 1.0377970933914185, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 208/779 [23:59<1:05:41,  6.90s/it]Training Epoch: 1/1, step 208/779 completed (loss: 1.0602740049362183, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 208/779 [23:59<1:05:41,  6.90s/it]Training Epoch: 1/1, step 208/779 completed (loss: 1.0602740049362183, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 209/779 [24:06<1:05:37,  6.91s/it]Training Epoch: 1/1, step 209/779 completed (loss: 0.9960428476333618, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 209/779 [24:06<1:05:37,  6.91s/it]Training Epoch: 1/1, step 209/779 completed (loss: 0.9960428476333618, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 210/779 [24:13<1:05:28,  6.90s/it]Training Epoch: 1/1, step 210/779 completed (loss: 1.024901032447815, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 210/779 [24:13<1:05:28,  6.90s/it] Training Epoch: 1/1, step 210/779 completed (loss: 1.024901032447815, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 211/779 [24:19<1:05:23,  6.91s/it]Training Epoch: 1/1, step 211/779 completed (loss: 1.0205637216567993, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 211/779 [24:20<1:05:23,  6.91s/it]Training Epoch: 1/1, step 211/779 completed (loss: 1.0205637216567993, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 212/779 [24:26<1:05:16,  6.91s/it]Training Epoch: 1/1, step 212/779 completed (loss: 1.0754876136779785, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 212/779 [24:27<1:05:16,  6.91s/it]Training Epoch: 1/1, step 212/779 completed (loss: 1.0754876136779785, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 213/779 [24:33<1:05:11,  6.91s/it]Training Epoch: 1/1, step 213/779 completed (loss: 1.0268720388412476, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 213/779 [24:33<1:05:11,  6.91s/it]Training Epoch: 1/1, step 213/779 completed (loss: 1.0268720388412476, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 214/779 [24:40<1:05:04,  6.91s/it]Training Epoch: 1/1, step 214/779 completed (loss: 1.0311689376831055, lr: 2e-05):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 214/779 [24:40<1:05:04,  6.91s/it]Training Epoch: 1/1, step 214/779 completed (loss: 1.0311689376831055, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 215/779 [24:47<1:04:55,  6.91s/it]Training Epoch: 1/1, step 215/779 completed (loss: 1.0977485179901123, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 215/779 [24:47<1:04:55,  6.91s/it]Training Epoch: 1/1, step 215/779 completed (loss: 1.0977485179901123, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 216/779 [24:54<1:04:46,  6.90s/it]Training Epoch: 1/1, step 216/779 completed (loss: 0.9823352098464966, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 216/779 [24:54<1:04:46,  6.90s/it]Training Epoch: 1/1, step 216/779 completed (loss: 0.9823352098464966, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 217/779 [25:01<1:04:42,  6.91s/it]Training Epoch: 1/1, step 217/779 completed (loss: 1.040781855583191, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 217/779 [25:01<1:04:42,  6.91s/it] Training Epoch: 1/1, step 217/779 completed (loss: 1.040781855583191, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 218/779 [25:08<1:04:33,  6.90s/it]Training Epoch: 1/1, step 218/779 completed (loss: 1.0991053581237793, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 218/779 [25:08<1:04:33,  6.90s/it]Training Epoch: 1/1, step 218/779 completed (loss: 1.0991053581237793, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 219/779 [25:15<1:04:26,  6.90s/it]Training Epoch: 1/1, step 219/779 completed (loss: 0.9580870866775513, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 219/779 [25:15<1:04:26,  6.90s/it]Training Epoch: 1/1, step 219/779 completed (loss: 0.9580870866775513, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 220/779 [25:22<1:04:18,  6.90s/it]Training Epoch: 1/1, step 220/779 completed (loss: 1.043555498123169, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 220/779 [25:22<1:04:18,  6.90s/it] Training Epoch: 1/1, step 220/779 completed (loss: 1.043555498123169, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 221/779 [25:29<1:04:15,  6.91s/it]Training Epoch: 1/1, step 221/779 completed (loss: 0.9949088096618652, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 221/779 [25:29<1:04:15,  6.91s/it]Training Epoch: 1/1, step 221/779 completed (loss: 0.9949088096618652, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 222/779 [25:35<1:04:07,  6.91s/it]Training Epoch: 1/1, step 222/779 completed (loss: 1.200600266456604, lr: 2e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 222/779 [25:36<1:04:07,  6.91s/it] Training Epoch: 1/1, step 222/779 completed (loss: 1.200600266456604, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 223/779 [25:42<1:04:02,  6.91s/it]Training Epoch: 1/1, step 223/779 completed (loss: 1.094286561012268, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 223/779 [25:42<1:04:02,  6.91s/it]Training Epoch: 1/1, step 223/779 completed (loss: 1.094286561012268, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 224/779 [25:49<1:03:56,  6.91s/it]Training Epoch: 1/1, step 224/779 completed (loss: 0.9923588037490845, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 224/779 [25:49<1:03:56,  6.91s/it]Training Epoch: 1/1, step 224/779 completed (loss: 0.9923588037490845, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 225/779 [25:56<1:03:47,  6.91s/it]Training Epoch: 1/1, step 225/779 completed (loss: 1.2079249620437622, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 225/779 [25:56<1:03:47,  6.91s/it]Training Epoch: 1/1, step 225/779 completed (loss: 1.2079249620437622, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 226/779 [26:03<1:03:39,  6.91s/it]Training Epoch: 1/1, step 226/779 completed (loss: 1.0086932182312012, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 226/779 [26:03<1:03:39,  6.91s/it]Training Epoch: 1/1, step 226/779 completed (loss: 1.0086932182312012, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 227/779 [26:10<1:03:29,  6.90s/it]Training Epoch: 1/1, step 227/779 completed (loss: 1.155287504196167, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 227/779 [26:10<1:03:29,  6.90s/it] Training Epoch: 1/1, step 227/779 completed (loss: 1.155287504196167, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 228/779 [26:17<1:03:22,  6.90s/it]Training Epoch: 1/1, step 228/779 completed (loss: 1.2173855304718018, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 228/779 [26:17<1:03:22,  6.90s/it]Training Epoch: 1/1, step 228/779 completed (loss: 1.2173855304718018, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 229/779 [26:24<1:03:17,  6.90s/it]Training Epoch: 1/1, step 229/779 completed (loss: 1.0909725427627563, lr: 2e-05):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 229/779 [26:24<1:03:17,  6.90s/it]Training Epoch: 1/1, step 229/779 completed (loss: 1.0909725427627563, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 230/779 [26:31<1:03:13,  6.91s/it]Training Epoch: 1/1, step 230/779 completed (loss: 1.130932092666626, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 230/779 [26:31<1:03:13,  6.91s/it] Training Epoch: 1/1, step 230/779 completed (loss: 1.130932092666626, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 231/779 [26:38<1:03:07,  6.91s/it]Training Epoch: 1/1, step 231/779 completed (loss: 1.1232911348342896, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 231/779 [26:38<1:03:07,  6.91s/it]Training Epoch: 1/1, step 231/779 completed (loss: 1.1232911348342896, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 232/779 [26:45<1:03:02,  6.92s/it]Training Epoch: 1/1, step 232/779 completed (loss: 1.0863181352615356, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 232/779 [26:45<1:03:02,  6.92s/it]Training Epoch: 1/1, step 232/779 completed (loss: 1.0863181352615356, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 233/779 [26:51<1:02:55,  6.91s/it]Training Epoch: 1/1, step 233/779 completed (loss: 1.0309152603149414, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 233/779 [26:52<1:02:55,  6.91s/it]Training Epoch: 1/1, step 233/779 completed (loss: 1.0309152603149414, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 234/779 [26:58<1:02:47,  6.91s/it]Training Epoch: 1/1, step 234/779 completed (loss: 1.0220023393630981, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 234/779 [26:58<1:02:47,  6.91s/it]Training Epoch: 1/1, step 234/779 completed (loss: 1.0220023393630981, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 235/779 [27:05<1:02:38,  6.91s/it]Training Epoch: 1/1, step 235/779 completed (loss: 0.9949668049812317, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 235/779 [27:05<1:02:38,  6.91s/it]Training Epoch: 1/1, step 235/779 completed (loss: 0.9949668049812317, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 236/779 [27:12<1:02:34,  6.91s/it]Training Epoch: 1/1, step 236/779 completed (loss: 1.1461169719696045, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 236/779 [27:12<1:02:34,  6.91s/it]Training Epoch: 1/1, step 236/779 completed (loss: 1.1461169719696045, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 237/779 [27:19<1:02:29,  6.92s/it]Training Epoch: 1/1, step 237/779 completed (loss: 1.1482151746749878, lr: 2e-05):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 237/779 [27:19<1:02:29,  6.92s/it]Training Epoch: 1/1, step 237/779 completed (loss: 1.1482151746749878, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 238/779 [27:26<1:02:26,  6.92s/it]Training Epoch: 1/1, step 238/779 completed (loss: 0.8424893617630005, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 238/779 [27:26<1:02:26,  6.92s/it]Training Epoch: 1/1, step 238/779 completed (loss: 0.8424893617630005, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 239/779 [27:33<1:02:20,  6.93s/it]Training Epoch: 1/1, step 239/779 completed (loss: 0.9703292846679688, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 239/779 [27:33<1:02:20,  6.93s/it]Training Epoch: 1/1, step 239/779 completed (loss: 0.9703292846679688, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 240/779 [27:40<1:02:17,  6.93s/it]Training Epoch: 1/1, step 240/779 completed (loss: 0.8995893597602844, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 240/779 [27:40<1:02:17,  6.93s/it]Training Epoch: 1/1, step 240/779 completed (loss: 0.8995893597602844, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 241/779 [27:47<1:02:06,  6.93s/it]Training Epoch: 1/1, step 241/779 completed (loss: 1.081324577331543, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 241/779 [27:47<1:02:06,  6.93s/it] Training Epoch: 1/1, step 241/779 completed (loss: 1.081324577331543, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 242/779 [27:54<1:02:02,  6.93s/it]Training Epoch: 1/1, step 242/779 completed (loss: 1.1598156690597534, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 242/779 [27:54<1:02:02,  6.93s/it]Training Epoch: 1/1, step 242/779 completed (loss: 1.1598156690597534, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 243/779 [28:01<1:01:54,  6.93s/it]Training Epoch: 1/1, step 243/779 completed (loss: 1.1082403659820557, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 243/779 [28:01<1:01:54,  6.93s/it]Training Epoch: 1/1, step 243/779 completed (loss: 1.1082403659820557, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 244/779 [28:08<1:01:45,  6.93s/it]Training Epoch: 1/1, step 244/779 completed (loss: 1.1019333600997925, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 244/779 [28:08<1:01:45,  6.93s/it]Training Epoch: 1/1, step 244/779 completed (loss: 1.1019333600997925, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 245/779 [28:15<1:01:37,  6.92s/it]Training Epoch: 1/1, step 245/779 completed (loss: 0.9937625527381897, lr: 2e-05):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 245/779 [28:15<1:01:37,  6.92s/it]Training Epoch: 1/1, step 245/779 completed (loss: 0.9937625527381897, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 246/779 [28:22<1:01:34,  6.93s/it]Training Epoch: 1/1, step 246/779 completed (loss: 0.9394897818565369, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 246/779 [28:22<1:01:34,  6.93s/it]Training Epoch: 1/1, step 246/779 completed (loss: 0.9394897818565369, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 247/779 [28:28<1:01:26,  6.93s/it]Training Epoch: 1/1, step 247/779 completed (loss: 1.053041696548462, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 247/779 [28:29<1:01:26,  6.93s/it] Training Epoch: 1/1, step 247/779 completed (loss: 1.053041696548462, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 248/779 [28:35<1:01:21,  6.93s/it]Training Epoch: 1/1, step 248/779 completed (loss: 1.1024523973464966, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 248/779 [28:36<1:01:21,  6.93s/it]Training Epoch: 1/1, step 248/779 completed (loss: 1.1024523973464966, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 249/779 [28:42<1:01:13,  6.93s/it]Training Epoch: 1/1, step 249/779 completed (loss: 1.0408991575241089, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 249/779 [28:42<1:01:13,  6.93s/it]Training Epoch: 1/1, step 249/779 completed (loss: 1.0408991575241089, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 250/779 [28:49<1:01:05,  6.93s/it]Training Epoch: 1/1, step 250/779 completed (loss: 0.9910412430763245, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 250/779 [28:49<1:01:05,  6.93s/it]Training Epoch: 1/1, step 250/779 completed (loss: 0.9910412430763245, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 251/779 [28:56<1:00:59,  6.93s/it]Training Epoch: 1/1, step 251/779 completed (loss: 1.0391961336135864, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 251/779 [28:56<1:00:59,  6.93s/it]Training Epoch: 1/1, step 251/779 completed (loss: 1.0391961336135864, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 252/779 [29:03<1:00:46,  6.92s/it]Training Epoch: 1/1, step 252/779 completed (loss: 1.0435420274734497, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 252/779 [29:03<1:00:46,  6.92s/it]Training Epoch: 1/1, step 252/779 completed (loss: 1.0435420274734497, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 253/779 [29:10<1:00:42,  6.92s/it]Training Epoch: 1/1, step 253/779 completed (loss: 0.9123031497001648, lr: 2e-05):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 253/779 [29:10<1:00:42,  6.92s/it]Training Epoch: 1/1, step 253/779 completed (loss: 0.9123031497001648, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 254/779 [29:17<1:00:35,  6.93s/it]Training Epoch: 1/1, step 254/779 completed (loss: 0.9728019833564758, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 254/779 [29:17<1:00:35,  6.93s/it]Training Epoch: 1/1, step 254/779 completed (loss: 0.9728019833564758, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 255/779 [29:24<1:00:27,  6.92s/it]Training Epoch: 1/1, step 255/779 completed (loss: 1.0272771120071411, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 255/779 [29:24<1:00:27,  6.92s/it]Training Epoch: 1/1, step 255/779 completed (loss: 1.0272771120071411, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 256/779 [29:31<1:00:20,  6.92s/it]Training Epoch: 1/1, step 256/779 completed (loss: 1.1163586378097534, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 256/779 [29:31<1:00:20,  6.92s/it]Training Epoch: 1/1, step 256/779 completed (loss: 1.1163586378097534, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 257/779 [29:38<1:00:08,  6.91s/it]Training Epoch: 1/1, step 257/779 completed (loss: 1.0106596946716309, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 257/779 [29:38<1:00:08,  6.91s/it]Training Epoch: 1/1, step 257/779 completed (loss: 1.0106596946716309, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 258/779 [29:45<1:00:03,  6.92s/it]Training Epoch: 1/1, step 258/779 completed (loss: 0.9035096764564514, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 258/779 [29:45<1:00:03,  6.92s/it]Training Epoch: 1/1, step 258/779 completed (loss: 0.9035096764564514, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 259/779 [29:51<59:53,  6.91s/it]  Training Epoch: 1/1, step 259/779 completed (loss: 0.9876020550727844, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 259/779 [29:52<59:53,  6.91s/it]Training Epoch: 1/1, step 259/779 completed (loss: 0.9876020550727844, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 260/779 [29:58<59:44,  6.91s/it]Training Epoch: 1/1, step 260/779 completed (loss: 1.1088167428970337, lr: 2e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 260/779 [29:58<59:44,  6.91s/it]Training Epoch: 1/1, step 260/779 completed (loss: 1.1088167428970337, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 261/779 [30:05<59:36,  6.90s/it]Training Epoch: 1/1, step 261/779 completed (loss: 1.0210729837417603, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 261/779 [30:05<59:36,  6.90s/it]Training Epoch: 1/1, step 261/779 completed (loss: 1.0210729837417603, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 262/779 [30:12<59:30,  6.91s/it]Training Epoch: 1/1, step 262/779 completed (loss: 1.0848829746246338, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 262/779 [30:12<59:30,  6.91s/it]Training Epoch: 1/1, step 262/779 completed (loss: 1.0848829746246338, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 263/779 [30:19<59:25,  6.91s/it]Training Epoch: 1/1, step 263/779 completed (loss: 1.011894941329956, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 263/779 [30:19<59:25,  6.91s/it] Training Epoch: 1/1, step 263/779 completed (loss: 1.011894941329956, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 264/779 [30:26<59:20,  6.91s/it]Training Epoch: 1/1, step 264/779 completed (loss: 1.069061517715454, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 264/779 [30:26<59:20,  6.91s/it]Training Epoch: 1/1, step 264/779 completed (loss: 1.069061517715454, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 265/779 [30:33<59:13,  6.91s/it]Training Epoch: 1/1, step 265/779 completed (loss: 1.0740782022476196, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 265/779 [30:33<59:13,  6.91s/it]Training Epoch: 1/1, step 265/779 completed (loss: 1.0740782022476196, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 266/779 [30:40<59:10,  6.92s/it]Training Epoch: 1/1, step 266/779 completed (loss: 1.1032403707504272, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 266/779 [30:40<59:10,  6.92s/it]Training Epoch: 1/1, step 266/779 completed (loss: 1.1032403707504272, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 267/779 [30:47<59:00,  6.91s/it]Training Epoch: 1/1, step 267/779 completed (loss: 1.1066815853118896, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 267/779 [30:47<59:00,  6.91s/it]Training Epoch: 1/1, step 267/779 completed (loss: 1.1066815853118896, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 268/779 [30:54<58:56,  6.92s/it]Training Epoch: 1/1, step 268/779 completed (loss: 1.0964411497116089, lr: 2e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 268/779 [30:54<58:56,  6.92s/it]Training Epoch: 1/1, step 268/779 completed (loss: 1.0964411497116089, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 269/779 [31:01<58:50,  6.92s/it]Training Epoch: 1/1, step 269/779 completed (loss: 1.002176284790039, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 269/779 [31:01<58:50,  6.92s/it] Training Epoch: 1/1, step 269/779 completed (loss: 1.002176284790039, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 270/779 [31:08<58:44,  6.92s/it]Training Epoch: 1/1, step 270/779 completed (loss: 1.084573745727539, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 270/779 [31:08<58:44,  6.92s/it]Training Epoch: 1/1, step 270/779 completed (loss: 1.084573745727539, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 271/779 [31:14<58:36,  6.92s/it]Training Epoch: 1/1, step 271/779 completed (loss: 0.9595927596092224, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 271/779 [31:15<58:36,  6.92s/it]Training Epoch: 1/1, step 271/779 completed (loss: 0.9595927596092224, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 272/779 [31:21<58:27,  6.92s/it]Training Epoch: 1/1, step 272/779 completed (loss: 0.8923539519309998, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 272/779 [31:22<58:27,  6.92s/it]Training Epoch: 1/1, step 272/779 completed (loss: 0.8923539519309998, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 273/779 [31:28<58:17,  6.91s/it]Training Epoch: 1/1, step 273/779 completed (loss: 1.1935958862304688, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 273/779 [31:28<58:17,  6.91s/it]Training Epoch: 1/1, step 273/779 completed (loss: 1.1935958862304688, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 274/779 [31:35<58:10,  6.91s/it]Training Epoch: 1/1, step 274/779 completed (loss: 1.0085538625717163, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 274/779 [31:35<58:10,  6.91s/it]Training Epoch: 1/1, step 274/779 completed (loss: 1.0085538625717163, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 275/779 [31:42<58:08,  6.92s/it]Training Epoch: 1/1, step 275/779 completed (loss: 1.1588579416275024, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 275/779 [31:42<58:08,  6.92s/it]Training Epoch: 1/1, step 275/779 completed (loss: 1.1588579416275024, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 276/779 [31:49<58:00,  6.92s/it]Training Epoch: 1/1, step 276/779 completed (loss: 1.029639482498169, lr: 2e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 276/779 [31:49<58:00,  6.92s/it] Training Epoch: 1/1, step 276/779 completed (loss: 1.029639482498169, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 277/779 [31:56<57:55,  6.92s/it]Training Epoch: 1/1, step 277/779 completed (loss: 0.9285376071929932, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 277/779 [31:56<57:55,  6.92s/it]Training Epoch: 1/1, step 277/779 completed (loss: 0.9285376071929932, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 278/779 [32:03<57:48,  6.92s/it]Training Epoch: 1/1, step 278/779 completed (loss: 0.931391179561615, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 278/779 [32:03<57:48,  6.92s/it] Training Epoch: 1/1, step 278/779 completed (loss: 0.931391179561615, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 279/779 [32:10<57:41,  6.92s/it]Training Epoch: 1/1, step 279/779 completed (loss: 1.017406702041626, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 279/779 [32:10<57:41,  6.92s/it]Training Epoch: 1/1, step 279/779 completed (loss: 1.017406702041626, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 280/779 [32:17<57:34,  6.92s/it]Training Epoch: 1/1, step 280/779 completed (loss: 0.9965651631355286, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 280/779 [32:17<57:34,  6.92s/it]Training Epoch: 1/1, step 280/779 completed (loss: 0.9965651631355286, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 281/779 [32:24<57:24,  6.92s/it]Training Epoch: 1/1, step 281/779 completed (loss: 1.028931736946106, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 281/779 [32:24<57:24,  6.92s/it] Training Epoch: 1/1, step 281/779 completed (loss: 1.028931736946106, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 282/779 [32:31<57:13,  6.91s/it]Training Epoch: 1/1, step 282/779 completed (loss: 1.157967209815979, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 282/779 [32:31<57:13,  6.91s/it]Training Epoch: 1/1, step 282/779 completed (loss: 1.157967209815979, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 283/779 [32:37<57:05,  6.91s/it]Training Epoch: 1/1, step 283/779 completed (loss: 1.0232698917388916, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 283/779 [32:38<57:05,  6.91s/it]Training Epoch: 1/1, step 283/779 completed (loss: 1.0232698917388916, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 284/779 [32:44<56:59,  6.91s/it]Training Epoch: 1/1, step 284/779 completed (loss: 0.976787805557251, lr: 2e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 284/779 [32:44<56:59,  6.91s/it] Training Epoch: 1/1, step 284/779 completed (loss: 0.976787805557251, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 285/779 [32:51<56:56,  6.92s/it]Training Epoch: 1/1, step 285/779 completed (loss: 1.065034031867981, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 285/779 [32:51<56:56,  6.92s/it]Training Epoch: 1/1, step 285/779 completed (loss: 1.065034031867981, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 286/779 [32:58<56:49,  6.91s/it]Training Epoch: 1/1, step 286/779 completed (loss: 1.1029725074768066, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 286/779 [32:58<56:49,  6.91s/it]Training Epoch: 1/1, step 286/779 completed (loss: 1.1029725074768066, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 287/779 [33:05<56:41,  6.91s/it]Training Epoch: 1/1, step 287/779 completed (loss: 1.048492670059204, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 287/779 [33:05<56:41,  6.91s/it] Training Epoch: 1/1, step 287/779 completed (loss: 1.048492670059204, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 288/779 [33:12<56:34,  6.91s/it]Training Epoch: 1/1, step 288/779 completed (loss: 1.0564837455749512, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 288/779 [33:12<56:34,  6.91s/it]Training Epoch: 1/1, step 288/779 completed (loss: 1.0564837455749512, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 289/779 [33:19<56:25,  6.91s/it]Training Epoch: 1/1, step 289/779 completed (loss: 1.172742486000061, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 289/779 [33:19<56:25,  6.91s/it] Training Epoch: 1/1, step 289/779 completed (loss: 1.172742486000061, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 290/779 [33:26<56:19,  6.91s/it]Training Epoch: 1/1, step 290/779 completed (loss: 1.0591964721679688, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 290/779 [33:26<56:19,  6.91s/it]Training Epoch: 1/1, step 290/779 completed (loss: 1.0591964721679688, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 291/779 [33:33<56:13,  6.91s/it]Training Epoch: 1/1, step 291/779 completed (loss: 1.0075509548187256, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 291/779 [33:33<56:13,  6.91s/it]Training Epoch: 1/1, step 291/779 completed (loss: 1.0075509548187256, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 292/779 [33:40<56:04,  6.91s/it]Training Epoch: 1/1, step 292/779 completed (loss: 1.1092994213104248, lr: 2e-05):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 292/779 [33:40<56:04,  6.91s/it]Training Epoch: 1/1, step 292/779 completed (loss: 1.1092994213104248, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 293/779 [33:47<55:57,  6.91s/it]Training Epoch: 1/1, step 293/779 completed (loss: 0.9789420962333679, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 293/779 [33:47<55:57,  6.91s/it]Training Epoch: 1/1, step 293/779 completed (loss: 0.9789420962333679, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 294/779 [33:53<55:50,  6.91s/it]Training Epoch: 1/1, step 294/779 completed (loss: 1.1249662637710571, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 294/779 [33:54<55:50,  6.91s/it]Training Epoch: 1/1, step 294/779 completed (loss: 1.1249662637710571, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 295/779 [34:00<55:41,  6.90s/it]Training Epoch: 1/1, step 295/779 completed (loss: 0.975459635257721, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 295/779 [34:00<55:41,  6.90s/it] Training Epoch: 1/1, step 295/779 completed (loss: 0.975459635257721, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 296/779 [34:07<55:34,  6.90s/it]Training Epoch: 1/1, step 296/779 completed (loss: 1.089459776878357, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 296/779 [34:07<55:34,  6.90s/it]Training Epoch: 1/1, step 296/779 completed (loss: 1.089459776878357, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 297/779 [34:14<55:26,  6.90s/it]Training Epoch: 1/1, step 297/779 completed (loss: 0.9235209822654724, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 297/779 [34:14<55:26,  6.90s/it]Training Epoch: 1/1, step 297/779 completed (loss: 0.9235209822654724, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 298/779 [34:21<55:25,  6.91s/it]Training Epoch: 1/1, step 298/779 completed (loss: 0.9993855357170105, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 298/779 [34:21<55:25,  6.91s/it]Training Epoch: 1/1, step 298/779 completed (loss: 0.9993855357170105, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 299/779 [34:28<55:17,  6.91s/it]Training Epoch: 1/1, step 299/779 completed (loss: 1.4019235372543335, lr: 2e-05):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 299/779 [34:28<55:17,  6.91s/it]Training Epoch: 1/1, step 299/779 completed (loss: 1.4019235372543335, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 300/779 [34:35<55:11,  6.91s/it]Training Epoch: 1/1, step 300/779 completed (loss: 0.9561398029327393, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 300/779 [34:35<55:11,  6.91s/it]Training Epoch: 1/1, step 300/779 completed (loss: 0.9561398029327393, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 301/779 [34:42<55:01,  6.91s/it]Training Epoch: 1/1, step 301/779 completed (loss: 1.2494845390319824, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 301/779 [34:42<55:01,  6.91s/it]Training Epoch: 1/1, step 301/779 completed (loss: 1.2494845390319824, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 302/779 [34:49<54:52,  6.90s/it]Training Epoch: 1/1, step 302/779 completed (loss: 1.1656568050384521, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 302/779 [34:49<54:52,  6.90s/it]Training Epoch: 1/1, step 302/779 completed (loss: 1.1656568050384521, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 303/779 [34:56<54:46,  6.90s/it]Training Epoch: 1/1, step 303/779 completed (loss: 0.8470739126205444, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 303/779 [34:56<54:46,  6.90s/it]Training Epoch: 1/1, step 303/779 completed (loss: 0.8470739126205444, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 304/779 [35:03<54:38,  6.90s/it]Training Epoch: 1/1, step 304/779 completed (loss: 0.9462254047393799, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 304/779 [35:03<54:38,  6.90s/it]Training Epoch: 1/1, step 304/779 completed (loss: 0.9462254047393799, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 305/779 [35:09<54:32,  6.90s/it]Training Epoch: 1/1, step 305/779 completed (loss: 1.0172361135482788, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 305/779 [35:10<54:32,  6.90s/it]Training Epoch: 1/1, step 305/779 completed (loss: 1.0172361135482788, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 306/779 [35:16<54:27,  6.91s/it]Training Epoch: 1/1, step 306/779 completed (loss: 1.0657658576965332, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 306/779 [35:16<54:27,  6.91s/it]Training Epoch: 1/1, step 306/779 completed (loss: 1.0657658576965332, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 307/779 [35:23<54:21,  6.91s/it]Training Epoch: 1/1, step 307/779 completed (loss: 1.1090914011001587, lr: 2e-05):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 307/779 [35:23<54:21,  6.91s/it]Training Epoch: 1/1, step 307/779 completed (loss: 1.1090914011001587, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 308/779 [35:30<54:14,  6.91s/it]Training Epoch: 1/1, step 308/779 completed (loss: 1.1121348142623901, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 308/779 [35:30<54:14,  6.91s/it]Training Epoch: 1/1, step 308/779 completed (loss: 1.1121348142623901, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 309/779 [35:37<54:10,  6.92s/it]Training Epoch: 1/1, step 309/779 completed (loss: 1.0231008529663086, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 309/779 [35:37<54:10,  6.92s/it]Training Epoch: 1/1, step 309/779 completed (loss: 1.0231008529663086, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 310/779 [35:44<54:03,  6.92s/it]Training Epoch: 1/1, step 310/779 completed (loss: 0.8987323045730591, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 310/779 [35:44<54:03,  6.92s/it]Training Epoch: 1/1, step 310/779 completed (loss: 0.8987323045730591, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 311/779 [35:51<53:57,  6.92s/it]Training Epoch: 1/1, step 311/779 completed (loss: 0.9770217537879944, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 311/779 [35:51<53:57,  6.92s/it]Training Epoch: 1/1, step 311/779 completed (loss: 0.9770217537879944, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 312/779 [35:58<53:50,  6.92s/it]Training Epoch: 1/1, step 312/779 completed (loss: 1.1214663982391357, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 312/779 [35:58<53:50,  6.92s/it]Training Epoch: 1/1, step 312/779 completed (loss: 1.1214663982391357, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 313/779 [36:05<53:42,  6.91s/it]Training Epoch: 1/1, step 313/779 completed (loss: 0.9363629817962646, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 313/779 [36:05<53:42,  6.91s/it]Training Epoch: 1/1, step 313/779 completed (loss: 0.9363629817962646, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 314/779 [36:12<53:36,  6.92s/it]Training Epoch: 1/1, step 314/779 completed (loss: 1.1433305740356445, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 314/779 [36:12<53:36,  6.92s/it]Training Epoch: 1/1, step 314/779 completed (loss: 1.1433305740356445, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 315/779 [36:19<53:27,  6.91s/it]Training Epoch: 1/1, step 315/779 completed (loss: 1.0451549291610718, lr: 2e-05):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 315/779 [36:19<53:27,  6.91s/it]Training Epoch: 1/1, step 315/779 completed (loss: 1.0451549291610718, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 316/779 [36:26<53:20,  6.91s/it]Training Epoch: 1/1, step 316/779 completed (loss: 1.0332846641540527, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 316/779 [36:26<53:20,  6.91s/it]Training Epoch: 1/1, step 316/779 completed (loss: 1.0332846641540527, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 317/779 [36:32<53:11,  6.91s/it]Training Epoch: 1/1, step 317/779 completed (loss: 1.1806508302688599, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 317/779 [36:33<53:11,  6.91s/it]Training Epoch: 1/1, step 317/779 completed (loss: 1.1806508302688599, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 318/779 [36:39<53:06,  6.91s/it]Training Epoch: 1/1, step 318/779 completed (loss: 0.9542693495750427, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 318/779 [36:39<53:06,  6.91s/it]Training Epoch: 1/1, step 318/779 completed (loss: 0.9542693495750427, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 319/779 [36:46<52:59,  6.91s/it]Training Epoch: 1/1, step 319/779 completed (loss: 0.9979275465011597, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 319/779 [36:46<52:59,  6.91s/it]Training Epoch: 1/1, step 319/779 completed (loss: 0.9979275465011597, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 320/779 [36:53<52:51,  6.91s/it]Training Epoch: 1/1, step 320/779 completed (loss: 1.0244368314743042, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 320/779 [36:53<52:51,  6.91s/it]Training Epoch: 1/1, step 320/779 completed (loss: 1.0244368314743042, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 321/779 [37:00<52:48,  6.92s/it]Training Epoch: 1/1, step 321/779 completed (loss: 1.061432957649231, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 321/779 [37:00<52:48,  6.92s/it] Training Epoch: 1/1, step 321/779 completed (loss: 1.061432957649231, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 322/779 [37:07<52:41,  6.92s/it]Training Epoch: 1/1, step 322/779 completed (loss: 1.0907129049301147, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 322/779 [37:07<52:41,  6.92s/it]Training Epoch: 1/1, step 322/779 completed (loss: 1.0907129049301147, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 323/779 [37:14<52:31,  6.91s/it]Training Epoch: 1/1, step 323/779 completed (loss: 1.176156759262085, lr: 2e-05):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 323/779 [37:14<52:31,  6.91s/it] Training Epoch: 1/1, step 323/779 completed (loss: 1.176156759262085, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 324/779 [37:21<52:24,  6.91s/it]Training Epoch: 1/1, step 324/779 completed (loss: 1.0194916725158691, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 324/779 [37:21<52:24,  6.91s/it]Training Epoch: 1/1, step 324/779 completed (loss: 1.0194916725158691, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 325/779 [37:28<52:16,  6.91s/it]Training Epoch: 1/1, step 325/779 completed (loss: 1.023116946220398, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 325/779 [37:28<52:16,  6.91s/it] Training Epoch: 1/1, step 325/779 completed (loss: 1.023116946220398, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 326/779 [37:35<52:09,  6.91s/it]Training Epoch: 1/1, step 326/779 completed (loss: 1.1680760383605957, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 326/779 [37:35<52:09,  6.91s/it]Training Epoch: 1/1, step 326/779 completed (loss: 1.1680760383605957, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 327/779 [37:42<52:03,  6.91s/it]Training Epoch: 1/1, step 327/779 completed (loss: 1.1219388246536255, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 327/779 [37:42<52:03,  6.91s/it]Training Epoch: 1/1, step 327/779 completed (loss: 1.1219388246536255, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 328/779 [37:48<51:54,  6.91s/it]Training Epoch: 1/1, step 328/779 completed (loss: 1.049998164176941, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 328/779 [37:49<51:54,  6.91s/it] Training Epoch: 1/1, step 328/779 completed (loss: 1.049998164176941, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 329/779 [37:55<51:48,  6.91s/it]Training Epoch: 1/1, step 329/779 completed (loss: 1.2545088529586792, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 329/779 [37:55<51:48,  6.91s/it]Training Epoch: 1/1, step 329/779 completed (loss: 1.2545088529586792, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 330/779 [38:02<51:42,  6.91s/it]Training Epoch: 1/1, step 330/779 completed (loss: 1.1210136413574219, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 330/779 [38:02<51:42,  6.91s/it]Training Epoch: 1/1, step 330/779 completed (loss: 1.1210136413574219, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 331/779 [38:09<51:34,  6.91s/it]Training Epoch: 1/1, step 331/779 completed (loss: 1.0196446180343628, lr: 2e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 331/779 [38:09<51:34,  6.91s/it]Training Epoch: 1/1, step 331/779 completed (loss: 1.0196446180343628, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 332/779 [38:16<51:29,  6.91s/it]Training Epoch: 1/1, step 332/779 completed (loss: 1.1265525817871094, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 332/779 [38:16<51:29,  6.91s/it]Training Epoch: 1/1, step 332/779 completed (loss: 1.1265525817871094, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 333/779 [38:23<51:20,  6.91s/it]Training Epoch: 1/1, step 333/779 completed (loss: 1.0302348136901855, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 333/779 [38:23<51:20,  6.91s/it]Training Epoch: 1/1, step 333/779 completed (loss: 1.0302348136901855, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 334/779 [38:30<51:13,  6.91s/it]Training Epoch: 1/1, step 334/779 completed (loss: 1.0415631532669067, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 334/779 [38:30<51:13,  6.91s/it]Training Epoch: 1/1, step 334/779 completed (loss: 1.0415631532669067, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 335/779 [38:37<51:06,  6.91s/it]Training Epoch: 1/1, step 335/779 completed (loss: 1.1270345449447632, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 335/779 [38:37<51:06,  6.91s/it]Training Epoch: 1/1, step 335/779 completed (loss: 1.1270345449447632, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 336/779 [38:44<51:00,  6.91s/it]Training Epoch: 1/1, step 336/779 completed (loss: 0.9451248049736023, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 336/779 [38:44<51:00,  6.91s/it]Training Epoch: 1/1, step 336/779 completed (loss: 0.9451248049736023, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 337/779 [38:51<50:54,  6.91s/it]Training Epoch: 1/1, step 337/779 completed (loss: 1.006176471710205, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 337/779 [38:51<50:54,  6.91s/it] Training Epoch: 1/1, step 337/779 completed (loss: 1.006176471710205, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 338/779 [38:58<50:50,  6.92s/it]Training Epoch: 1/1, step 338/779 completed (loss: 0.9184530973434448, lr: 2e-05):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 338/779 [38:58<50:50,  6.92s/it]Training Epoch: 1/1, step 338/779 completed (loss: 0.9184530973434448, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 339/779 [39:04<50:49,  6.93s/it]Training Epoch: 1/1, step 339/779 completed (loss: 1.209447979927063, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 339/779 [39:05<50:49,  6.93s/it] Training Epoch: 1/1, step 339/779 completed (loss: 1.209447979927063, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 340/779 [39:11<50:41,  6.93s/it]Training Epoch: 1/1, step 340/779 completed (loss: 0.971254289150238, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 340/779 [39:12<50:41,  6.93s/it]Training Epoch: 1/1, step 340/779 completed (loss: 0.971254289150238, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 341/779 [39:18<50:34,  6.93s/it]Training Epoch: 1/1, step 341/779 completed (loss: 1.0621984004974365, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 341/779 [39:18<50:34,  6.93s/it]Training Epoch: 1/1, step 341/779 completed (loss: 1.0621984004974365, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 342/779 [39:25<50:28,  6.93s/it]Training Epoch: 1/1, step 342/779 completed (loss: 1.0558521747589111, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 342/779 [39:25<50:28,  6.93s/it]Training Epoch: 1/1, step 342/779 completed (loss: 1.0558521747589111, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 343/779 [39:32<50:18,  6.92s/it]Training Epoch: 1/1, step 343/779 completed (loss: 1.145561933517456, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 343/779 [39:32<50:18,  6.92s/it] Training Epoch: 1/1, step 343/779 completed (loss: 1.145561933517456, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 344/779 [39:39<50:12,  6.93s/it]Training Epoch: 1/1, step 344/779 completed (loss: 1.1540932655334473, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 344/779 [39:39<50:12,  6.93s/it]Training Epoch: 1/1, step 344/779 completed (loss: 1.1540932655334473, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 345/779 [39:46<50:04,  6.92s/it]Training Epoch: 1/1, step 345/779 completed (loss: 1.0511162281036377, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 345/779 [39:46<50:04,  6.92s/it]Training Epoch: 1/1, step 345/779 completed (loss: 1.0511162281036377, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 346/779 [39:53<49:56,  6.92s/it]Training Epoch: 1/1, step 346/779 completed (loss: 1.1050543785095215, lr: 2e-05):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 346/779 [39:53<49:56,  6.92s/it]Training Epoch: 1/1, step 346/779 completed (loss: 1.1050543785095215, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 347/779 [40:00<49:47,  6.91s/it]Training Epoch: 1/1, step 347/779 completed (loss: 1.0070295333862305, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 347/779 [40:00<49:47,  6.91s/it]Training Epoch: 1/1, step 347/779 completed (loss: 1.0070295333862305, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 348/779 [40:07<49:40,  6.92s/it]Training Epoch: 1/1, step 348/779 completed (loss: 1.27213716506958, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 348/779 [40:07<49:40,  6.92s/it]  Training Epoch: 1/1, step 348/779 completed (loss: 1.27213716506958, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 349/779 [40:14<49:32,  6.91s/it]Training Epoch: 1/1, step 349/779 completed (loss: 1.092969536781311, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 349/779 [40:14<49:32,  6.91s/it]Training Epoch: 1/1, step 349/779 completed (loss: 1.092969536781311, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 350/779 [40:21<49:28,  6.92s/it]Training Epoch: 1/1, step 350/779 completed (loss: 1.1821446418762207, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 350/779 [40:21<49:28,  6.92s/it]Training Epoch: 1/1, step 350/779 completed (loss: 1.1821446418762207, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 351/779 [40:28<49:23,  6.92s/it]Training Epoch: 1/1, step 351/779 completed (loss: 1.0737885236740112, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 351/779 [40:28<49:23,  6.92s/it]Training Epoch: 1/1, step 351/779 completed (loss: 1.0737885236740112, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 352/779 [40:34<49:13,  6.92s/it]Training Epoch: 1/1, step 352/779 completed (loss: 1.049044132232666, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 352/779 [40:35<49:13,  6.92s/it] Training Epoch: 1/1, step 352/779 completed (loss: 1.049044132232666, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 353/779 [40:41<49:06,  6.92s/it]Training Epoch: 1/1, step 353/779 completed (loss: 1.0880348682403564, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 353/779 [40:41<49:06,  6.92s/it]Training Epoch: 1/1, step 353/779 completed (loss: 1.0880348682403564, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 354/779 [40:48<48:59,  6.92s/it]Training Epoch: 1/1, step 354/779 completed (loss: 1.0732992887496948, lr: 2e-05):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 354/779 [40:48<48:59,  6.92s/it]Training Epoch: 1/1, step 354/779 completed (loss: 1.0732992887496948, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 355/779 [40:55<48:49,  6.91s/it]Training Epoch: 1/1, step 355/779 completed (loss: 1.0839024782180786, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 355/779 [40:55<48:49,  6.91s/it]Training Epoch: 1/1, step 355/779 completed (loss: 1.0839024782180786, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 356/779 [41:02<48:41,  6.91s/it]Training Epoch: 1/1, step 356/779 completed (loss: 0.9325054883956909, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 356/779 [41:02<48:41,  6.91s/it]Training Epoch: 1/1, step 356/779 completed (loss: 0.9325054883956909, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 357/779 [41:09<48:34,  6.91s/it]Training Epoch: 1/1, step 357/779 completed (loss: 1.1053544282913208, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 357/779 [41:09<48:34,  6.91s/it]Training Epoch: 1/1, step 357/779 completed (loss: 1.1053544282913208, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 358/779 [41:16<48:28,  6.91s/it]Training Epoch: 1/1, step 358/779 completed (loss: 1.092379093170166, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 358/779 [41:16<48:28,  6.91s/it] Training Epoch: 1/1, step 358/779 completed (loss: 1.092379093170166, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 359/779 [41:23<48:22,  6.91s/it]Training Epoch: 1/1, step 359/779 completed (loss: 1.0777881145477295, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 359/779 [41:23<48:22,  6.91s/it]Training Epoch: 1/1, step 359/779 completed (loss: 1.0777881145477295, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 360/779 [41:30<48:16,  6.91s/it]Training Epoch: 1/1, step 360/779 completed (loss: 1.1400792598724365, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 360/779 [41:30<48:16,  6.91s/it]Training Epoch: 1/1, step 360/779 completed (loss: 1.1400792598724365, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 361/779 [41:37<48:10,  6.91s/it]Training Epoch: 1/1, step 361/779 completed (loss: 1.1145483255386353, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 361/779 [41:37<48:10,  6.91s/it]Training Epoch: 1/1, step 361/779 completed (loss: 1.1145483255386353, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 362/779 [41:44<48:01,  6.91s/it]Training Epoch: 1/1, step 362/779 completed (loss: 1.1419340372085571, lr: 2e-05):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 362/779 [41:44<48:01,  6.91s/it]Training Epoch: 1/1, step 362/779 completed (loss: 1.1419340372085571, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 363/779 [41:50<47:52,  6.91s/it]Training Epoch: 1/1, step 363/779 completed (loss: 0.9752078652381897, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 363/779 [41:51<47:52,  6.91s/it]Training Epoch: 1/1, step 363/779 completed (loss: 0.9752078652381897, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 364/779 [41:57<47:46,  6.91s/it]Training Epoch: 1/1, step 364/779 completed (loss: 1.0864814519882202, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 364/779 [41:57<47:46,  6.91s/it]Training Epoch: 1/1, step 364/779 completed (loss: 1.0864814519882202, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 365/779 [42:04<47:40,  6.91s/it]Training Epoch: 1/1, step 365/779 completed (loss: 0.9543554782867432, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 365/779 [42:04<47:40,  6.91s/it]Training Epoch: 1/1, step 365/779 completed (loss: 0.9543554782867432, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 366/779 [42:11<47:32,  6.91s/it]Training Epoch: 1/1, step 366/779 completed (loss: 1.03534996509552, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 366/779 [42:11<47:32,  6.91s/it]  Training Epoch: 1/1, step 366/779 completed (loss: 1.03534996509552, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 367/779 [42:18<47:26,  6.91s/it]Training Epoch: 1/1, step 367/779 completed (loss: 0.9213306903839111, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 367/779 [42:18<47:26,  6.91s/it]Training Epoch: 1/1, step 367/779 completed (loss: 0.9213306903839111, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 368/779 [42:25<47:20,  6.91s/it]Training Epoch: 1/1, step 368/779 completed (loss: 0.9199777245521545, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 368/779 [42:25<47:20,  6.91s/it]Training Epoch: 1/1, step 368/779 completed (loss: 0.9199777245521545, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 369/779 [42:32<47:13,  6.91s/it]Training Epoch: 1/1, step 369/779 completed (loss: 1.0385898351669312, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 369/779 [42:32<47:13,  6.91s/it]Training Epoch: 1/1, step 369/779 completed (loss: 1.0385898351669312, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 370/779 [42:39<47:06,  6.91s/it]Training Epoch: 1/1, step 370/779 completed (loss: 1.2314751148223877, lr: 2e-05):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 370/779 [42:39<47:06,  6.91s/it]Training Epoch: 1/1, step 370/779 completed (loss: 1.2314751148223877, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 371/779 [42:46<47:01,  6.92s/it]Training Epoch: 1/1, step 371/779 completed (loss: 1.1219300031661987, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 371/779 [42:46<47:01,  6.92s/it]Training Epoch: 1/1, step 371/779 completed (loss: 1.1219300031661987, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 372/779 [42:53<46:52,  6.91s/it]Training Epoch: 1/1, step 372/779 completed (loss: 1.0079859495162964, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 372/779 [42:53<46:52,  6.91s/it]Training Epoch: 1/1, step 372/779 completed (loss: 1.0079859495162964, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 373/779 [43:00<46:44,  6.91s/it]Training Epoch: 1/1, step 373/779 completed (loss: 1.1625369787216187, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 373/779 [43:00<46:44,  6.91s/it]Training Epoch: 1/1, step 373/779 completed (loss: 1.1625369787216187, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 374/779 [43:06<46:38,  6.91s/it]Training Epoch: 1/1, step 374/779 completed (loss: 1.0752986669540405, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 374/779 [43:07<46:38,  6.91s/it]Training Epoch: 1/1, step 374/779 completed (loss: 1.0752986669540405, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 375/779 [43:13<46:30,  6.91s/it]Training Epoch: 1/1, step 375/779 completed (loss: 0.9170628190040588, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 375/779 [43:13<46:30,  6.91s/it]Training Epoch: 1/1, step 375/779 completed (loss: 0.9170628190040588, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 376/779 [43:20<46:22,  6.90s/it]Training Epoch: 1/1, step 376/779 completed (loss: 1.0499671697616577, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 376/779 [43:20<46:22,  6.90s/it]Training Epoch: 1/1, step 376/779 completed (loss: 1.0499671697616577, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 377/779 [43:27<46:14,  6.90s/it]Training Epoch: 1/1, step 377/779 completed (loss: 0.8915846943855286, lr: 2e-05):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 377/779 [43:27<46:14,  6.90s/it]Training Epoch: 1/1, step 377/779 completed (loss: 0.8915846943855286, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 378/779 [43:34<46:10,  6.91s/it]Training Epoch: 1/1, step 378/779 completed (loss: 1.11290442943573, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 378/779 [43:34<46:10,  6.91s/it]  Training Epoch: 1/1, step 378/779 completed (loss: 1.11290442943573, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 379/779 [43:41<46:01,  6.90s/it]Training Epoch: 1/1, step 379/779 completed (loss: 1.0470459461212158, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 379/779 [43:41<46:01,  6.90s/it]Training Epoch: 1/1, step 379/779 completed (loss: 1.0470459461212158, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 380/779 [43:48<45:53,  6.90s/it]Training Epoch: 1/1, step 380/779 completed (loss: 1.0571383237838745, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 380/779 [43:48<45:53,  6.90s/it]Training Epoch: 1/1, step 380/779 completed (loss: 1.0571383237838745, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 381/779 [43:55<45:44,  6.90s/it]Training Epoch: 1/1, step 381/779 completed (loss: 0.960866391658783, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 381/779 [43:55<45:44,  6.90s/it] Training Epoch: 1/1, step 381/779 completed (loss: 0.960866391658783, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 382/779 [44:02<45:37,  6.90s/it]Training Epoch: 1/1, step 382/779 completed (loss: 0.9544230699539185, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 382/779 [44:02<45:37,  6.90s/it]Training Epoch: 1/1, step 382/779 completed (loss: 0.9544230699539185, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 383/779 [44:09<45:30,  6.90s/it]Training Epoch: 1/1, step 383/779 completed (loss: 0.9839366674423218, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 383/779 [44:09<45:30,  6.90s/it]Training Epoch: 1/1, step 383/779 completed (loss: 0.9839366674423218, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 384/779 [44:15<45:23,  6.90s/it]Training Epoch: 1/1, step 384/779 completed (loss: 1.0929187536239624, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 384/779 [44:16<45:23,  6.90s/it]Training Epoch: 1/1, step 384/779 completed (loss: 1.0929187536239624, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 385/779 [44:22<45:19,  6.90s/it]Training Epoch: 1/1, step 385/779 completed (loss: 1.0772628784179688, lr: 2e-05):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 385/779 [44:22<45:19,  6.90s/it]Training Epoch: 1/1, step 385/779 completed (loss: 1.0772628784179688, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 386/779 [44:29<45:11,  6.90s/it]Training Epoch: 1/1, step 386/779 completed (loss: 1.0183613300323486, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 386/779 [44:29<45:11,  6.90s/it]Training Epoch: 1/1, step 386/779 completed (loss: 1.0183613300323486, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 387/779 [44:36<45:03,  6.90s/it]Training Epoch: 1/1, step 387/779 completed (loss: 1.1822112798690796, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 387/779 [44:36<45:03,  6.90s/it]Training Epoch: 1/1, step 387/779 completed (loss: 1.1822112798690796, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 388/779 [44:43<44:56,  6.90s/it]Training Epoch: 1/1, step 388/779 completed (loss: 0.9493317604064941, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 388/779 [44:43<44:56,  6.90s/it]Training Epoch: 1/1, step 388/779 completed (loss: 0.9493317604064941, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 389/779 [44:50<44:52,  6.90s/it]Training Epoch: 1/1, step 389/779 completed (loss: 1.201206088066101, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 389/779 [44:50<44:52,  6.90s/it] Training Epoch: 1/1, step 389/779 completed (loss: 1.201206088066101, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 390/779 [44:57<44:44,  6.90s/it]Training Epoch: 1/1, step 390/779 completed (loss: 1.059678077697754, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 390/779 [44:57<44:44,  6.90s/it]Training Epoch: 1/1, step 390/779 completed (loss: 1.059678077697754, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 391/779 [45:04<44:36,  6.90s/it]Training Epoch: 1/1, step 391/779 completed (loss: 1.0413620471954346, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 391/779 [45:04<44:36,  6.90s/it]Training Epoch: 1/1, step 391/779 completed (loss: 1.0413620471954346, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 392/779 [45:11<44:30,  6.90s/it]Training Epoch: 1/1, step 392/779 completed (loss: 1.058699607849121, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 392/779 [45:11<44:30,  6.90s/it] Training Epoch: 1/1, step 392/779 completed (loss: 1.058699607849121, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 393/779 [45:18<44:25,  6.91s/it]Training Epoch: 1/1, step 393/779 completed (loss: 0.9831815958023071, lr: 2e-05):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 393/779 [45:18<44:25,  6.91s/it]Training Epoch: 1/1, step 393/779 completed (loss: 0.9831815958023071, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 394/779 [45:24<44:20,  6.91s/it]Training Epoch: 1/1, step 394/779 completed (loss: 1.1160732507705688, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 394/779 [45:25<44:20,  6.91s/it]Training Epoch: 1/1, step 394/779 completed (loss: 1.1160732507705688, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 395/779 [45:31<44:12,  6.91s/it]Training Epoch: 1/1, step 395/779 completed (loss: 1.082798957824707, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 395/779 [45:32<44:12,  6.91s/it] Training Epoch: 1/1, step 395/779 completed (loss: 1.082798957824707, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 396/779 [45:38<44:10,  6.92s/it]Training Epoch: 1/1, step 396/779 completed (loss: 1.1682854890823364, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 396/779 [45:38<44:10,  6.92s/it]Training Epoch: 1/1, step 396/779 completed (loss: 1.1682854890823364, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 397/779 [45:45<44:02,  6.92s/it]Training Epoch: 1/1, step 397/779 completed (loss: 1.215428352355957, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 397/779 [45:45<44:02,  6.92s/it] Training Epoch: 1/1, step 397/779 completed (loss: 1.215428352355957, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 398/779 [45:52<43:54,  6.92s/it]Training Epoch: 1/1, step 398/779 completed (loss: 1.0087883472442627, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 398/779 [45:52<43:54,  6.92s/it]Training Epoch: 1/1, step 398/779 completed (loss: 1.0087883472442627, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 399/779 [45:59<43:46,  6.91s/it]Training Epoch: 1/1, step 399/779 completed (loss: 1.1060216426849365, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 399/779 [45:59<43:46,  6.91s/it]Training Epoch: 1/1, step 399/779 completed (loss: 1.1060216426849365, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 400/779 [46:06<43:39,  6.91s/it]Training Epoch: 1/1, step 400/779 completed (loss: 1.0884631872177124, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 400/779 [46:06<43:39,  6.91s/it]Training Epoch: 1/1, step 400/779 completed (loss: 1.0884631872177124, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 401/779 [46:13<43:31,  6.91s/it]Training Epoch: 1/1, step 401/779 completed (loss: 1.1702215671539307, lr: 2e-05):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 401/779 [46:13<43:31,  6.91s/it]Training Epoch: 1/1, step 401/779 completed (loss: 1.1702215671539307, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 402/779 [46:20<43:24,  6.91s/it]Training Epoch: 1/1, step 402/779 completed (loss: 1.2052812576293945, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 402/779 [46:20<43:24,  6.91s/it]Training Epoch: 1/1, step 402/779 completed (loss: 1.2052812576293945, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 403/779 [46:27<43:19,  6.91s/it]Training Epoch: 1/1, step 403/779 completed (loss: 1.1239925622940063, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 403/779 [46:27<43:19,  6.91s/it]Training Epoch: 1/1, step 403/779 completed (loss: 1.1239925622940063, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 404/779 [46:34<43:13,  6.91s/it]Training Epoch: 1/1, step 404/779 completed (loss: 1.1522172689437866, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 404/779 [46:34<43:13,  6.91s/it]Training Epoch: 1/1, step 404/779 completed (loss: 1.1522172689437866, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 405/779 [46:41<43:04,  6.91s/it]Training Epoch: 1/1, step 405/779 completed (loss: 1.1730152368545532, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 405/779 [46:41<43:04,  6.91s/it]Training Epoch: 1/1, step 405/779 completed (loss: 1.1730152368545532, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 406/779 [46:47<42:56,  6.91s/it]Training Epoch: 1/1, step 406/779 completed (loss: 0.9739603996276855, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 406/779 [46:48<42:56,  6.91s/it]Training Epoch: 1/1, step 406/779 completed (loss: 0.9739603996276855, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 407/779 [46:54<42:49,  6.91s/it]Training Epoch: 1/1, step 407/779 completed (loss: 1.2100799083709717, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 407/779 [46:54<42:49,  6.91s/it]Training Epoch: 1/1, step 407/779 completed (loss: 1.2100799083709717, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 408/779 [47:01<42:44,  6.91s/it]Training Epoch: 1/1, step 408/779 completed (loss: 1.142991065979004, lr: 2e-05):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 408/779 [47:01<42:44,  6.91s/it] Training Epoch: 1/1, step 408/779 completed (loss: 1.142991065979004, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 409/779 [47:08<42:37,  6.91s/it]Training Epoch: 1/1, step 409/779 completed (loss: 1.0404999256134033, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 409/779 [47:08<42:37,  6.91s/it]Training Epoch: 1/1, step 409/779 completed (loss: 1.0404999256134033, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 410/779 [47:15<42:31,  6.91s/it]Training Epoch: 1/1, step 410/779 completed (loss: 1.0379133224487305, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 410/779 [47:15<42:31,  6.91s/it]Training Epoch: 1/1, step 410/779 completed (loss: 1.0379133224487305, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 411/779 [47:22<42:26,  6.92s/it]Training Epoch: 1/1, step 411/779 completed (loss: 0.9312043190002441, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 411/779 [47:22<42:26,  6.92s/it]Training Epoch: 1/1, step 411/779 completed (loss: 0.9312043190002441, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 412/779 [47:29<42:20,  6.92s/it]Training Epoch: 1/1, step 412/779 completed (loss: 1.156911849975586, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 412/779 [47:29<42:20,  6.92s/it] Training Epoch: 1/1, step 412/779 completed (loss: 1.156911849975586, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 413/779 [47:36<42:14,  6.92s/it]Training Epoch: 1/1, step 413/779 completed (loss: 0.9769521951675415, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 413/779 [47:36<42:14,  6.92s/it]Training Epoch: 1/1, step 413/779 completed (loss: 0.9769521951675415, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 414/779 [47:43<42:08,  6.93s/it]Training Epoch: 1/1, step 414/779 completed (loss: 1.0373646020889282, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 414/779 [47:43<42:08,  6.93s/it]Training Epoch: 1/1, step 414/779 completed (loss: 1.0373646020889282, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 415/779 [47:50<42:01,  6.93s/it]Training Epoch: 1/1, step 415/779 completed (loss: 1.099101185798645, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 415/779 [47:50<42:01,  6.93s/it] Training Epoch: 1/1, step 415/779 completed (loss: 1.099101185798645, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 416/779 [47:57<41:53,  6.92s/it]Training Epoch: 1/1, step 416/779 completed (loss: 1.013208031654358, lr: 2e-05):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 416/779 [47:57<41:53,  6.92s/it]Training Epoch: 1/1, step 416/779 completed (loss: 1.013208031654358, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 417/779 [48:04<41:46,  6.92s/it]Training Epoch: 1/1, step 417/779 completed (loss: 1.0274356603622437, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 417/779 [48:04<41:46,  6.92s/it]Training Epoch: 1/1, step 417/779 completed (loss: 1.0274356603622437, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 418/779 [48:10<41:39,  6.92s/it]Training Epoch: 1/1, step 418/779 completed (loss: 1.1110490560531616, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 418/779 [48:11<41:39,  6.92s/it]Training Epoch: 1/1, step 418/779 completed (loss: 1.1110490560531616, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 419/779 [48:17<41:32,  6.92s/it]Training Epoch: 1/1, step 419/779 completed (loss: 1.1883593797683716, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 419/779 [48:18<41:32,  6.92s/it]Training Epoch: 1/1, step 419/779 completed (loss: 1.1883593797683716, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 420/779 [48:24<41:27,  6.93s/it]Training Epoch: 1/1, step 420/779 completed (loss: 1.0158377885818481, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 420/779 [48:24<41:27,  6.93s/it]Training Epoch: 1/1, step 420/779 completed (loss: 1.0158377885818481, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 421/779 [48:31<41:21,  6.93s/it]Training Epoch: 1/1, step 421/779 completed (loss: 1.1190485954284668, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 421/779 [48:31<41:21,  6.93s/it]Training Epoch: 1/1, step 421/779 completed (loss: 1.1190485954284668, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 422/779 [48:38<41:15,  6.93s/it]Training Epoch: 1/1, step 422/779 completed (loss: 1.1681034564971924, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 422/779 [48:38<41:15,  6.93s/it]Training Epoch: 1/1, step 422/779 completed (loss: 1.1681034564971924, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 423/779 [48:45<41:06,  6.93s/it]Training Epoch: 1/1, step 423/779 completed (loss: 1.1954559087753296, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 423/779 [48:45<41:06,  6.93s/it]Training Epoch: 1/1, step 423/779 completed (loss: 1.1954559087753296, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 424/779 [48:52<40:56,  6.92s/it]Training Epoch: 1/1, step 424/779 completed (loss: 1.205297589302063, lr: 2e-05):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 424/779 [48:52<40:56,  6.92s/it] Training Epoch: 1/1, step 424/779 completed (loss: 1.205297589302063, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 425/779 [48:59<40:49,  6.92s/it]Training Epoch: 1/1, step 425/779 completed (loss: 1.0457860231399536, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 425/779 [48:59<40:49,  6.92s/it]Training Epoch: 1/1, step 425/779 completed (loss: 1.0457860231399536, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 426/779 [49:06<40:43,  6.92s/it]Training Epoch: 1/1, step 426/779 completed (loss: 1.2101808786392212, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 426/779 [49:06<40:43,  6.92s/it]Training Epoch: 1/1, step 426/779 completed (loss: 1.2101808786392212, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 427/779 [49:13<40:37,  6.92s/it]Training Epoch: 1/1, step 427/779 completed (loss: 1.1535096168518066, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 427/779 [49:13<40:37,  6.92s/it]Training Epoch: 1/1, step 427/779 completed (loss: 1.1535096168518066, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 428/779 [49:20<40:29,  6.92s/it]Training Epoch: 1/1, step 428/779 completed (loss: 0.983588695526123, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 428/779 [49:20<40:29,  6.92s/it] Training Epoch: 1/1, step 428/779 completed (loss: 0.983588695526123, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 429/779 [49:27<40:21,  6.92s/it]Training Epoch: 1/1, step 429/779 completed (loss: 1.1306029558181763, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 429/779 [49:27<40:21,  6.92s/it]Training Epoch: 1/1, step 429/779 completed (loss: 1.1306029558181763, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 430/779 [49:34<40:14,  6.92s/it]Training Epoch: 1/1, step 430/779 completed (loss: 1.033047080039978, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 430/779 [49:34<40:14,  6.92s/it] Training Epoch: 1/1, step 430/779 completed (loss: 1.033047080039978, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 431/779 [49:40<40:06,  6.91s/it]Training Epoch: 1/1, step 431/779 completed (loss: 1.1446324586868286, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 431/779 [49:41<40:06,  6.91s/it]Training Epoch: 1/1, step 431/779 completed (loss: 1.1446324586868286, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 432/779 [49:47<39:57,  6.91s/it]Training Epoch: 1/1, step 432/779 completed (loss: 1.0677698850631714, lr: 2e-05):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 432/779 [49:48<39:57,  6.91s/it]Training Epoch: 1/1, step 432/779 completed (loss: 1.0677698850631714, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 433/779 [49:54<39:50,  6.91s/it]Training Epoch: 1/1, step 433/779 completed (loss: 1.1369644403457642, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 433/779 [49:54<39:50,  6.91s/it]Training Epoch: 1/1, step 433/779 completed (loss: 1.1369644403457642, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 434/779 [50:01<39:44,  6.91s/it]Training Epoch: 1/1, step 434/779 completed (loss: 1.037861943244934, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 434/779 [50:01<39:44,  6.91s/it] Training Epoch: 1/1, step 434/779 completed (loss: 1.037861943244934, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 435/779 [50:08<39:38,  6.91s/it]Training Epoch: 1/1, step 435/779 completed (loss: 1.1893936395645142, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 435/779 [50:08<39:38,  6.91s/it]Training Epoch: 1/1, step 435/779 completed (loss: 1.1893936395645142, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 436/779 [50:15<39:33,  6.92s/it]Training Epoch: 1/1, step 436/779 completed (loss: 0.9039373397827148, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 436/779 [50:15<39:33,  6.92s/it]Training Epoch: 1/1, step 436/779 completed (loss: 0.9039373397827148, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 437/779 [50:22<39:25,  6.92s/it]Training Epoch: 1/1, step 437/779 completed (loss: 1.0211385488510132, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 437/779 [50:22<39:25,  6.92s/it]Training Epoch: 1/1, step 437/779 completed (loss: 1.0211385488510132, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 438/779 [50:29<39:18,  6.92s/it]Training Epoch: 1/1, step 438/779 completed (loss: 1.0910860300064087, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 438/779 [50:29<39:18,  6.92s/it]Training Epoch: 1/1, step 438/779 completed (loss: 1.0910860300064087, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 439/779 [50:36<39:10,  6.91s/it]Training Epoch: 1/1, step 439/779 completed (loss: 1.311410665512085, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 439/779 [50:36<39:10,  6.91s/it] Training Epoch: 1/1, step 439/779 completed (loss: 1.311410665512085, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 440/779 [50:43<39:04,  6.92s/it]Training Epoch: 1/1, step 440/779 completed (loss: 1.0634894371032715, lr: 2e-05):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 440/779 [50:43<39:04,  6.92s/it]Training Epoch: 1/1, step 440/779 completed (loss: 1.0634894371032715, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 441/779 [50:50<38:55,  6.91s/it]Training Epoch: 1/1, step 441/779 completed (loss: 1.144268274307251, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 441/779 [50:50<38:55,  6.91s/it] Training Epoch: 1/1, step 441/779 completed (loss: 1.144268274307251, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 442/779 [50:57<38:48,  6.91s/it]Training Epoch: 1/1, step 442/779 completed (loss: 1.048081636428833, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 442/779 [50:57<38:48,  6.91s/it]Training Epoch: 1/1, step 442/779 completed (loss: 1.048081636428833, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 443/779 [51:03<38:41,  6.91s/it]Training Epoch: 1/1, step 443/779 completed (loss: 1.0076539516448975, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 443/779 [51:04<38:41,  6.91s/it]Training Epoch: 1/1, step 443/779 completed (loss: 1.0076539516448975, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 444/779 [51:10<38:35,  6.91s/it]Training Epoch: 1/1, step 444/779 completed (loss: 1.0458272695541382, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 444/779 [51:10<38:35,  6.91s/it]Training Epoch: 1/1, step 444/779 completed (loss: 1.0458272695541382, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 445/779 [51:17<38:26,  6.90s/it]Training Epoch: 1/1, step 445/779 completed (loss: 0.971735954284668, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 445/779 [51:17<38:26,  6.90s/it] Training Epoch: 1/1, step 445/779 completed (loss: 0.971735954284668, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 446/779 [51:24<38:21,  6.91s/it]Training Epoch: 1/1, step 446/779 completed (loss: 1.0571037530899048, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 446/779 [51:24<38:21,  6.91s/it]Training Epoch: 1/1, step 446/779 completed (loss: 1.0571037530899048, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 447/779 [51:31<38:13,  6.91s/it]Training Epoch: 1/1, step 447/779 completed (loss: 0.908896803855896, lr: 2e-05):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 447/779 [51:31<38:13,  6.91s/it] Training Epoch: 1/1, step 447/779 completed (loss: 0.908896803855896, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 448/779 [51:38<38:07,  6.91s/it]Training Epoch: 1/1, step 448/779 completed (loss: 1.0573225021362305, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 448/779 [51:38<38:07,  6.91s/it]Training Epoch: 1/1, step 448/779 completed (loss: 1.0573225021362305, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 449/779 [51:45<37:59,  6.91s/it]Training Epoch: 1/1, step 449/779 completed (loss: 1.1292293071746826, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 449/779 [51:45<37:59,  6.91s/it]Training Epoch: 1/1, step 449/779 completed (loss: 1.1292293071746826, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 450/779 [51:52<37:53,  6.91s/it]Training Epoch: 1/1, step 450/779 completed (loss: 1.2753164768218994, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 450/779 [51:52<37:53,  6.91s/it]Training Epoch: 1/1, step 450/779 completed (loss: 1.2753164768218994, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 451/779 [51:59<37:45,  6.91s/it]Training Epoch: 1/1, step 451/779 completed (loss: 1.1570767164230347, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 451/779 [51:59<37:45,  6.91s/it]Training Epoch: 1/1, step 451/779 completed (loss: 1.1570767164230347, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 452/779 [52:06<37:41,  6.92s/it]Training Epoch: 1/1, step 452/779 completed (loss: 1.1082793474197388, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 452/779 [52:06<37:41,  6.92s/it]Training Epoch: 1/1, step 452/779 completed (loss: 1.1082793474197388, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 453/779 [52:13<37:32,  6.91s/it]Training Epoch: 1/1, step 453/779 completed (loss: 0.9089491367340088, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 453/779 [52:13<37:32,  6.91s/it]Training Epoch: 1/1, step 453/779 completed (loss: 0.9089491367340088, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 454/779 [52:19<37:24,  6.91s/it]Training Epoch: 1/1, step 454/779 completed (loss: 1.1928647756576538, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 454/779 [52:20<37:24,  6.91s/it]Training Epoch: 1/1, step 454/779 completed (loss: 1.1928647756576538, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 455/779 [52:26<37:17,  6.90s/it]Training Epoch: 1/1, step 455/779 completed (loss: 1.1505945920944214, lr: 2e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 455/779 [52:26<37:17,  6.90s/it]Training Epoch: 1/1, step 455/779 completed (loss: 1.1505945920944214, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 456/779 [52:33<37:11,  6.91s/it]Training Epoch: 1/1, step 456/779 completed (loss: 0.9196863174438477, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 456/779 [52:33<37:11,  6.91s/it]Training Epoch: 1/1, step 456/779 completed (loss: 0.9196863174438477, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 457/779 [52:40<37:04,  6.91s/it]Training Epoch: 1/1, step 457/779 completed (loss: 0.9996744394302368, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 457/779 [52:40<37:04,  6.91s/it]Training Epoch: 1/1, step 457/779 completed (loss: 0.9996744394302368, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 458/779 [52:47<36:57,  6.91s/it]Training Epoch: 1/1, step 458/779 completed (loss: 1.0077260732650757, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 458/779 [52:47<36:57,  6.91s/it]Training Epoch: 1/1, step 458/779 completed (loss: 1.0077260732650757, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 459/779 [52:54<36:50,  6.91s/it]Training Epoch: 1/1, step 459/779 completed (loss: 1.1912336349487305, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 459/779 [52:54<36:50,  6.91s/it]Training Epoch: 1/1, step 459/779 completed (loss: 1.1912336349487305, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 460/779 [53:01<36:42,  6.90s/it]Training Epoch: 1/1, step 460/779 completed (loss: 1.0175516605377197, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 460/779 [53:01<36:42,  6.90s/it]Training Epoch: 1/1, step 460/779 completed (loss: 1.0175516605377197, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 461/779 [53:08<36:36,  6.91s/it]Training Epoch: 1/1, step 461/779 completed (loss: 1.1961252689361572, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 461/779 [53:08<36:36,  6.91s/it]Training Epoch: 1/1, step 461/779 completed (loss: 1.1961252689361572, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 462/779 [53:15<36:26,  6.90s/it]Training Epoch: 1/1, step 462/779 completed (loss: 1.0103715658187866, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 462/779 [53:15<36:26,  6.90s/it]Training Epoch: 1/1, step 462/779 completed (loss: 1.0103715658187866, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 463/779 [53:22<36:21,  6.90s/it]Training Epoch: 1/1, step 463/779 completed (loss: 0.9491109848022461, lr: 2e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 463/779 [53:22<36:21,  6.90s/it]Training Epoch: 1/1, step 463/779 completed (loss: 0.9491109848022461, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 464/779 [53:28<36:14,  6.90s/it]Training Epoch: 1/1, step 464/779 completed (loss: 1.1265944242477417, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 464/779 [53:29<36:14,  6.90s/it]Training Epoch: 1/1, step 464/779 completed (loss: 1.1265944242477417, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 465/779 [53:35<36:07,  6.90s/it]Training Epoch: 1/1, step 465/779 completed (loss: 1.051771640777588, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 465/779 [53:35<36:07,  6.90s/it] Training Epoch: 1/1, step 465/779 completed (loss: 1.051771640777588, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 466/779 [53:42<36:02,  6.91s/it]Training Epoch: 1/1, step 466/779 completed (loss: 0.938814640045166, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 466/779 [53:42<36:02,  6.91s/it]Training Epoch: 1/1, step 466/779 completed (loss: 0.938814640045166, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 467/779 [53:49<35:57,  6.91s/it]Training Epoch: 1/1, step 467/779 completed (loss: 1.048177719116211, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 467/779 [53:49<35:57,  6.91s/it]Training Epoch: 1/1, step 467/779 completed (loss: 1.048177719116211, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 468/779 [53:56<35:52,  6.92s/it]Training Epoch: 1/1, step 468/779 completed (loss: 0.9094176888465881, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 468/779 [53:56<35:52,  6.92s/it]Training Epoch: 1/1, step 468/779 completed (loss: 0.9094176888465881, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 469/779 [54:03<35:44,  6.92s/it]Training Epoch: 1/1, step 469/779 completed (loss: 1.0551522970199585, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 469/779 [54:03<35:44,  6.92s/it]Training Epoch: 1/1, step 469/779 completed (loss: 1.0551522970199585, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 470/779 [54:10<35:35,  6.91s/it]Training Epoch: 1/1, step 470/779 completed (loss: 0.980374276638031, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 470/779 [54:10<35:35,  6.91s/it] Training Epoch: 1/1, step 470/779 completed (loss: 0.980374276638031, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 471/779 [54:17<35:28,  6.91s/it]Training Epoch: 1/1, step 471/779 completed (loss: 0.9836686253547668, lr: 2e-05):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 471/779 [54:17<35:28,  6.91s/it]Training Epoch: 1/1, step 471/779 completed (loss: 0.9836686253547668, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 472/779 [54:24<35:21,  6.91s/it]Training Epoch: 1/1, step 472/779 completed (loss: 1.3012285232543945, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 472/779 [54:24<35:21,  6.91s/it]Training Epoch: 1/1, step 472/779 completed (loss: 1.3012285232543945, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 473/779 [54:31<35:15,  6.91s/it]Training Epoch: 1/1, step 473/779 completed (loss: 1.0901352167129517, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 473/779 [54:31<35:15,  6.91s/it]Training Epoch: 1/1, step 473/779 completed (loss: 1.0901352167129517, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 474/779 [54:38<35:10,  6.92s/it]Training Epoch: 1/1, step 474/779 completed (loss: 1.0190765857696533, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 474/779 [54:38<35:10,  6.92s/it]Training Epoch: 1/1, step 474/779 completed (loss: 1.0190765857696533, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 475/779 [54:45<35:02,  6.92s/it]Training Epoch: 1/1, step 475/779 completed (loss: 1.0894403457641602, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 475/779 [54:45<35:02,  6.92s/it]Training Epoch: 1/1, step 475/779 completed (loss: 1.0894403457641602, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 476/779 [54:51<34:55,  6.92s/it]Training Epoch: 1/1, step 476/779 completed (loss: 1.0891309976577759, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 476/779 [54:52<34:55,  6.92s/it]Training Epoch: 1/1, step 476/779 completed (loss: 1.0891309976577759, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 477/779 [54:58<34:46,  6.91s/it]Training Epoch: 1/1, step 477/779 completed (loss: 0.9409402012825012, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 477/779 [54:58<34:46,  6.91s/it]Training Epoch: 1/1, step 477/779 completed (loss: 0.9409402012825012, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 478/779 [55:05<34:36,  6.90s/it]Training Epoch: 1/1, step 478/779 completed (loss: 0.9524869322776794, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 478/779 [55:05<34:36,  6.90s/it]Training Epoch: 1/1, step 478/779 completed (loss: 0.9524869322776794, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 479/779 [55:12<34:30,  6.90s/it]Training Epoch: 1/1, step 479/779 completed (loss: 0.9841012954711914, lr: 2e-05):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 479/779 [55:12<34:30,  6.90s/it]Training Epoch: 1/1, step 479/779 completed (loss: 0.9841012954711914, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 480/779 [55:19<34:22,  6.90s/it]Training Epoch: 1/1, step 480/779 completed (loss: 1.3106286525726318, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 480/779 [55:19<34:22,  6.90s/it]Training Epoch: 1/1, step 480/779 completed (loss: 1.3106286525726318, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 481/779 [55:26<34:15,  6.90s/it]Training Epoch: 1/1, step 481/779 completed (loss: 1.011641263961792, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 481/779 [55:26<34:15,  6.90s/it] Training Epoch: 1/1, step 481/779 completed (loss: 1.011641263961792, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 482/779 [55:33<34:07,  6.89s/it]Training Epoch: 1/1, step 482/779 completed (loss: 1.0574313402175903, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 482/779 [55:33<34:07,  6.89s/it]Training Epoch: 1/1, step 482/779 completed (loss: 1.0574313402175903, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 483/779 [55:40<34:02,  6.90s/it]Training Epoch: 1/1, step 483/779 completed (loss: 0.9622118473052979, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 483/779 [55:40<34:02,  6.90s/it]Training Epoch: 1/1, step 483/779 completed (loss: 0.9622118473052979, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 484/779 [55:47<33:55,  6.90s/it]Training Epoch: 1/1, step 484/779 completed (loss: 1.1264787912368774, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 484/779 [55:47<33:55,  6.90s/it]Training Epoch: 1/1, step 484/779 completed (loss: 1.1264787912368774, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 485/779 [55:54<33:48,  6.90s/it]Training Epoch: 1/1, step 485/779 completed (loss: 1.196062684059143, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 485/779 [55:54<33:48,  6.90s/it] Training Epoch: 1/1, step 485/779 completed (loss: 1.196062684059143, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 486/779 [56:00<33:41,  6.90s/it]Training Epoch: 1/1, step 486/779 completed (loss: 0.9789540767669678, lr: 2e-05):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 486/779 [56:01<33:41,  6.90s/it]Training Epoch: 1/1, step 486/779 completed (loss: 0.9789540767669678, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 487/779 [56:07<33:34,  6.90s/it]Training Epoch: 1/1, step 487/779 completed (loss: 1.083562970161438, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 487/779 [56:07<33:34,  6.90s/it] Training Epoch: 1/1, step 487/779 completed (loss: 1.083562970161438, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 488/779 [56:14<33:30,  6.91s/it]Training Epoch: 1/1, step 488/779 completed (loss: 1.048730492591858, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 488/779 [56:14<33:30,  6.91s/it]Training Epoch: 1/1, step 488/779 completed (loss: 1.048730492591858, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 489/779 [56:21<33:24,  6.91s/it]Training Epoch: 1/1, step 489/779 completed (loss: 1.1003785133361816, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 489/779 [56:21<33:24,  6.91s/it]Training Epoch: 1/1, step 489/779 completed (loss: 1.1003785133361816, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 490/779 [56:28<33:18,  6.91s/it]Training Epoch: 1/1, step 490/779 completed (loss: 1.236849069595337, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 490/779 [56:28<33:18,  6.91s/it] Training Epoch: 1/1, step 490/779 completed (loss: 1.236849069595337, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 491/779 [56:35<33:12,  6.92s/it]Training Epoch: 1/1, step 491/779 completed (loss: 0.9729769825935364, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 491/779 [56:35<33:12,  6.92s/it]Training Epoch: 1/1, step 491/779 completed (loss: 0.9729769825935364, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 492/779 [56:42<33:05,  6.92s/it]Training Epoch: 1/1, step 492/779 completed (loss: 1.0092781782150269, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 492/779 [56:42<33:05,  6.92s/it]Training Epoch: 1/1, step 492/779 completed (loss: 1.0092781782150269, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 493/779 [56:49<32:55,  6.91s/it]Training Epoch: 1/1, step 493/779 completed (loss: 0.9919893145561218, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 493/779 [56:49<32:55,  6.91s/it]Training Epoch: 1/1, step 493/779 completed (loss: 0.9919893145561218, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 494/779 [56:56<32:47,  6.90s/it]Training Epoch: 1/1, step 494/779 completed (loss: 0.9999642372131348, lr: 2e-05):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 494/779 [56:56<32:47,  6.90s/it]Training Epoch: 1/1, step 494/779 completed (loss: 0.9999642372131348, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 495/779 [57:03<32:44,  6.92s/it]Training Epoch: 1/1, step 495/779 completed (loss: 1.0274051427841187, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 495/779 [57:03<32:44,  6.92s/it]Training Epoch: 1/1, step 495/779 completed (loss: 1.0274051427841187, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 496/779 [57:10<32:35,  6.91s/it]Training Epoch: 1/1, step 496/779 completed (loss: 1.0373055934906006, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 496/779 [57:10<32:35,  6.91s/it]Training Epoch: 1/1, step 496/779 completed (loss: 1.0373055934906006, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 497/779 [57:16<32:27,  6.91s/it]Training Epoch: 1/1, step 497/779 completed (loss: 1.0054761171340942, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 497/779 [57:17<32:27,  6.91s/it]Training Epoch: 1/1, step 497/779 completed (loss: 1.0054761171340942, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 498/779 [57:23<32:21,  6.91s/it]Training Epoch: 1/1, step 498/779 completed (loss: 0.9617273211479187, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 498/779 [57:24<32:21,  6.91s/it]Training Epoch: 1/1, step 498/779 completed (loss: 0.9617273211479187, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 499/779 [57:30<32:17,  6.92s/it]Training Epoch: 1/1, step 499/779 completed (loss: 1.0202850103378296, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 499/779 [57:30<32:17,  6.92s/it]Training Epoch: 1/1, step 499/779 completed (loss: 1.0202850103378296, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 500/779 [57:37<32:10,  6.92s/it]Training Epoch: 1/1, step 500/779 completed (loss: 1.1161547899246216, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 500/779 [57:37<32:10,  6.92s/it]Training Epoch: 1/1, step 500/779 completed (loss: 1.1161547899246216, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 501/779 [57:44<32:03,  6.92s/it]Training Epoch: 1/1, step 501/779 completed (loss: 1.1068679094314575, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 501/779 [57:44<32:03,  6.92s/it]Training Epoch: 1/1, step 501/779 completed (loss: 1.1068679094314575, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 502/779 [57:51<31:54,  6.91s/it]Training Epoch: 1/1, step 502/779 completed (loss: 1.0006771087646484, lr: 2e-05):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 502/779 [57:51<31:54,  6.91s/it]Training Epoch: 1/1, step 502/779 completed (loss: 1.0006771087646484, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 503/779 [57:58<31:46,  6.91s/it]Training Epoch: 1/1, step 503/779 completed (loss: 0.9911145567893982, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 503/779 [57:58<31:46,  6.91s/it]Training Epoch: 1/1, step 503/779 completed (loss: 0.9911145567893982, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 504/779 [58:05<31:39,  6.91s/it]Training Epoch: 1/1, step 504/779 completed (loss: 0.9409234523773193, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 504/779 [58:05<31:39,  6.91s/it]Training Epoch: 1/1, step 504/779 completed (loss: 0.9409234523773193, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 505/779 [58:12<31:33,  6.91s/it]Training Epoch: 1/1, step 505/779 completed (loss: 0.9858568906784058, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 505/779 [58:12<31:33,  6.91s/it]Training Epoch: 1/1, step 505/779 completed (loss: 0.9858568906784058, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 506/779 [58:19<31:27,  6.91s/it]Training Epoch: 1/1, step 506/779 completed (loss: 1.0160105228424072, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 506/779 [58:19<31:27,  6.91s/it]Training Epoch: 1/1, step 506/779 completed (loss: 1.0160105228424072, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 507/779 [58:26<31:19,  6.91s/it]Training Epoch: 1/1, step 507/779 completed (loss: 0.9628806710243225, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 507/779 [58:26<31:19,  6.91s/it]Training Epoch: 1/1, step 507/779 completed (loss: 0.9628806710243225, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 508/779 [58:32<31:11,  6.91s/it]Training Epoch: 1/1, step 508/779 completed (loss: 1.0213398933410645, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 508/779 [58:33<31:11,  6.91s/it]Training Epoch: 1/1, step 508/779 completed (loss: 1.0213398933410645, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 509/779 [58:39<31:03,  6.90s/it]Training Epoch: 1/1, step 509/779 completed (loss: 1.0691118240356445, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 509/779 [58:40<31:03,  6.90s/it]Training Epoch: 1/1, step 509/779 completed (loss: 1.0691118240356445, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 510/779 [58:46<30:56,  6.90s/it]Training Epoch: 1/1, step 510/779 completed (loss: 1.0556074380874634, lr: 2e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 510/779 [58:46<30:56,  6.90s/it]Training Epoch: 1/1, step 510/779 completed (loss: 1.0556074380874634, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 511/779 [58:53<30:49,  6.90s/it]Training Epoch: 1/1, step 511/779 completed (loss: 1.0566139221191406, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 511/779 [58:53<30:49,  6.90s/it]Training Epoch: 1/1, step 511/779 completed (loss: 1.0566139221191406, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 512/779 [59:00<30:42,  6.90s/it]Training Epoch: 1/1, step 512/779 completed (loss: 0.98548823595047, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 512/779 [59:00<30:42,  6.90s/it]  Training Epoch: 1/1, step 512/779 completed (loss: 0.98548823595047, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 513/779 [59:07<30:34,  6.90s/it]Training Epoch: 1/1, step 513/779 completed (loss: 1.0556968450546265, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 513/779 [59:07<30:34,  6.90s/it]Training Epoch: 1/1, step 513/779 completed (loss: 1.0556968450546265, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 514/779 [59:14<30:27,  6.90s/it]Training Epoch: 1/1, step 514/779 completed (loss: 1.0973409414291382, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 514/779 [59:14<30:27,  6.90s/it]Training Epoch: 1/1, step 514/779 completed (loss: 1.0973409414291382, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 515/779 [59:21<30:20,  6.90s/it]Training Epoch: 1/1, step 515/779 completed (loss: 0.9810271263122559, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 515/779 [59:21<30:20,  6.90s/it]Training Epoch: 1/1, step 515/779 completed (loss: 0.9810271263122559, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 516/779 [59:28<30:12,  6.89s/it]Training Epoch: 1/1, step 516/779 completed (loss: 1.1313321590423584, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 516/779 [59:28<30:12,  6.89s/it]Training Epoch: 1/1, step 516/779 completed (loss: 1.1313321590423584, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 517/779 [59:35<30:09,  6.91s/it]Training Epoch: 1/1, step 517/779 completed (loss: 1.1427873373031616, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 517/779 [59:35<30:09,  6.91s/it]Training Epoch: 1/1, step 517/779 completed (loss: 1.1427873373031616, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 518/779 [59:41<30:02,  6.90s/it]Training Epoch: 1/1, step 518/779 completed (loss: 0.9458795189857483, lr: 2e-05):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 518/779 [59:42<30:02,  6.90s/it]Training Epoch: 1/1, step 518/779 completed (loss: 0.9458795189857483, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 519/779 [59:48<29:55,  6.91s/it]Training Epoch: 1/1, step 519/779 completed (loss: 0.9011602997779846, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 519/779 [59:49<29:55,  6.91s/it]Training Epoch: 1/1, step 519/779 completed (loss: 0.9011602997779846, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 520/779 [59:55<29:50,  6.91s/it]Training Epoch: 1/1, step 520/779 completed (loss: 1.0253883600234985, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 520/779 [59:55<29:50,  6.91s/it]Training Epoch: 1/1, step 520/779 completed (loss: 1.0253883600234985, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 521/779 [1:00:02<29:43,  6.91s/it]Training Epoch: 1/1, step 521/779 completed (loss: 1.1097333431243896, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 521/779 [1:00:02<29:43,  6.91s/it]Training Epoch: 1/1, step 521/779 completed (loss: 1.1097333431243896, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 522/779 [1:00:09<29:35,  6.91s/it]Training Epoch: 1/1, step 522/779 completed (loss: 0.9594370126724243, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 522/779 [1:00:09<29:35,  6.91s/it]Training Epoch: 1/1, step 522/779 completed (loss: 0.9594370126724243, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 523/779 [1:00:16<29:28,  6.91s/it]Training Epoch: 1/1, step 523/779 completed (loss: 1.2310750484466553, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 523/779 [1:00:16<29:28,  6.91s/it]Training Epoch: 1/1, step 523/779 completed (loss: 1.2310750484466553, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 524/779 [1:00:23<29:23,  6.92s/it]Training Epoch: 1/1, step 524/779 completed (loss: 0.9619137048721313, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 524/779 [1:00:23<29:23,  6.92s/it]Training Epoch: 1/1, step 524/779 completed (loss: 0.9619137048721313, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 525/779 [1:00:30<29:17,  6.92s/it]Training Epoch: 1/1, step 525/779 completed (loss: 1.0592528581619263, lr: 2e-05):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 525/779 [1:00:30<29:17,  6.92s/it]Training Epoch: 1/1, step 525/779 completed (loss: 1.0592528581619263, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 526/779 [1:00:37<29:09,  6.91s/it]Training Epoch: 1/1, step 526/779 completed (loss: 1.1259108781814575, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 526/779 [1:00:37<29:09,  6.91s/it]Training Epoch: 1/1, step 526/779 completed (loss: 1.1259108781814575, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 527/779 [1:00:44<29:04,  6.92s/it]Training Epoch: 1/1, step 527/779 completed (loss: 1.0824917554855347, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 527/779 [1:00:44<29:04,  6.92s/it]Training Epoch: 1/1, step 527/779 completed (loss: 1.0824917554855347, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 528/779 [1:00:51<28:56,  6.92s/it]Training Epoch: 1/1, step 528/779 completed (loss: 0.9174496531486511, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 528/779 [1:00:51<28:56,  6.92s/it]Training Epoch: 1/1, step 528/779 completed (loss: 0.9174496531486511, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 529/779 [1:00:58<28:48,  6.91s/it]Training Epoch: 1/1, step 529/779 completed (loss: 0.9379013180732727, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 529/779 [1:00:58<28:48,  6.91s/it]Training Epoch: 1/1, step 529/779 completed (loss: 0.9379013180732727, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 530/779 [1:01:04<28:39,  6.91s/it]Training Epoch: 1/1, step 530/779 completed (loss: 1.1069796085357666, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 530/779 [1:01:05<28:39,  6.91s/it]Training Epoch: 1/1, step 530/779 completed (loss: 1.1069796085357666, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 531/779 [1:01:11<28:32,  6.90s/it]Training Epoch: 1/1, step 531/779 completed (loss: 1.074460744857788, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 531/779 [1:01:11<28:32,  6.90s/it] Training Epoch: 1/1, step 531/779 completed (loss: 1.074460744857788, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 532/779 [1:01:18<28:24,  6.90s/it]Training Epoch: 1/1, step 532/779 completed (loss: 1.140005350112915, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 532/779 [1:01:18<28:24,  6.90s/it]Training Epoch: 1/1, step 532/779 completed (loss: 1.140005350112915, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 533/779 [1:01:25<28:17,  6.90s/it]Training Epoch: 1/1, step 533/779 completed (loss: 0.9488487243652344, lr: 2e-05):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 533/779 [1:01:25<28:17,  6.90s/it]Training Epoch: 1/1, step 533/779 completed (loss: 0.9488487243652344, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 534/779 [1:01:32<28:09,  6.89s/it]Training Epoch: 1/1, step 534/779 completed (loss: 1.1292338371276855, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 534/779 [1:01:32<28:09,  6.89s/it]Training Epoch: 1/1, step 534/779 completed (loss: 1.1292338371276855, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 535/779 [1:01:39<28:02,  6.90s/it]Training Epoch: 1/1, step 535/779 completed (loss: 1.008487343788147, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 535/779 [1:01:39<28:02,  6.90s/it] Training Epoch: 1/1, step 535/779 completed (loss: 1.008487343788147, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 536/779 [1:01:46<27:55,  6.89s/it]Training Epoch: 1/1, step 536/779 completed (loss: 1.100403070449829, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 536/779 [1:01:46<27:55,  6.89s/it]Training Epoch: 1/1, step 536/779 completed (loss: 1.100403070449829, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 537/779 [1:01:53<27:49,  6.90s/it]Training Epoch: 1/1, step 537/779 completed (loss: 0.9956182837486267, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 537/779 [1:01:53<27:49,  6.90s/it]Training Epoch: 1/1, step 537/779 completed (loss: 0.9956182837486267, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 538/779 [1:02:00<27:42,  6.90s/it]Training Epoch: 1/1, step 538/779 completed (loss: 1.2568635940551758, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 538/779 [1:02:00<27:42,  6.90s/it]Training Epoch: 1/1, step 538/779 completed (loss: 1.2568635940551758, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 539/779 [1:02:07<27:36,  6.90s/it]Training Epoch: 1/1, step 539/779 completed (loss: 1.1242913007736206, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 539/779 [1:02:07<27:36,  6.90s/it]Training Epoch: 1/1, step 539/779 completed (loss: 1.1242913007736206, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 540/779 [1:02:13<27:29,  6.90s/it]Training Epoch: 1/1, step 540/779 completed (loss: 1.2001477479934692, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 540/779 [1:02:14<27:29,  6.90s/it]Training Epoch: 1/1, step 540/779 completed (loss: 1.2001477479934692, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 541/779 [1:02:20<27:23,  6.91s/it]Training Epoch: 1/1, step 541/779 completed (loss: 0.9704339504241943, lr: 2e-05):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 541/779 [1:02:20<27:23,  6.91s/it]Training Epoch: 1/1, step 541/779 completed (loss: 0.9704339504241943, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 542/779 [1:02:27<27:18,  6.91s/it]Training Epoch: 1/1, step 542/779 completed (loss: 1.0936617851257324, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 542/779 [1:02:27<27:18,  6.91s/it]Training Epoch: 1/1, step 542/779 completed (loss: 1.0936617851257324, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 543/779 [1:02:34<27:11,  6.91s/it]Training Epoch: 1/1, step 543/779 completed (loss: 0.8626328706741333, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 543/779 [1:02:34<27:11,  6.91s/it]Training Epoch: 1/1, step 543/779 completed (loss: 0.8626328706741333, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 544/779 [1:02:41<27:04,  6.91s/it]Training Epoch: 1/1, step 544/779 completed (loss: 1.1955924034118652, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 544/779 [1:02:41<27:04,  6.91s/it]Training Epoch: 1/1, step 544/779 completed (loss: 1.1955924034118652, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 545/779 [1:02:48<26:58,  6.92s/it]Training Epoch: 1/1, step 545/779 completed (loss: 1.156352162361145, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 545/779 [1:02:48<26:58,  6.92s/it] Training Epoch: 1/1, step 545/779 completed (loss: 1.156352162361145, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 546/779 [1:02:55<26:51,  6.92s/it]Training Epoch: 1/1, step 546/779 completed (loss: 0.9323551654815674, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 546/779 [1:02:55<26:51,  6.92s/it]Training Epoch: 1/1, step 546/779 completed (loss: 0.9323551654815674, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 547/779 [1:03:02<26:43,  6.91s/it]Training Epoch: 1/1, step 547/779 completed (loss: 1.0596281290054321, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 547/779 [1:03:02<26:43,  6.91s/it]Training Epoch: 1/1, step 547/779 completed (loss: 1.0596281290054321, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 548/779 [1:03:09<26:36,  6.91s/it]Training Epoch: 1/1, step 548/779 completed (loss: 1.144933819770813, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 548/779 [1:03:09<26:36,  6.91s/it] Training Epoch: 1/1, step 548/779 completed (loss: 1.144933819770813, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 549/779 [1:03:16<26:31,  6.92s/it]Training Epoch: 1/1, step 549/779 completed (loss: 0.7922507524490356, lr: 2e-05):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 549/779 [1:03:16<26:31,  6.92s/it]Training Epoch: 1/1, step 549/779 completed (loss: 0.7922507524490356, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 550/779 [1:03:23<26:24,  6.92s/it]Training Epoch: 1/1, step 550/779 completed (loss: 1.1928058862686157, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 550/779 [1:03:23<26:24,  6.92s/it]Training Epoch: 1/1, step 550/779 completed (loss: 1.1928058862686157, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 551/779 [1:03:30<26:17,  6.92s/it]Training Epoch: 1/1, step 551/779 completed (loss: 0.8155030608177185, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 551/779 [1:03:30<26:17,  6.92s/it]Training Epoch: 1/1, step 551/779 completed (loss: 0.8155030608177185, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 552/779 [1:03:36<26:09,  6.91s/it]Training Epoch: 1/1, step 552/779 completed (loss: 1.0998904705047607, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 552/779 [1:03:37<26:09,  6.91s/it]Training Epoch: 1/1, step 552/779 completed (loss: 1.0998904705047607, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 553/779 [1:03:43<26:01,  6.91s/it]Training Epoch: 1/1, step 553/779 completed (loss: 1.1013175249099731, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 553/779 [1:03:43<26:01,  6.91s/it]Training Epoch: 1/1, step 553/779 completed (loss: 1.1013175249099731, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 554/779 [1:03:50<25:53,  6.90s/it]Training Epoch: 1/1, step 554/779 completed (loss: 1.0481936931610107, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 554/779 [1:03:50<25:53,  6.90s/it]Training Epoch: 1/1, step 554/779 completed (loss: 1.0481936931610107, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 555/779 [1:03:57<25:47,  6.91s/it]Training Epoch: 1/1, step 555/779 completed (loss: 1.007053017616272, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 555/779 [1:03:57<25:47,  6.91s/it] Training Epoch: 1/1, step 555/779 completed (loss: 1.007053017616272, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 556/779 [1:04:04<25:40,  6.91s/it]Training Epoch: 1/1, step 556/779 completed (loss: 1.0551259517669678, lr: 2e-05):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 556/779 [1:04:04<25:40,  6.91s/it]Training Epoch: 1/1, step 556/779 completed (loss: 1.0551259517669678, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 557/779 [1:04:11<25:33,  6.91s/it]Training Epoch: 1/1, step 557/779 completed (loss: 0.9033882021903992, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 557/779 [1:04:11<25:33,  6.91s/it]Training Epoch: 1/1, step 557/779 completed (loss: 0.9033882021903992, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 558/779 [1:04:18<25:27,  6.91s/it]Training Epoch: 1/1, step 558/779 completed (loss: 1.0583816766738892, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 558/779 [1:04:18<25:27,  6.91s/it]Training Epoch: 1/1, step 558/779 completed (loss: 1.0583816766738892, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 559/779 [1:04:25<25:19,  6.91s/it]Training Epoch: 1/1, step 559/779 completed (loss: 1.0122390985488892, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 559/779 [1:04:25<25:19,  6.91s/it]Training Epoch: 1/1, step 559/779 completed (loss: 1.0122390985488892, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 560/779 [1:04:32<25:13,  6.91s/it]Training Epoch: 1/1, step 560/779 completed (loss: 0.9526402950286865, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 560/779 [1:04:32<25:13,  6.91s/it]Training Epoch: 1/1, step 560/779 completed (loss: 0.9526402950286865, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 561/779 [1:04:39<25:05,  6.91s/it]Training Epoch: 1/1, step 561/779 completed (loss: 1.067641258239746, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 561/779 [1:04:39<25:05,  6.91s/it] Training Epoch: 1/1, step 561/779 completed (loss: 1.067641258239746, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 562/779 [1:04:45<24:58,  6.90s/it]Training Epoch: 1/1, step 562/779 completed (loss: 1.1309947967529297, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 562/779 [1:04:46<24:58,  6.90s/it]Training Epoch: 1/1, step 562/779 completed (loss: 1.1309947967529297, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 563/779 [1:04:52<24:51,  6.90s/it]Training Epoch: 1/1, step 563/779 completed (loss: 1.1804962158203125, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 563/779 [1:04:53<24:51,  6.90s/it]Training Epoch: 1/1, step 563/779 completed (loss: 1.1804962158203125, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 564/779 [1:04:59<24:47,  6.92s/it]Training Epoch: 1/1, step 564/779 completed (loss: 1.1536471843719482, lr: 2e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 564/779 [1:04:59<24:47,  6.92s/it]Training Epoch: 1/1, step 564/779 completed (loss: 1.1536471843719482, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 565/779 [1:05:06<24:39,  6.91s/it]Training Epoch: 1/1, step 565/779 completed (loss: 0.7587885856628418, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 565/779 [1:05:06<24:39,  6.91s/it]Training Epoch: 1/1, step 565/779 completed (loss: 0.7587885856628418, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 566/779 [1:05:13<24:31,  6.91s/it]Training Epoch: 1/1, step 566/779 completed (loss: 1.0894930362701416, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 566/779 [1:05:13<24:31,  6.91s/it]Training Epoch: 1/1, step 566/779 completed (loss: 1.0894930362701416, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 567/779 [1:05:20<24:25,  6.91s/it]Training Epoch: 1/1, step 567/779 completed (loss: 1.148125171661377, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 567/779 [1:05:20<24:25,  6.91s/it] Training Epoch: 1/1, step 567/779 completed (loss: 1.148125171661377, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 568/779 [1:05:27<24:18,  6.91s/it]Training Epoch: 1/1, step 568/779 completed (loss: 0.9783930778503418, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 568/779 [1:05:27<24:18,  6.91s/it]Training Epoch: 1/1, step 568/779 completed (loss: 0.9783930778503418, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 569/779 [1:05:34<24:11,  6.91s/it]Training Epoch: 1/1, step 569/779 completed (loss: 1.0218467712402344, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 569/779 [1:05:34<24:11,  6.91s/it]Training Epoch: 1/1, step 569/779 completed (loss: 1.0218467712402344, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 570/779 [1:05:41<24:06,  6.92s/it]Training Epoch: 1/1, step 570/779 completed (loss: 1.0014759302139282, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 570/779 [1:05:41<24:06,  6.92s/it]Training Epoch: 1/1, step 570/779 completed (loss: 1.0014759302139282, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 571/779 [1:05:48<23:59,  6.92s/it]Training Epoch: 1/1, step 571/779 completed (loss: 0.9501882791519165, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 571/779 [1:05:48<23:59,  6.92s/it]Training Epoch: 1/1, step 571/779 completed (loss: 0.9501882791519165, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 572/779 [1:05:55<23:52,  6.92s/it]Training Epoch: 1/1, step 572/779 completed (loss: 1.0079007148742676, lr: 2e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 572/779 [1:05:55<23:52,  6.92s/it]Training Epoch: 1/1, step 572/779 completed (loss: 1.0079007148742676, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 573/779 [1:06:02<23:45,  6.92s/it]Training Epoch: 1/1, step 573/779 completed (loss: 1.2607858180999756, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 573/779 [1:06:02<23:45,  6.92s/it]Training Epoch: 1/1, step 573/779 completed (loss: 1.2607858180999756, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 574/779 [1:06:08<23:38,  6.92s/it]Training Epoch: 1/1, step 574/779 completed (loss: 1.2743629217147827, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 574/779 [1:06:09<23:38,  6.92s/it]Training Epoch: 1/1, step 574/779 completed (loss: 1.2743629217147827, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 575/779 [1:06:15<23:32,  6.92s/it]Training Epoch: 1/1, step 575/779 completed (loss: 1.1946007013320923, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 575/779 [1:06:16<23:32,  6.92s/it]Training Epoch: 1/1, step 575/779 completed (loss: 1.1946007013320923, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 576/779 [1:06:22<23:23,  6.91s/it]Training Epoch: 1/1, step 576/779 completed (loss: 1.012627363204956, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 576/779 [1:06:22<23:23,  6.91s/it] Training Epoch: 1/1, step 576/779 completed (loss: 1.012627363204956, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 577/779 [1:06:29<23:16,  6.91s/it]Training Epoch: 1/1, step 577/779 completed (loss: 1.0285652875900269, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 577/779 [1:06:29<23:16,  6.91s/it]Training Epoch: 1/1, step 577/779 completed (loss: 1.0285652875900269, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 578/779 [1:06:36<23:08,  6.91s/it]Training Epoch: 1/1, step 578/779 completed (loss: 1.1047863960266113, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 578/779 [1:06:36<23:08,  6.91s/it]Training Epoch: 1/1, step 578/779 completed (loss: 1.1047863960266113, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 579/779 [1:06:43<23:01,  6.91s/it]Training Epoch: 1/1, step 579/779 completed (loss: 0.9505685567855835, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 579/779 [1:06:43<23:01,  6.91s/it]Training Epoch: 1/1, step 579/779 completed (loss: 0.9505685567855835, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 580/779 [1:06:50<22:53,  6.90s/it]Training Epoch: 1/1, step 580/779 completed (loss: 1.0442759990692139, lr: 2e-05):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 580/779 [1:06:50<22:53,  6.90s/it]Training Epoch: 1/1, step 580/779 completed (loss: 1.0442759990692139, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 581/779 [1:06:57<22:45,  6.90s/it]Training Epoch: 1/1, step 581/779 completed (loss: 1.036450982093811, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 581/779 [1:06:57<22:45,  6.90s/it] Training Epoch: 1/1, step 581/779 completed (loss: 1.036450982093811, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 582/779 [1:07:04<22:39,  6.90s/it]Training Epoch: 1/1, step 582/779 completed (loss: 1.114872694015503, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 582/779 [1:07:04<22:39,  6.90s/it]Training Epoch: 1/1, step 582/779 completed (loss: 1.114872694015503, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 583/779 [1:07:11<22:32,  6.90s/it]Training Epoch: 1/1, step 583/779 completed (loss: 1.0848358869552612, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 583/779 [1:07:11<22:32,  6.90s/it]Training Epoch: 1/1, step 583/779 completed (loss: 1.0848358869552612, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 584/779 [1:07:18<22:25,  6.90s/it]Training Epoch: 1/1, step 584/779 completed (loss: 0.8225284218788147, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 584/779 [1:07:18<22:25,  6.90s/it]Training Epoch: 1/1, step 584/779 completed (loss: 0.8225284218788147, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 585/779 [1:07:24<22:19,  6.90s/it]Training Epoch: 1/1, step 585/779 completed (loss: 0.9934154748916626, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 585/779 [1:07:25<22:19,  6.90s/it]Training Epoch: 1/1, step 585/779 completed (loss: 0.9934154748916626, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 586/779 [1:07:31<22:11,  6.90s/it]Training Epoch: 1/1, step 586/779 completed (loss: 1.187497854232788, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 586/779 [1:07:31<22:11,  6.90s/it] Training Epoch: 1/1, step 586/779 completed (loss: 1.187497854232788, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 587/779 [1:07:38<22:03,  6.89s/it]Training Epoch: 1/1, step 587/779 completed (loss: 1.0032610893249512, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 587/779 [1:07:38<22:03,  6.89s/it]Training Epoch: 1/1, step 587/779 completed (loss: 1.0032610893249512, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 588/779 [1:07:45<21:57,  6.90s/it]Training Epoch: 1/1, step 588/779 completed (loss: 0.9718846678733826, lr: 2e-05):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 588/779 [1:07:45<21:57,  6.90s/it]Training Epoch: 1/1, step 588/779 completed (loss: 0.9718846678733826, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 589/779 [1:07:52<21:50,  6.90s/it]Training Epoch: 1/1, step 589/779 completed (loss: 1.2932530641555786, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 589/779 [1:07:52<21:50,  6.90s/it]Training Epoch: 1/1, step 589/779 completed (loss: 1.2932530641555786, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 590/779 [1:07:59<21:43,  6.90s/it]Training Epoch: 1/1, step 590/779 completed (loss: 1.1090190410614014, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 590/779 [1:07:59<21:43,  6.90s/it]Training Epoch: 1/1, step 590/779 completed (loss: 1.1090190410614014, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 591/779 [1:08:06<21:36,  6.90s/it]Training Epoch: 1/1, step 591/779 completed (loss: 0.9779297113418579, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 591/779 [1:08:06<21:36,  6.90s/it]Training Epoch: 1/1, step 591/779 completed (loss: 0.9779297113418579, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 592/779 [1:08:13<21:30,  6.90s/it]Training Epoch: 1/1, step 592/779 completed (loss: 1.0973838567733765, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 592/779 [1:08:13<21:30,  6.90s/it]Training Epoch: 1/1, step 592/779 completed (loss: 1.0973838567733765, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 593/779 [1:08:20<21:22,  6.90s/it]Training Epoch: 1/1, step 593/779 completed (loss: 0.9784671068191528, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 593/779 [1:08:20<21:22,  6.90s/it]Training Epoch: 1/1, step 593/779 completed (loss: 0.9784671068191528, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 594/779 [1:08:27<21:17,  6.90s/it]Training Epoch: 1/1, step 594/779 completed (loss: 1.0557224750518799, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 594/779 [1:08:27<21:17,  6.90s/it]Training Epoch: 1/1, step 594/779 completed (loss: 1.0557224750518799, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 595/779 [1:08:33<21:09,  6.90s/it]Training Epoch: 1/1, step 595/779 completed (loss: 1.0372048616409302, lr: 2e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 595/779 [1:08:34<21:09,  6.90s/it]Training Epoch: 1/1, step 595/779 completed (loss: 1.0372048616409302, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 596/779 [1:08:40<21:04,  6.91s/it]Training Epoch: 1/1, step 596/779 completed (loss: 1.1198625564575195, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 596/779 [1:08:40<21:04,  6.91s/it]Training Epoch: 1/1, step 596/779 completed (loss: 1.1198625564575195, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 597/779 [1:08:47<20:58,  6.92s/it]Training Epoch: 1/1, step 597/779 completed (loss: 0.9723303318023682, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 597/779 [1:08:47<20:58,  6.92s/it]Training Epoch: 1/1, step 597/779 completed (loss: 0.9723303318023682, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 598/779 [1:08:54<20:51,  6.91s/it]Training Epoch: 1/1, step 598/779 completed (loss: 1.0363054275512695, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 598/779 [1:08:54<20:51,  6.91s/it]Training Epoch: 1/1, step 598/779 completed (loss: 1.0363054275512695, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 599/779 [1:09:01<20:44,  6.91s/it]Training Epoch: 1/1, step 599/779 completed (loss: 1.191632628440857, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 599/779 [1:09:01<20:44,  6.91s/it] Training Epoch: 1/1, step 599/779 completed (loss: 1.191632628440857, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 600/779 [1:09:08<20:37,  6.91s/it]Training Epoch: 1/1, step 600/779 completed (loss: 1.1675437688827515, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 600/779 [1:09:08<20:37,  6.91s/it]Training Epoch: 1/1, step 600/779 completed (loss: 1.1675437688827515, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 601/779 [1:09:15<20:29,  6.91s/it]Training Epoch: 1/1, step 601/779 completed (loss: 0.9072204232215881, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 601/779 [1:09:15<20:29,  6.91s/it]Training Epoch: 1/1, step 601/779 completed (loss: 0.9072204232215881, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 602/779 [1:09:22<20:23,  6.91s/it]Training Epoch: 1/1, step 602/779 completed (loss: 1.1904118061065674, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 602/779 [1:09:22<20:23,  6.91s/it]Training Epoch: 1/1, step 602/779 completed (loss: 1.1904118061065674, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 603/779 [1:09:29<20:16,  6.91s/it]Training Epoch: 1/1, step 603/779 completed (loss: 1.1357001066207886, lr: 2e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 603/779 [1:09:29<20:16,  6.91s/it]Training Epoch: 1/1, step 603/779 completed (loss: 1.1357001066207886, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 604/779 [1:09:36<20:07,  6.90s/it]Training Epoch: 1/1, step 604/779 completed (loss: 1.1052616834640503, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 604/779 [1:09:36<20:07,  6.90s/it]Training Epoch: 1/1, step 604/779 completed (loss: 1.1052616834640503, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 605/779 [1:09:43<20:00,  6.90s/it]Training Epoch: 1/1, step 605/779 completed (loss: 1.0328391790390015, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 605/779 [1:09:43<20:00,  6.90s/it]Training Epoch: 1/1, step 605/779 completed (loss: 1.0328391790390015, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 606/779 [1:09:49<19:53,  6.90s/it]Training Epoch: 1/1, step 606/779 completed (loss: 0.9976106882095337, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 606/779 [1:09:50<19:53,  6.90s/it]Training Epoch: 1/1, step 606/779 completed (loss: 0.9976106882095337, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 607/779 [1:09:56<19:47,  6.90s/it]Training Epoch: 1/1, step 607/779 completed (loss: 1.0037919282913208, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 607/779 [1:09:56<19:47,  6.90s/it]Training Epoch: 1/1, step 607/779 completed (loss: 1.0037919282913208, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 608/779 [1:10:03<19:39,  6.90s/it]Training Epoch: 1/1, step 608/779 completed (loss: 1.0343502759933472, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 608/779 [1:10:03<19:39,  6.90s/it]Training Epoch: 1/1, step 608/779 completed (loss: 1.0343502759933472, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 609/779 [1:10:10<19:32,  6.89s/it]Training Epoch: 1/1, step 609/779 completed (loss: 0.9644603133201599, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 609/779 [1:10:10<19:32,  6.89s/it]Training Epoch: 1/1, step 609/779 completed (loss: 0.9644603133201599, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 610/779 [1:10:17<19:25,  6.89s/it]Training Epoch: 1/1, step 610/779 completed (loss: 1.1514801979064941, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 610/779 [1:10:17<19:25,  6.89s/it]Training Epoch: 1/1, step 610/779 completed (loss: 1.1514801979064941, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 611/779 [1:10:24<19:18,  6.90s/it]Training Epoch: 1/1, step 611/779 completed (loss: 0.9438385367393494, lr: 2e-05):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 611/779 [1:10:24<19:18,  6.90s/it]Training Epoch: 1/1, step 611/779 completed (loss: 0.9438385367393494, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 612/779 [1:10:31<19:12,  6.90s/it]Training Epoch: 1/1, step 612/779 completed (loss: 1.0833970308303833, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 612/779 [1:10:31<19:12,  6.90s/it]Training Epoch: 1/1, step 612/779 completed (loss: 1.0833970308303833, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 613/779 [1:10:38<19:06,  6.90s/it]Training Epoch: 1/1, step 613/779 completed (loss: 1.2158904075622559, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 613/779 [1:10:38<19:06,  6.90s/it]Training Epoch: 1/1, step 613/779 completed (loss: 1.2158904075622559, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 614/779 [1:10:45<18:59,  6.91s/it]Training Epoch: 1/1, step 614/779 completed (loss: 1.0799517631530762, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 614/779 [1:10:45<18:59,  6.91s/it]Training Epoch: 1/1, step 614/779 completed (loss: 1.0799517631530762, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 615/779 [1:10:52<18:53,  6.91s/it]Training Epoch: 1/1, step 615/779 completed (loss: 1.0445562601089478, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 615/779 [1:10:52<18:53,  6.91s/it]Training Epoch: 1/1, step 615/779 completed (loss: 1.0445562601089478, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 616/779 [1:10:58<18:46,  6.91s/it]Training Epoch: 1/1, step 616/779 completed (loss: 0.9533644318580627, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 616/779 [1:10:59<18:46,  6.91s/it]Training Epoch: 1/1, step 616/779 completed (loss: 0.9533644318580627, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 617/779 [1:11:05<18:40,  6.91s/it]Training Epoch: 1/1, step 617/779 completed (loss: 0.9782456755638123, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 617/779 [1:11:05<18:40,  6.91s/it]Training Epoch: 1/1, step 617/779 completed (loss: 0.9782456755638123, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 618/779 [1:11:12<18:33,  6.91s/it]Training Epoch: 1/1, step 618/779 completed (loss: 0.9756789803504944, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 618/779 [1:11:12<18:33,  6.91s/it]Training Epoch: 1/1, step 618/779 completed (loss: 0.9756789803504944, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 619/779 [1:11:19<18:26,  6.92s/it]Training Epoch: 1/1, step 619/779 completed (loss: 1.1454713344573975, lr: 2e-05):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 619/779 [1:11:19<18:26,  6.92s/it]Training Epoch: 1/1, step 619/779 completed (loss: 1.1454713344573975, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 620/779 [1:11:26<18:19,  6.92s/it]Training Epoch: 1/1, step 620/779 completed (loss: 0.9623420834541321, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 620/779 [1:11:26<18:19,  6.92s/it]Training Epoch: 1/1, step 620/779 completed (loss: 0.9623420834541321, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 621/779 [1:11:33<18:12,  6.92s/it]Training Epoch: 1/1, step 621/779 completed (loss: 0.9496227502822876, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 621/779 [1:11:33<18:12,  6.92s/it]Training Epoch: 1/1, step 621/779 completed (loss: 0.9496227502822876, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 622/779 [1:11:40<18:06,  6.92s/it]Training Epoch: 1/1, step 622/779 completed (loss: 1.0459450483322144, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 622/779 [1:11:40<18:06,  6.92s/it]Training Epoch: 1/1, step 622/779 completed (loss: 1.0459450483322144, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 623/779 [1:11:47<17:59,  6.92s/it]Training Epoch: 1/1, step 623/779 completed (loss: 1.1007739305496216, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 623/779 [1:11:47<17:59,  6.92s/it]Training Epoch: 1/1, step 623/779 completed (loss: 1.1007739305496216, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 624/779 [1:11:54<17:52,  6.92s/it]Training Epoch: 1/1, step 624/779 completed (loss: 1.1389974355697632, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 624/779 [1:11:54<17:52,  6.92s/it]Training Epoch: 1/1, step 624/779 completed (loss: 1.1389974355697632, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 625/779 [1:12:01<17:45,  6.92s/it]Training Epoch: 1/1, step 625/779 completed (loss: 1.1552575826644897, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 625/779 [1:12:01<17:45,  6.92s/it]Training Epoch: 1/1, step 625/779 completed (loss: 1.1552575826644897, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 626/779 [1:12:08<17:38,  6.92s/it]Training Epoch: 1/1, step 626/779 completed (loss: 1.1928799152374268, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 626/779 [1:12:08<17:38,  6.92s/it]Training Epoch: 1/1, step 626/779 completed (loss: 1.1928799152374268, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 627/779 [1:12:15<17:31,  6.92s/it]Training Epoch: 1/1, step 627/779 completed (loss: 0.9136508107185364, lr: 2e-05):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 627/779 [1:12:15<17:31,  6.92s/it]Training Epoch: 1/1, step 627/779 completed (loss: 0.9136508107185364, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 628/779 [1:12:21<17:24,  6.92s/it]Training Epoch: 1/1, step 628/779 completed (loss: 1.1950236558914185, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 628/779 [1:12:22<17:24,  6.92s/it]Training Epoch: 1/1, step 628/779 completed (loss: 1.1950236558914185, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 629/779 [1:12:28<17:17,  6.92s/it]Training Epoch: 1/1, step 629/779 completed (loss: 0.9886036515235901, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 629/779 [1:12:29<17:17,  6.92s/it]Training Epoch: 1/1, step 629/779 completed (loss: 0.9886036515235901, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 630/779 [1:12:35<17:11,  6.92s/it]Training Epoch: 1/1, step 630/779 completed (loss: 1.0377124547958374, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 630/779 [1:12:35<17:11,  6.92s/it]Training Epoch: 1/1, step 630/779 completed (loss: 1.0377124547958374, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 631/779 [1:12:42<17:03,  6.92s/it]Training Epoch: 1/1, step 631/779 completed (loss: 1.1456125974655151, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 631/779 [1:12:42<17:03,  6.92s/it]Training Epoch: 1/1, step 631/779 completed (loss: 1.1456125974655151, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 632/779 [1:12:49<16:56,  6.92s/it]Training Epoch: 1/1, step 632/779 completed (loss: 1.2682826519012451, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 632/779 [1:12:49<16:56,  6.92s/it]Training Epoch: 1/1, step 632/779 completed (loss: 1.2682826519012451, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 633/779 [1:12:56<16:49,  6.92s/it]Training Epoch: 1/1, step 633/779 completed (loss: 1.0858092308044434, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 633/779 [1:12:56<16:49,  6.92s/it]Training Epoch: 1/1, step 633/779 completed (loss: 1.0858092308044434, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 634/779 [1:13:03<16:43,  6.92s/it]Training Epoch: 1/1, step 634/779 completed (loss: 1.1547572612762451, lr: 2e-05):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 634/779 [1:13:03<16:43,  6.92s/it]Training Epoch: 1/1, step 634/779 completed (loss: 1.1547572612762451, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 635/779 [1:13:10<16:35,  6.91s/it]Training Epoch: 1/1, step 635/779 completed (loss: 1.1278311014175415, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 635/779 [1:13:10<16:35,  6.91s/it]Training Epoch: 1/1, step 635/779 completed (loss: 1.1278311014175415, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 636/779 [1:13:17<16:29,  6.92s/it]Training Epoch: 1/1, step 636/779 completed (loss: 0.9822086095809937, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 636/779 [1:13:17<16:29,  6.92s/it]Training Epoch: 1/1, step 636/779 completed (loss: 0.9822086095809937, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 637/779 [1:13:24<16:21,  6.91s/it]Training Epoch: 1/1, step 637/779 completed (loss: 1.1662240028381348, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 637/779 [1:13:24<16:21,  6.91s/it]Training Epoch: 1/1, step 637/779 completed (loss: 1.1662240028381348, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 638/779 [1:13:31<16:15,  6.92s/it]Training Epoch: 1/1, step 638/779 completed (loss: 1.202027440071106, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 638/779 [1:13:31<16:15,  6.92s/it] Training Epoch: 1/1, step 638/779 completed (loss: 1.202027440071106, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 639/779 [1:13:38<16:08,  6.92s/it]Training Epoch: 1/1, step 639/779 completed (loss: 1.0767992734909058, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 639/779 [1:13:38<16:08,  6.92s/it]Training Epoch: 1/1, step 639/779 completed (loss: 1.0767992734909058, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 640/779 [1:13:45<16:02,  6.92s/it]Training Epoch: 1/1, step 640/779 completed (loss: 1.2678658962249756, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 640/779 [1:13:45<16:02,  6.92s/it]Training Epoch: 1/1, step 640/779 completed (loss: 1.2678658962249756, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 641/779 [1:13:51<15:55,  6.93s/it]Training Epoch: 1/1, step 641/779 completed (loss: 0.909472644329071, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 641/779 [1:13:52<15:55,  6.93s/it] Training Epoch: 1/1, step 641/779 completed (loss: 0.909472644329071, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 642/779 [1:13:58<15:48,  6.92s/it]Training Epoch: 1/1, step 642/779 completed (loss: 1.2017922401428223, lr: 2e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 642/779 [1:13:58<15:48,  6.92s/it]Training Epoch: 1/1, step 642/779 completed (loss: 1.2017922401428223, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 643/779 [1:14:05<15:41,  6.92s/it]Training Epoch: 1/1, step 643/779 completed (loss: 1.0452176332473755, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 643/779 [1:14:05<15:41,  6.92s/it]Training Epoch: 1/1, step 643/779 completed (loss: 1.0452176332473755, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 644/779 [1:14:12<15:33,  6.92s/it]Training Epoch: 1/1, step 644/779 completed (loss: 1.0106532573699951, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 644/779 [1:14:12<15:33,  6.92s/it]Training Epoch: 1/1, step 644/779 completed (loss: 1.0106532573699951, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 645/779 [1:14:19<15:26,  6.91s/it]Training Epoch: 1/1, step 645/779 completed (loss: 1.0393158197402954, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 645/779 [1:14:19<15:26,  6.91s/it]Training Epoch: 1/1, step 645/779 completed (loss: 1.0393158197402954, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 646/779 [1:14:26<15:18,  6.91s/it]Training Epoch: 1/1, step 646/779 completed (loss: 0.9086017608642578, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 646/779 [1:14:26<15:18,  6.91s/it]Training Epoch: 1/1, step 646/779 completed (loss: 0.9086017608642578, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 647/779 [1:14:33<15:12,  6.92s/it]Training Epoch: 1/1, step 647/779 completed (loss: 1.0866185426712036, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 647/779 [1:14:33<15:12,  6.92s/it]Training Epoch: 1/1, step 647/779 completed (loss: 1.0866185426712036, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 648/779 [1:14:40<15:06,  6.92s/it]Training Epoch: 1/1, step 648/779 completed (loss: 1.044284462928772, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 648/779 [1:14:40<15:06,  6.92s/it] Training Epoch: 1/1, step 648/779 completed (loss: 1.044284462928772, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 649/779 [1:14:47<14:59,  6.92s/it]Training Epoch: 1/1, step 649/779 completed (loss: 1.1419885158538818, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 649/779 [1:14:47<14:59,  6.92s/it]Training Epoch: 1/1, step 649/779 completed (loss: 1.1419885158538818, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 650/779 [1:14:54<14:52,  6.92s/it]Training Epoch: 1/1, step 650/779 completed (loss: 0.9446946978569031, lr: 2e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 650/779 [1:14:54<14:52,  6.92s/it]Training Epoch: 1/1, step 650/779 completed (loss: 0.9446946978569031, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 651/779 [1:15:01<14:44,  6.91s/it]Training Epoch: 1/1, step 651/779 completed (loss: 1.0990666151046753, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 651/779 [1:15:01<14:44,  6.91s/it]Training Epoch: 1/1, step 651/779 completed (loss: 1.0990666151046753, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 652/779 [1:15:07<14:37,  6.91s/it]Training Epoch: 1/1, step 652/779 completed (loss: 1.0178009271621704, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 652/779 [1:15:08<14:37,  6.91s/it]Training Epoch: 1/1, step 652/779 completed (loss: 1.0178009271621704, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 653/779 [1:15:14<14:30,  6.91s/it]Training Epoch: 1/1, step 653/779 completed (loss: 0.8980300426483154, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 653/779 [1:15:15<14:30,  6.91s/it]Training Epoch: 1/1, step 653/779 completed (loss: 0.8980300426483154, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 654/779 [1:15:21<14:24,  6.92s/it]Training Epoch: 1/1, step 654/779 completed (loss: 1.182155966758728, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 654/779 [1:15:21<14:24,  6.92s/it] Training Epoch: 1/1, step 654/779 completed (loss: 1.182155966758728, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 655/779 [1:15:28<14:17,  6.92s/it]Training Epoch: 1/1, step 655/779 completed (loss: 0.99260413646698, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 655/779 [1:15:28<14:17,  6.92s/it] Training Epoch: 1/1, step 655/779 completed (loss: 0.99260413646698, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 656/779 [1:15:35<14:10,  6.91s/it]Training Epoch: 1/1, step 656/779 completed (loss: 1.0797526836395264, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 656/779 [1:15:35<14:10,  6.91s/it]Training Epoch: 1/1, step 656/779 completed (loss: 1.0797526836395264, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 657/779 [1:15:42<14:03,  6.92s/it]Training Epoch: 1/1, step 657/779 completed (loss: 1.1267389059066772, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 657/779 [1:15:42<14:03,  6.92s/it]Training Epoch: 1/1, step 657/779 completed (loss: 1.1267389059066772, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 658/779 [1:15:49<13:56,  6.91s/it]Training Epoch: 1/1, step 658/779 completed (loss: 1.094787836074829, lr: 2e-05):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 658/779 [1:15:49<13:56,  6.91s/it] Training Epoch: 1/1, step 658/779 completed (loss: 1.094787836074829, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 659/779 [1:15:56<13:49,  6.91s/it]Training Epoch: 1/1, step 659/779 completed (loss: 0.9873736500740051, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 659/779 [1:15:56<13:49,  6.91s/it]Training Epoch: 1/1, step 659/779 completed (loss: 0.9873736500740051, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 660/779 [1:16:03<13:42,  6.91s/it]Training Epoch: 1/1, step 660/779 completed (loss: 0.9341359734535217, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 660/779 [1:16:03<13:42,  6.91s/it]Training Epoch: 1/1, step 660/779 completed (loss: 0.9341359734535217, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 661/779 [1:16:10<13:34,  6.90s/it]Training Epoch: 1/1, step 661/779 completed (loss: 0.9192460775375366, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 661/779 [1:16:10<13:34,  6.90s/it]Training Epoch: 1/1, step 661/779 completed (loss: 0.9192460775375366, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 662/779 [1:16:17<13:28,  6.91s/it]Training Epoch: 1/1, step 662/779 completed (loss: 0.7878642678260803, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 662/779 [1:16:17<13:28,  6.91s/it]Training Epoch: 1/1, step 662/779 completed (loss: 0.7878642678260803, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 663/779 [1:16:24<13:21,  6.91s/it]Training Epoch: 1/1, step 663/779 completed (loss: 1.2013664245605469, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 663/779 [1:16:24<13:21,  6.91s/it]Training Epoch: 1/1, step 663/779 completed (loss: 1.2013664245605469, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 664/779 [1:16:30<13:13,  6.90s/it]Training Epoch: 1/1, step 664/779 completed (loss: 1.1894519329071045, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 664/779 [1:16:31<13:13,  6.90s/it]Training Epoch: 1/1, step 664/779 completed (loss: 1.1894519329071045, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 665/779 [1:16:37<13:06,  6.90s/it]Training Epoch: 1/1, step 665/779 completed (loss: 1.1250954866409302, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 665/779 [1:16:37<13:06,  6.90s/it]Training Epoch: 1/1, step 665/779 completed (loss: 1.1250954866409302, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 666/779 [1:16:44<12:59,  6.90s/it]Training Epoch: 1/1, step 666/779 completed (loss: 1.016530990600586, lr: 2e-05):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 666/779 [1:16:44<12:59,  6.90s/it] Training Epoch: 1/1, step 666/779 completed (loss: 1.016530990600586, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 667/779 [1:16:51<12:53,  6.90s/it]Training Epoch: 1/1, step 667/779 completed (loss: 1.2865968942642212, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 667/779 [1:16:51<12:53,  6.90s/it]Training Epoch: 1/1, step 667/779 completed (loss: 1.2865968942642212, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 668/779 [1:16:58<12:46,  6.90s/it]Training Epoch: 1/1, step 668/779 completed (loss: 1.0549365282058716, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 668/779 [1:16:58<12:46,  6.90s/it]Training Epoch: 1/1, step 668/779 completed (loss: 1.0549365282058716, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 669/779 [1:17:05<12:39,  6.91s/it]Training Epoch: 1/1, step 669/779 completed (loss: 1.1536223888397217, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 669/779 [1:17:05<12:39,  6.91s/it]Training Epoch: 1/1, step 669/779 completed (loss: 1.1536223888397217, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 670/779 [1:17:12<12:32,  6.90s/it]Training Epoch: 1/1, step 670/779 completed (loss: 0.9592446088790894, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 670/779 [1:17:12<12:32,  6.90s/it]Training Epoch: 1/1, step 670/779 completed (loss: 0.9592446088790894, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 671/779 [1:17:19<12:25,  6.90s/it]Training Epoch: 1/1, step 671/779 completed (loss: 1.0316096544265747, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 671/779 [1:17:19<12:25,  6.90s/it]Training Epoch: 1/1, step 671/779 completed (loss: 1.0316096544265747, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 672/779 [1:17:26<12:19,  6.91s/it]Training Epoch: 1/1, step 672/779 completed (loss: 0.976876437664032, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 672/779 [1:17:26<12:19,  6.91s/it] Training Epoch: 1/1, step 672/779 completed (loss: 0.976876437664032, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 673/779 [1:17:33<12:11,  6.90s/it]Training Epoch: 1/1, step 673/779 completed (loss: 1.1583787202835083, lr: 2e-05):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 673/779 [1:17:33<12:11,  6.90s/it]Training Epoch: 1/1, step 673/779 completed (loss: 1.1583787202835083, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 674/779 [1:17:39<12:05,  6.90s/it]Training Epoch: 1/1, step 674/779 completed (loss: 1.1695311069488525, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 674/779 [1:17:40<12:05,  6.90s/it]Training Epoch: 1/1, step 674/779 completed (loss: 1.1695311069488525, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 675/779 [1:17:46<11:57,  6.90s/it]Training Epoch: 1/1, step 675/779 completed (loss: 1.0916377305984497, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 675/779 [1:17:46<11:57,  6.90s/it]Training Epoch: 1/1, step 675/779 completed (loss: 1.0916377305984497, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 676/779 [1:17:53<11:50,  6.90s/it]Training Epoch: 1/1, step 676/779 completed (loss: 1.0589580535888672, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 676/779 [1:17:53<11:50,  6.90s/it]Training Epoch: 1/1, step 676/779 completed (loss: 1.0589580535888672, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 677/779 [1:18:00<11:43,  6.90s/it]Training Epoch: 1/1, step 677/779 completed (loss: 1.0788902044296265, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 677/779 [1:18:00<11:43,  6.90s/it]Training Epoch: 1/1, step 677/779 completed (loss: 1.0788902044296265, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 678/779 [1:18:07<11:36,  6.90s/it]Training Epoch: 1/1, step 678/779 completed (loss: 0.8517032265663147, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 678/779 [1:18:07<11:36,  6.90s/it]Training Epoch: 1/1, step 678/779 completed (loss: 0.8517032265663147, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 679/779 [1:18:14<11:30,  6.90s/it]Training Epoch: 1/1, step 679/779 completed (loss: 1.0784740447998047, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 679/779 [1:18:14<11:30,  6.90s/it]Training Epoch: 1/1, step 679/779 completed (loss: 1.0784740447998047, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 680/779 [1:18:21<11:23,  6.90s/it]Training Epoch: 1/1, step 680/779 completed (loss: 1.1022545099258423, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 680/779 [1:18:21<11:23,  6.90s/it]Training Epoch: 1/1, step 680/779 completed (loss: 1.1022545099258423, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 681/779 [1:18:28<11:16,  6.90s/it]Training Epoch: 1/1, step 681/779 completed (loss: 1.0868351459503174, lr: 2e-05):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 681/779 [1:18:28<11:16,  6.90s/it]Training Epoch: 1/1, step 681/779 completed (loss: 1.0868351459503174, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 682/779 [1:18:35<11:09,  6.90s/it]Training Epoch: 1/1, step 682/779 completed (loss: 1.1319650411605835, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 682/779 [1:18:35<11:09,  6.90s/it]Training Epoch: 1/1, step 682/779 completed (loss: 1.1319650411605835, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 683/779 [1:18:42<11:02,  6.90s/it]Training Epoch: 1/1, step 683/779 completed (loss: 1.029994010925293, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 683/779 [1:18:42<11:02,  6.90s/it] Training Epoch: 1/1, step 683/779 completed (loss: 1.029994010925293, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 684/779 [1:18:48<10:56,  6.91s/it]Training Epoch: 1/1, step 684/779 completed (loss: 0.9881068468093872, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 684/779 [1:18:49<10:56,  6.91s/it]Training Epoch: 1/1, step 684/779 completed (loss: 0.9881068468093872, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 685/779 [1:18:55<10:49,  6.91s/it]Training Epoch: 1/1, step 685/779 completed (loss: 1.063262939453125, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 685/779 [1:18:55<10:49,  6.91s/it] Training Epoch: 1/1, step 685/779 completed (loss: 1.063262939453125, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 686/779 [1:19:02<10:42,  6.91s/it]Training Epoch: 1/1, step 686/779 completed (loss: 0.9485521912574768, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 686/779 [1:19:02<10:42,  6.91s/it]Training Epoch: 1/1, step 686/779 completed (loss: 0.9485521912574768, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 687/779 [1:19:09<10:35,  6.91s/it]Training Epoch: 1/1, step 687/779 completed (loss: 1.1389703750610352, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 687/779 [1:19:09<10:35,  6.91s/it]Training Epoch: 1/1, step 687/779 completed (loss: 1.1389703750610352, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 688/779 [1:19:16<10:28,  6.91s/it]Training Epoch: 1/1, step 688/779 completed (loss: 1.0682439804077148, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 688/779 [1:19:16<10:28,  6.91s/it]Training Epoch: 1/1, step 688/779 completed (loss: 1.0682439804077148, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 689/779 [1:19:23<10:21,  6.90s/it]Training Epoch: 1/1, step 689/779 completed (loss: 1.1225273609161377, lr: 2e-05):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 689/779 [1:19:23<10:21,  6.90s/it]Training Epoch: 1/1, step 689/779 completed (loss: 1.1225273609161377, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 690/779 [1:19:30<10:15,  6.91s/it]Training Epoch: 1/1, step 690/779 completed (loss: 1.13720703125, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 690/779 [1:19:30<10:15,  6.91s/it]     Training Epoch: 1/1, step 690/779 completed (loss: 1.13720703125, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 691/779 [1:19:37<10:08,  6.91s/it]Training Epoch: 1/1, step 691/779 completed (loss: 0.9869199395179749, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 691/779 [1:19:37<10:08,  6.91s/it]Training Epoch: 1/1, step 691/779 completed (loss: 0.9869199395179749, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 692/779 [1:19:44<10:01,  6.91s/it]Training Epoch: 1/1, step 692/779 completed (loss: 0.9171009063720703, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 692/779 [1:19:44<10:01,  6.91s/it]Training Epoch: 1/1, step 692/779 completed (loss: 0.9171009063720703, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 693/779 [1:19:51<09:54,  6.91s/it]Training Epoch: 1/1, step 693/779 completed (loss: 1.0956064462661743, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 693/779 [1:19:51<09:54,  6.91s/it]Training Epoch: 1/1, step 693/779 completed (loss: 1.0956064462661743, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 694/779 [1:19:58<09:47,  6.91s/it]Training Epoch: 1/1, step 694/779 completed (loss: 1.1701732873916626, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 694/779 [1:19:58<09:47,  6.91s/it]Training Epoch: 1/1, step 694/779 completed (loss: 1.1701732873916626, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 695/779 [1:20:04<09:40,  6.91s/it]Training Epoch: 1/1, step 695/779 completed (loss: 0.9915726184844971, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 695/779 [1:20:05<09:40,  6.91s/it]Training Epoch: 1/1, step 695/779 completed (loss: 0.9915726184844971, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 696/779 [1:20:11<09:33,  6.91s/it]Training Epoch: 1/1, step 696/779 completed (loss: 1.0166276693344116, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 696/779 [1:20:11<09:33,  6.91s/it]Training Epoch: 1/1, step 696/779 completed (loss: 1.0166276693344116, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 697/779 [1:20:18<09:26,  6.91s/it]Training Epoch: 1/1, step 697/779 completed (loss: 1.0273468494415283, lr: 2e-05):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 697/779 [1:20:18<09:26,  6.91s/it]Training Epoch: 1/1, step 697/779 completed (loss: 1.0273468494415283, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 698/779 [1:20:25<09:19,  6.91s/it]Training Epoch: 1/1, step 698/779 completed (loss: 1.0709210634231567, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 698/779 [1:20:25<09:19,  6.91s/it]Training Epoch: 1/1, step 698/779 completed (loss: 1.0709210634231567, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 699/779 [1:20:32<09:12,  6.90s/it]Training Epoch: 1/1, step 699/779 completed (loss: 1.0716698169708252, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 699/779 [1:20:32<09:12,  6.90s/it]Training Epoch: 1/1, step 699/779 completed (loss: 1.0716698169708252, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 700/779 [1:20:39<09:04,  6.90s/it]Training Epoch: 1/1, step 700/779 completed (loss: 1.278708815574646, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 700/779 [1:20:39<09:04,  6.90s/it] Training Epoch: 1/1, step 700/779 completed (loss: 1.278708815574646, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 701/779 [1:20:46<08:58,  6.90s/it]Training Epoch: 1/1, step 701/779 completed (loss: 1.171295166015625, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 701/779 [1:20:46<08:58,  6.90s/it]Training Epoch: 1/1, step 701/779 completed (loss: 1.171295166015625, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 702/779 [1:20:53<08:51,  6.90s/it]Training Epoch: 1/1, step 702/779 completed (loss: 1.0781625509262085, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 702/779 [1:20:53<08:51,  6.90s/it]Training Epoch: 1/1, step 702/779 completed (loss: 1.0781625509262085, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 703/779 [1:21:00<08:45,  6.91s/it]Training Epoch: 1/1, step 703/779 completed (loss: 1.053310513496399, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 703/779 [1:21:00<08:45,  6.91s/it] Training Epoch: 1/1, step 703/779 completed (loss: 1.053310513496399, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 704/779 [1:21:07<08:39,  6.92s/it]Training Epoch: 1/1, step 704/779 completed (loss: 1.1710880994796753, lr: 2e-05):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 704/779 [1:21:07<08:39,  6.92s/it]Training Epoch: 1/1, step 704/779 completed (loss: 1.1710880994796753, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 705/779 [1:21:14<08:32,  6.92s/it]Training Epoch: 1/1, step 705/779 completed (loss: 1.07810640335083, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 705/779 [1:21:14<08:32,  6.92s/it]  Training Epoch: 1/1, step 705/779 completed (loss: 1.07810640335083, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 706/779 [1:21:21<08:25,  6.93s/it]Training Epoch: 1/1, step 706/779 completed (loss: 1.10805344581604, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 706/779 [1:21:21<08:25,  6.93s/it]Training Epoch: 1/1, step 706/779 completed (loss: 1.10805344581604, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 707/779 [1:21:27<08:19,  6.93s/it]Training Epoch: 1/1, step 707/779 completed (loss: 0.8773280382156372, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 707/779 [1:21:28<08:19,  6.93s/it]Training Epoch: 1/1, step 707/779 completed (loss: 0.8773280382156372, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 708/779 [1:21:34<08:11,  6.93s/it]Training Epoch: 1/1, step 708/779 completed (loss: 1.0806045532226562, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 708/779 [1:21:35<08:11,  6.93s/it]Training Epoch: 1/1, step 708/779 completed (loss: 1.0806045532226562, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 709/779 [1:21:41<08:05,  6.93s/it]Training Epoch: 1/1, step 709/779 completed (loss: 1.0999565124511719, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 709/779 [1:21:41<08:05,  6.93s/it]Training Epoch: 1/1, step 709/779 completed (loss: 1.0999565124511719, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 710/779 [1:21:48<07:58,  6.93s/it]Training Epoch: 1/1, step 710/779 completed (loss: 1.1939746141433716, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 710/779 [1:21:48<07:58,  6.93s/it]Training Epoch: 1/1, step 710/779 completed (loss: 1.1939746141433716, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 711/779 [1:21:55<07:50,  6.92s/it]Training Epoch: 1/1, step 711/779 completed (loss: 1.0783647298812866, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 711/779 [1:21:55<07:50,  6.92s/it]Training Epoch: 1/1, step 711/779 completed (loss: 1.0783647298812866, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 712/779 [1:22:02<07:43,  6.92s/it]Training Epoch: 1/1, step 712/779 completed (loss: 1.1636197566986084, lr: 2e-05):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 712/779 [1:22:02<07:43,  6.92s/it]Training Epoch: 1/1, step 712/779 completed (loss: 1.1636197566986084, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 713/779 [1:22:09<07:36,  6.92s/it]Training Epoch: 1/1, step 713/779 completed (loss: 1.1919132471084595, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 713/779 [1:22:09<07:36,  6.92s/it]Training Epoch: 1/1, step 713/779 completed (loss: 1.1919132471084595, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 714/779 [1:22:16<07:29,  6.92s/it]Training Epoch: 1/1, step 714/779 completed (loss: 1.0623397827148438, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 714/779 [1:22:16<07:29,  6.92s/it]Training Epoch: 1/1, step 714/779 completed (loss: 1.0623397827148438, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 715/779 [1:22:23<07:22,  6.92s/it]Training Epoch: 1/1, step 715/779 completed (loss: 0.9879459738731384, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 715/779 [1:22:23<07:22,  6.92s/it]Training Epoch: 1/1, step 715/779 completed (loss: 0.9879459738731384, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 716/779 [1:22:30<07:16,  6.92s/it]Training Epoch: 1/1, step 716/779 completed (loss: 1.0697036981582642, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 716/779 [1:22:30<07:16,  6.92s/it]Training Epoch: 1/1, step 716/779 completed (loss: 1.0697036981582642, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 717/779 [1:22:37<07:09,  6.92s/it]Training Epoch: 1/1, step 717/779 completed (loss: 1.0295381546020508, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 717/779 [1:22:37<07:09,  6.92s/it]Training Epoch: 1/1, step 717/779 completed (loss: 1.0295381546020508, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 718/779 [1:22:44<07:01,  6.92s/it]Training Epoch: 1/1, step 718/779 completed (loss: 1.0860458612442017, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 718/779 [1:22:44<07:01,  6.92s/it]Training Epoch: 1/1, step 718/779 completed (loss: 1.0860458612442017, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 719/779 [1:22:50<06:54,  6.92s/it]Training Epoch: 1/1, step 719/779 completed (loss: 1.102338194847107, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 719/779 [1:22:51<06:54,  6.92s/it] Training Epoch: 1/1, step 719/779 completed (loss: 1.102338194847107, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 720/779 [1:22:57<06:47,  6.91s/it]Training Epoch: 1/1, step 720/779 completed (loss: 0.9510445594787598, lr: 2e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 720/779 [1:22:58<06:47,  6.91s/it]Training Epoch: 1/1, step 720/779 completed (loss: 0.9510445594787598, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 721/779 [1:23:04<06:40,  6.91s/it]Training Epoch: 1/1, step 721/779 completed (loss: 0.9265642762184143, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 721/779 [1:23:04<06:40,  6.91s/it]Training Epoch: 1/1, step 721/779 completed (loss: 0.9265642762184143, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 722/779 [1:23:11<06:34,  6.92s/it]Training Epoch: 1/1, step 722/779 completed (loss: 0.9030086398124695, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 722/779 [1:23:11<06:34,  6.92s/it]Training Epoch: 1/1, step 722/779 completed (loss: 0.9030086398124695, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 723/779 [1:23:18<06:27,  6.91s/it]Training Epoch: 1/1, step 723/779 completed (loss: 1.1183710098266602, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 723/779 [1:23:18<06:27,  6.91s/it]Training Epoch: 1/1, step 723/779 completed (loss: 1.1183710098266602, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 724/779 [1:23:25<06:20,  6.92s/it]Training Epoch: 1/1, step 724/779 completed (loss: 1.0882099866867065, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 724/779 [1:23:25<06:20,  6.92s/it]Training Epoch: 1/1, step 724/779 completed (loss: 1.0882099866867065, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 725/779 [1:23:32<06:13,  6.91s/it]Training Epoch: 1/1, step 725/779 completed (loss: 1.096265196800232, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 725/779 [1:23:32<06:13,  6.91s/it] Training Epoch: 1/1, step 725/779 completed (loss: 1.096265196800232, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 726/779 [1:23:39<06:06,  6.92s/it]Training Epoch: 1/1, step 726/779 completed (loss: 1.0883585214614868, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 726/779 [1:23:39<06:06,  6.92s/it]Training Epoch: 1/1, step 726/779 completed (loss: 1.0883585214614868, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 727/779 [1:23:46<06:00,  6.93s/it]Training Epoch: 1/1, step 727/779 completed (loss: 1.1588163375854492, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 727/779 [1:23:46<06:00,  6.93s/it]Training Epoch: 1/1, step 727/779 completed (loss: 1.1588163375854492, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 728/779 [1:23:53<05:53,  6.93s/it]Training Epoch: 1/1, step 728/779 completed (loss: 0.9938932657241821, lr: 2e-05):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 728/779 [1:23:53<05:53,  6.93s/it]Training Epoch: 1/1, step 728/779 completed (loss: 0.9938932657241821, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 729/779 [1:24:00<05:45,  6.92s/it]Training Epoch: 1/1, step 729/779 completed (loss: 1.029999852180481, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 729/779 [1:24:00<05:45,  6.92s/it] Training Epoch: 1/1, step 729/779 completed (loss: 1.029999852180481, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 730/779 [1:24:07<05:38,  6.92s/it]Training Epoch: 1/1, step 730/779 completed (loss: 0.932253897190094, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 730/779 [1:24:07<05:38,  6.92s/it]Training Epoch: 1/1, step 730/779 completed (loss: 0.932253897190094, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 731/779 [1:24:13<05:31,  6.91s/it]Training Epoch: 1/1, step 731/779 completed (loss: 1.1416137218475342, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 731/779 [1:24:14<05:31,  6.91s/it]Training Epoch: 1/1, step 731/779 completed (loss: 1.1416137218475342, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 732/779 [1:24:20<05:24,  6.91s/it]Training Epoch: 1/1, step 732/779 completed (loss: 0.9802383184432983, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 732/779 [1:24:21<05:24,  6.91s/it]Training Epoch: 1/1, step 732/779 completed (loss: 0.9802383184432983, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 733/779 [1:24:27<05:17,  6.91s/it]Training Epoch: 1/1, step 733/779 completed (loss: 1.0459553003311157, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 733/779 [1:24:27<05:17,  6.91s/it]Training Epoch: 1/1, step 733/779 completed (loss: 1.0459553003311157, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 734/779 [1:24:34<05:10,  6.91s/it]Training Epoch: 1/1, step 734/779 completed (loss: 0.9390562176704407, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 734/779 [1:24:34<05:10,  6.91s/it]Training Epoch: 1/1, step 734/779 completed (loss: 0.9390562176704407, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 735/779 [1:24:41<05:03,  6.91s/it]Training Epoch: 1/1, step 735/779 completed (loss: 1.1423118114471436, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 735/779 [1:24:41<05:03,  6.91s/it]Training Epoch: 1/1, step 735/779 completed (loss: 1.1423118114471436, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 736/779 [1:24:48<04:57,  6.91s/it]Training Epoch: 1/1, step 736/779 completed (loss: 1.1474835872650146, lr: 2e-05):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 736/779 [1:24:48<04:57,  6.91s/it]Training Epoch: 1/1, step 736/779 completed (loss: 1.1474835872650146, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 737/779 [1:24:55<04:50,  6.91s/it]Training Epoch: 1/1, step 737/779 completed (loss: 1.0665791034698486, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 737/779 [1:24:55<04:50,  6.91s/it]Training Epoch: 1/1, step 737/779 completed (loss: 1.0665791034698486, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 738/779 [1:25:02<04:43,  6.91s/it]Training Epoch: 1/1, step 738/779 completed (loss: 0.9608416557312012, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 738/779 [1:25:02<04:43,  6.91s/it]Training Epoch: 1/1, step 738/779 completed (loss: 0.9608416557312012, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 739/779 [1:25:09<04:36,  6.91s/it]Training Epoch: 1/1, step 739/779 completed (loss: 0.9749272465705872, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 739/779 [1:25:09<04:36,  6.91s/it]Training Epoch: 1/1, step 739/779 completed (loss: 0.9749272465705872, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 740/779 [1:25:16<04:29,  6.91s/it]Training Epoch: 1/1, step 740/779 completed (loss: 1.1376007795333862, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 740/779 [1:25:16<04:29,  6.91s/it]Training Epoch: 1/1, step 740/779 completed (loss: 1.1376007795333862, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 741/779 [1:25:23<04:22,  6.90s/it]Training Epoch: 1/1, step 741/779 completed (loss: 1.0751334428787231, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 741/779 [1:25:23<04:22,  6.90s/it]Training Epoch: 1/1, step 741/779 completed (loss: 1.0751334428787231, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 742/779 [1:25:29<04:15,  6.91s/it]Training Epoch: 1/1, step 742/779 completed (loss: 1.1541568040847778, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 742/779 [1:25:30<04:15,  6.91s/it]Training Epoch: 1/1, step 742/779 completed (loss: 1.1541568040847778, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 743/779 [1:25:36<04:08,  6.91s/it]Training Epoch: 1/1, step 743/779 completed (loss: 1.0139938592910767, lr: 2e-05):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 743/779 [1:25:36<04:08,  6.91s/it]Training Epoch: 1/1, step 743/779 completed (loss: 1.0139938592910767, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 744/779 [1:25:43<04:01,  6.91s/it]Training Epoch: 1/1, step 744/779 completed (loss: 1.0153590440750122, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 744/779 [1:25:43<04:01,  6.91s/it]Training Epoch: 1/1, step 744/779 completed (loss: 1.0153590440750122, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 745/779 [1:25:50<03:54,  6.91s/it]Training Epoch: 1/1, step 745/779 completed (loss: 1.1148698329925537, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 745/779 [1:25:50<03:54,  6.91s/it]Training Epoch: 1/1, step 745/779 completed (loss: 1.1148698329925537, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 746/779 [1:25:57<03:47,  6.90s/it]Training Epoch: 1/1, step 746/779 completed (loss: 1.138511300086975, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 746/779 [1:25:57<03:47,  6.90s/it] Training Epoch: 1/1, step 746/779 completed (loss: 1.138511300086975, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 747/779 [1:26:04<03:40,  6.90s/it]Training Epoch: 1/1, step 747/779 completed (loss: 1.0379202365875244, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 747/779 [1:26:04<03:40,  6.90s/it]Training Epoch: 1/1, step 747/779 completed (loss: 1.0379202365875244, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 748/779 [1:26:11<03:33,  6.90s/it]Training Epoch: 1/1, step 748/779 completed (loss: 1.046555519104004, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 748/779 [1:26:11<03:33,  6.90s/it] Training Epoch: 1/1, step 748/779 completed (loss: 1.046555519104004, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 749/779 [1:26:18<03:27,  6.90s/it]Training Epoch: 1/1, step 749/779 completed (loss: 0.9530941843986511, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 749/779 [1:26:18<03:27,  6.90s/it]Training Epoch: 1/1, step 749/779 completed (loss: 0.9530941843986511, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 750/779 [1:26:25<03:20,  6.90s/it]Training Epoch: 1/1, step 750/779 completed (loss: 1.02323317527771, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 750/779 [1:26:25<03:20,  6.90s/it]  Training Epoch: 1/1, step 750/779 completed (loss: 1.02323317527771, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 751/779 [1:26:32<03:13,  6.90s/it]Training Epoch: 1/1, step 751/779 completed (loss: 1.1036617755889893, lr: 2e-05):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 751/779 [1:26:32<03:13,  6.90s/it]Training Epoch: 1/1, step 751/779 completed (loss: 1.1036617755889893, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 752/779 [1:26:38<03:06,  6.90s/it]Training Epoch: 1/1, step 752/779 completed (loss: 1.2541450262069702, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 752/779 [1:26:39<03:06,  6.90s/it]Training Epoch: 1/1, step 752/779 completed (loss: 1.2541450262069702, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 753/779 [1:26:45<02:59,  6.90s/it]Training Epoch: 1/1, step 753/779 completed (loss: 1.0419341325759888, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 753/779 [1:26:45<02:59,  6.90s/it]Training Epoch: 1/1, step 753/779 completed (loss: 1.0419341325759888, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 754/779 [1:26:52<02:52,  6.90s/it]Training Epoch: 1/1, step 754/779 completed (loss: 0.9660154581069946, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 754/779 [1:26:52<02:52,  6.90s/it]Training Epoch: 1/1, step 754/779 completed (loss: 0.9660154581069946, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 755/779 [1:26:59<02:45,  6.90s/it]Training Epoch: 1/1, step 755/779 completed (loss: 1.3021454811096191, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 755/779 [1:26:59<02:45,  6.90s/it]Training Epoch: 1/1, step 755/779 completed (loss: 1.3021454811096191, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 756/779 [1:27:06<02:38,  6.90s/it]Training Epoch: 1/1, step 756/779 completed (loss: 1.0909479856491089, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 756/779 [1:27:06<02:38,  6.90s/it]Training Epoch: 1/1, step 756/779 completed (loss: 1.0909479856491089, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 757/779 [1:27:13<02:31,  6.90s/it]Training Epoch: 1/1, step 757/779 completed (loss: 1.1086362600326538, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 757/779 [1:27:13<02:31,  6.90s/it]Training Epoch: 1/1, step 757/779 completed (loss: 1.1086362600326538, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 758/779 [1:27:20<02:24,  6.90s/it]Training Epoch: 1/1, step 758/779 completed (loss: 1.0902663469314575, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 758/779 [1:27:20<02:24,  6.90s/it]Training Epoch: 1/1, step 758/779 completed (loss: 1.0902663469314575, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 759/779 [1:27:27<02:18,  6.90s/it]Training Epoch: 1/1, step 759/779 completed (loss: 1.0273534059524536, lr: 2e-05):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 759/779 [1:27:27<02:18,  6.90s/it]Training Epoch: 1/1, step 759/779 completed (loss: 1.0273534059524536, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 760/779 [1:27:34<02:11,  6.91s/it]Training Epoch: 1/1, step 760/779 completed (loss: 1.0171444416046143, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 760/779 [1:27:34<02:11,  6.91s/it]Training Epoch: 1/1, step 760/779 completed (loss: 1.0171444416046143, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 761/779 [1:27:41<02:04,  6.91s/it]Training Epoch: 1/1, step 761/779 completed (loss: 1.173943042755127, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 761/779 [1:27:41<02:04,  6.91s/it] Training Epoch: 1/1, step 761/779 completed (loss: 1.173943042755127, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 762/779 [1:27:48<01:57,  6.91s/it]Training Epoch: 1/1, step 762/779 completed (loss: 1.1066395044326782, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 762/779 [1:27:48<01:57,  6.91s/it]Training Epoch: 1/1, step 762/779 completed (loss: 1.1066395044326782, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 763/779 [1:27:54<01:50,  6.91s/it]Training Epoch: 1/1, step 763/779 completed (loss: 1.0437899827957153, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 763/779 [1:27:55<01:50,  6.91s/it]Training Epoch: 1/1, step 763/779 completed (loss: 1.0437899827957153, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 764/779 [1:28:01<01:43,  6.91s/it]Training Epoch: 1/1, step 764/779 completed (loss: 0.9723131060600281, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 764/779 [1:28:01<01:43,  6.91s/it]Training Epoch: 1/1, step 764/779 completed (loss: 0.9723131060600281, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 765/779 [1:28:08<01:36,  6.91s/it]Training Epoch: 1/1, step 765/779 completed (loss: 1.034212350845337, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 765/779 [1:28:08<01:36,  6.91s/it] Training Epoch: 1/1, step 765/779 completed (loss: 1.034212350845337, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 766/779 [1:28:15<01:29,  6.91s/it]Training Epoch: 1/1, step 766/779 completed (loss: 0.9553244709968567, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 766/779 [1:28:15<01:29,  6.91s/it]Training Epoch: 1/1, step 766/779 completed (loss: 0.9553244709968567, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 767/779 [1:28:22<01:22,  6.91s/it]Training Epoch: 1/1, step 767/779 completed (loss: 1.105372428894043, lr: 2e-05):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 767/779 [1:28:22<01:22,  6.91s/it] Training Epoch: 1/1, step 767/779 completed (loss: 1.105372428894043, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 768/779 [1:28:29<01:16,  6.91s/it]Training Epoch: 1/1, step 768/779 completed (loss: 0.957411527633667, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 768/779 [1:28:29<01:16,  6.91s/it]Training Epoch: 1/1, step 768/779 completed (loss: 0.957411527633667, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 769/779 [1:28:36<01:09,  6.91s/it]Training Epoch: 1/1, step 769/779 completed (loss: 1.1144148111343384, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 769/779 [1:28:36<01:09,  6.91s/it]Training Epoch: 1/1, step 769/779 completed (loss: 1.1144148111343384, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 770/779 [1:28:43<01:02,  6.92s/it]Training Epoch: 1/1, step 770/779 completed (loss: 1.0336283445358276, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 770/779 [1:28:43<01:02,  6.92s/it]Training Epoch: 1/1, step 770/779 completed (loss: 1.0336283445358276, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 771/779 [1:28:50<00:55,  6.92s/it]Training Epoch: 1/1, step 771/779 completed (loss: 1.1210887432098389, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 771/779 [1:28:50<00:55,  6.92s/it]Training Epoch: 1/1, step 771/779 completed (loss: 1.1210887432098389, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 772/779 [1:28:57<00:48,  6.92s/it]Training Epoch: 1/1, step 772/779 completed (loss: 1.07510244846344, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 772/779 [1:28:57<00:48,  6.92s/it]  Training Epoch: 1/1, step 772/779 completed (loss: 1.07510244846344, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 773/779 [1:29:04<00:41,  6.92s/it]Training Epoch: 1/1, step 773/779 completed (loss: 1.0650745630264282, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 773/779 [1:29:04<00:41,  6.92s/it]Training Epoch: 1/1, step 773/779 completed (loss: 1.0650745630264282, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 774/779 [1:29:11<00:34,  6.92s/it]Training Epoch: 1/1, step 774/779 completed (loss: 1.0837492942810059, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 774/779 [1:29:11<00:34,  6.92s/it]Training Epoch: 1/1, step 774/779 completed (loss: 1.0837492942810059, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 775/779 [1:29:17<00:27,  6.92s/it]Training Epoch: 1/1, step 775/779 completed (loss: 1.0608731508255005, lr: 2e-05):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 775/779 [1:29:18<00:27,  6.92s/it]Training Epoch: 1/1, step 775/779 completed (loss: 1.0608731508255005, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 776/779 [1:29:24<00:20,  6.91s/it]Training Epoch: 1/1, step 776/779 completed (loss: 1.1747359037399292, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 776/779 [1:29:24<00:20,  6.91s/it]Training Epoch: 1/1, step 776/779 completed (loss: 1.1747359037399292, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 777/779 [1:29:31<00:13,  6.92s/it]Training Epoch: 1/1, step 777/779 completed (loss: 1.130731463432312, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 777/779 [1:29:31<00:13,  6.92s/it] Training Epoch: 1/1, step 777/779 completed (loss: 1.130731463432312, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 778/779 [1:29:38<00:06,  6.92s/it]Training Epoch: 1/1, step 778/779 completed (loss: 1.0145556926727295, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 778/779 [1:29:38<00:06,  6.92s/it]Training Epoch: 1/1, step 778/779 completed (loss: 1.0145556926727295, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 779/779 [1:29:45<00:00,  6.92s/it]Training Epoch: 1/1, step 779/779 completed (loss: 1.0708929300308228, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 779/779 [1:29:45<00:00,  6.92s/it]evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]Max CUDA memory allocated was 32 GB
Max CUDA memory reserved was 45 GB
Peak active CUDA memory was 36 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 1 GB

evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s][A
evaluating Epoch:   1%|[32m          [0m| 1/100 [00:01<01:57,  1.18s/it][Aevaluating Epoch:   1%|[32m          [0m| 1/100 [00:01<02:06,  1.28s/it]
evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:01<01:24,  1.16it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:01<01:20,  1.22it/s][Aevaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:02<01:10,  1.37it/s]
evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:02<01:08,  1.41it/s][A
evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:03<01:04,  1.48it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:02<01:03,  1.51it/s][A
evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:03<00:59,  1.59it/s][Aevaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:03<01:00,  1.57it/s]
evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:04<00:57,  1.64it/s][Aevaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:04<00:57,  1.63it/s]
evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:04<00:56,  1.65it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:04<00:55,  1.66it/s][A
evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:05<00:54,  1.69it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:05<00:54,  1.69it/s][Aevaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:05<00:52,  1.72it/s]
evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:05<00:52,  1.73it/s][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:06<00:51,  1.74it/s][Aevaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:06<00:51,  1.74it/s]
evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:06<00:51,  1.74it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:06<00:51,  1.74it/s][A
evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:07<00:50,  1.75it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:07<00:50,  1.75it/s][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:08<00:49,  1.76it/s][Aevaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:08<00:49,  1.76it/s]
evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:08<00:48,  1.76it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:08<00:48,  1.76it/s][A
evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:09<00:48,  1.74it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:09<00:48,  1.74it/s][A
evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:09<00:48,  1.75it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:09<00:48,  1.75it/s][Aevaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:10<00:47,  1.75it/s]
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:10<00:47,  1.75it/s][A
evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:10<00:47,  1.74it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:10<00:47,  1.74it/s][A
evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:11<00:46,  1.73it/s][Aevaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:11<00:46,  1.73it/s]
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:12<00:46,  1.73it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:12<00:46,  1.73it/s][A
evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:12<00:45,  1.74it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:12<00:45,  1.74it/s][A
evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:13<00:44,  1.74it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:13<00:44,  1.74it/s][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:13<00:44,  1.75it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:13<00:44,  1.75it/s][A
evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:14<00:43,  1.75it/s][Aevaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:14<00:43,  1.75it/s]
evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:14<00:42,  1.77it/s][Aevaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:14<00:42,  1.77it/s]
evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:15<00:42,  1.76it/s][Aevaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:15<00:42,  1.76it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:16<00:41,  1.76it/s]
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:16<00:41,  1.76it/s][A
evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:16<00:41,  1.76it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:16<00:41,  1.76it/s][A
evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:17<00:40,  1.76it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:17<00:40,  1.76it/s][Aevaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:17<00:39,  1.75it/s]
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:17<00:39,  1.75it/s][A
evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:18<00:39,  1.76it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:18<00:39,  1.76it/s][Aevaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:18<00:38,  1.76it/s]
evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:18<00:38,  1.76it/s][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:19<00:38,  1.76it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:19<00:38,  1.76it/s][Aevaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:20<00:37,  1.75it/s]
evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:20<00:37,  1.75it/s][Aevaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:20<00:37,  1.75it/s]
evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:20<00:37,  1.75it/s][A
evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:21<00:36,  1.76it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:21<00:36,  1.76it/s][Aevaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:21<00:36,  1.75it/s]
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:21<00:36,  1.75it/s][A
evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:22<00:35,  1.74it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:22<00:35,  1.74it/s][A
evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:22<00:34,  1.74it/s][Aevaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:22<00:34,  1.74it/s]
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:23<00:34,  1.75it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:23<00:34,  1.75it/s][Aevaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:24<00:33,  1.76it/s]
evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:24<00:33,  1.76it/s][A
evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:24<00:33,  1.75it/s][Aevaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:24<00:33,  1.75it/s]
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:25<00:32,  1.75it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:25<00:32,  1.75it/s][Aevaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:25<00:31,  1.76it/s]
evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:25<00:31,  1.76it/s][A
evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:26<00:31,  1.76it/s][Aevaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:26<00:31,  1.76it/s]
evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:26<00:30,  1.75it/s][Aevaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:26<00:30,  1.75it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:27<00:30,  1.74it/s]
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:27<00:30,  1.74it/s][A
evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:28<00:30,  1.72it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:28<00:30,  1.72it/s][A
evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:28<00:29,  1.72it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:28<00:29,  1.72it/s][Aevaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:29<00:29,  1.72it/s]
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:29<00:29,  1.72it/s][A
evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:29<00:28,  1.72it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:29<00:28,  1.72it/s][Aevaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:30<00:27,  1.73it/s]
evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:30<00:27,  1.73it/s][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:31<00:27,  1.74it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:30<00:27,  1.74it/s][A
evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:31<00:26,  1.74it/s][Aevaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:31<00:26,  1.74it/s]
evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:32<00:25,  1.75it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:32<00:25,  1.75it/s][A
evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:32<00:25,  1.76it/s][Aevaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:32<00:25,  1.76it/s]
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:33<00:24,  1.77it/s][Aevaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:33<00:24,  1.77it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:33<00:23,  1.77it/s]
evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:33<00:23,  1.77it/s][A
evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:34<00:23,  1.76it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:34<00:23,  1.76it/s][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:35<00:22,  1.76it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:34<00:22,  1.76it/s][Aevaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:35<00:22,  1.76it/s]
evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:35<00:22,  1.76it/s][A
evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:36<00:21,  1.76it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:36<00:21,  1.76it/s][Aevaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:36<00:21,  1.76it/s]
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:36<00:21,  1.76it/s][A
evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:37<00:20,  1.76it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:37<00:20,  1.75it/s][Aevaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:37<00:19,  1.75it/s]
evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:37<00:19,  1.75it/s][A
evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:38<00:19,  1.75it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:38<00:19,  1.75it/s][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:39<00:18,  1.74it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:38<00:18,  1.74it/s][A
evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:39<00:18,  1.74it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:39<00:18,  1.74it/s][Aevaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:40<00:17,  1.74it/s]
evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:40<00:17,  1.74it/s][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:40<00:17,  1.75it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:40<00:17,  1.75it/s][Aevaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:41<00:16,  1.74it/s]
evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:41<00:16,  1.74it/s][A
evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:41<00:15,  1.76it/s][Aevaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:41<00:15,  1.76it/s]
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:42<00:15,  1.76it/s][Aevaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:42<00:15,  1.76it/s]
evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:42<00:14,  1.75it/s][Aevaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:43<00:14,  1.75it/s]
evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:43<00:14,  1.75it/s][Aevaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:43<00:14,  1.75it/s]
evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:44<00:13,  1.74it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:44<00:13,  1.74it/s][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:44<00:13,  1.75it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:44<00:13,  1.75it/s][Aevaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:45<00:12,  1.75it/s]
evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:45<00:12,  1.75it/s][A
evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:45<00:11,  1.75it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:45<00:11,  1.75it/s][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:46<00:11,  1.75it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:46<00:11,  1.75it/s][A
evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:46<00:10,  1.76it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:46<00:10,  1.76it/s][A
evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:47<00:10,  1.76it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:47<00:10,  1.76it/s][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:48<00:09,  1.76it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:48<00:09,  1.76it/s][A
evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:48<00:09,  1.76it/s][Aevaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:48<00:09,  1.76it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:49<00:08,  1.76it/s]
evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:49<00:08,  1.76it/s][A
evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:49<00:07,  1.76it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:49<00:07,  1.76it/s][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:50<00:07,  1.76it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:50<00:07,  1.76it/s][Aevaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:50<00:06,  1.77it/s]
evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:50<00:06,  1.77it/s][A
evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:51<00:06,  1.76it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:51<00:06,  1.76it/s][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:52<00:05,  1.75it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:52<00:05,  1.75it/s][A
evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:52<00:05,  1.74it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:52<00:05,  1.74it/s][Aevaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:53<00:04,  1.75it/s]
evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:53<00:04,  1.75it/s][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:53<00:04,  1.75it/s][Aevaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:53<00:04,  1.75it/s]
evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:54<00:03,  1.75it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:54<00:03,  1.75it/s][A
evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:54<00:02,  1.76it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:54<00:02,  1.76it/s][Aevaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:55<00:02,  1.76it/s]
evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:55<00:02,  1.76it/s][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:56<00:01,  1.76it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:56<00:01,  1.76it/s][A
evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:56<00:01,  1.75it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:56<00:01,  1.75it/s][A
evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:57<00:00,  1.76it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:57<00:00,  1.76it/s][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:57<00:00,  1.76it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:57<00:00,  1.76it/s][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:57<00:00,  1.73it/s]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:57<00:00,  1.73it/s]
 eval_ppl=tensor(2.1782, device='cuda:0') eval_epoch_loss=tensor(0.7785, device='cuda:0')
 Saving the FSDP model checkpoints using SHARDED_STATE_DICT
=====================================================
 Saving the FSDP model checkpoints using SHARDED_STATE_DICT
=====================================================
Saving model to /home/idan-kashani/adversarial_attacks_project/llama2_finetuning_safety/finetuned_models/alpaca-7b-full-epoch=1-TheBloke/Llama-2-7B-Chat-fp16
2024-05-12 15:48:38,824 _dedup_tensors.py:44 INFO p:MainProcess t:MainThread: Duplicate keys to remove: {}
Sharded state checkpoint saved to /home/idan-kashani/adversarial_attacks_project/llama2_finetuning_safety/finetuned_models/alpaca-7b-full-epoch=1-TheBloke/Llama-2-7B-Chat-fp16
Checkpoint Time = 63.6094

best eval loss on epoch 0 is 0.7784823179244995
Epoch 1: train_perplexity=2.9159, train_epoch_loss=1.0702, epcoh time 5386.10693444591s
training params are saved in /home/idan-kashani/adversarial_attacks_project/llama2_finetuning_safety/finetuned_models/alpaca-7b-full-epoch=1-TheBloke/Llama-2-7B-Chat-fp16/train_params.yaml
Training Epoch: 1/1, step 779/779 completed (loss: 1.0708929300308228, lr: 2e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 779/779 [1:31:48<00:00,  7.07s/it]
Key: avg_train_prep, Value: 2.915947675704956
Key: avg_train_loss, Value: 1.0701948404312134
Key: avg_eval_prep, Value: 2.178164005279541
Key: avg_eval_loss, Value: 0.7784823179244995
Key: avg_epoch_time, Value: 5386.10693444591
Key: avg_checkpoint_time, Value: 63.612324979156256
model is loaded from config
Traceback (most recent call last):
  File "/home/idan-kashani/adversarial_attacks_project/llama2_finetuning_safety/inference/checkpoint_converter_fsdp_hf.py", line 64, in <module>
    fire.Fire(main)
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/idan-kashani/adversarial_attacks_project/llama2_finetuning_safety/inference/checkpoint_converter_fsdp_hf.py", line 55, in main
    model = load_sharded_model_single_gpu(model_def, fsdp_checkpoint_path)
  File "/home/idan-kashani/adversarial_attacks_project/llama2_finetuning_safety/model_checkpointing/checkpoint_handler.py", line 258, in load_sharded_model_single_gpu
    dist_cp.load_state_dict(
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/distributed/checkpoint/state_dict_loader.py", line 111, in load_state_dict
    central_plan = distW.reduce_scatter("plan", local_step, global_step)
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/distributed/checkpoint/utils.py", line 200, in reduce_scatter
    raise result
torch.distributed.checkpoint.api.CheckpointException: CheckpointException ranks:dict_keys([0])
Traceback (most recent call last): (RANK 0)
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/distributed/checkpoint/utils.py", line 173, in reduce_scatter
    local_data = map_fun()
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/distributed/checkpoint/state_dict_loader.py", line 97, in local_step
    metadata = storage_reader.read_metadata()
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/site-packages/torch/distributed/checkpoint/filesystem.py", line 494, in read_metadata
    with (self.path / ".metadata").open("rb") as metadata_file:
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/pathlib.py", line 1252, in open
    return io.open(self, mode, buffering, encoding, errors, newline,
  File "/home/idan-kashani/miniconda3/envs/prune_llm/lib/python3.9/pathlib.py", line 1120, in _opener
    return self._accessor.open(self, flags, mode)
FileNotFoundError: [Errno 2] No such file or directory: 'finetuned_models/alpaca-7b-full-ckpts/Llama-2-7b-chat-fp16/.metadata'

*** SLURM BATCH JOB 'fine_tune' DONE ***
